{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100, 1]) tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "         90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n",
      "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "         90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])\n",
      "torch.Size([2, 100]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "x = torch.cat([torch.arange(0,100)[None], torch.arange(0,100)[None], torch.arange(0,100)[None]], dim=0)[...,None]\n",
    "print(x.shape, x[...,0])\n",
    "onehot = torch.zeros_like(x)[...,0]\n",
    "onehot[0,:10] = 1\n",
    "onehot[1,:5] = 1\n",
    "print(onehot.shape, onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([2, 100, 1]) tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0],\n",
      "        [0, 1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "r = seq_utils.seq_clean(x, onehot.bool())\n",
    "print(r.shape, r[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([2, 1]) tensor([4, 2])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "r = seq_utils.seq_avg_pooling(x, onehot.bool())\n",
    "print(r.shape, r[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([2, 1]) tensor([9, 4])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "r = seq_utils.seq_last_element(x, onehot.bool())\n",
    "print(r.shape, r[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([2, 1]) tensor([9, 4])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "r = seq_utils.seq_max_pooling(x, onehot.bool())\n",
    "print(r.shape, r[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([3, 10]) tensor([[ True,  True,  True,  True,  True, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "r = seq_utils.get_seq_onehot_mask(torch.tensor([5,7,2]), 10)\n",
    "print(r.shape, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([2, 100, 1]) torch.Size([2, 100]) torch.Size([2, 101, 1])\n",
      "torch.Size([2, 100, 1]) tensor([[ 0,  1,  2,  9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 0,  2,  7, 11, 99,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "onehot = torch.zeros_like(x)[...,0]\n",
    "onehot[0,1] = 1\n",
    "onehot[0,2] = 1\n",
    "onehot[0,0] = 1\n",
    "onehot[0,9] = 1\n",
    "\n",
    "onehot[1,0] = 1\n",
    "onehot[1,2] = 1\n",
    "onehot[1,7] = 1\n",
    "onehot[1,11] = 1\n",
    "onehot[1,99] = 1\n",
    "\n",
    "p = seq_utils.serial_to_parallel(x, onehot.bool())\n",
    "print(p.shape, p[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([2, 100, 1]) tensor([  5.,   6.,   7.,   8.,   9.,  10.,  11.,  12.,  13.,  14.,  15.,  16.,\n",
      "         17.,  18.,  19.,  20.,  21.,  22.,  23.,  24.,  25.,  26.,  27.,  28.,\n",
      "         29.,  30.,  31.,  32.,  33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,\n",
      "         41.,  42.,  43.,  44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,\n",
      "         53.,  54.,  55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,\n",
      "         65.,  66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,\n",
      "         77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,  88.,\n",
      "         89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,  99., 100.,\n",
      "        101., 102., 103., 104.])\n",
      "torch.Size([2, 100, 1]) tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
      "        28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,\n",
      "        42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53., 54., 55.,\n",
      "        56., 57., 58., 59., 60., 61., 62., 63., 64., 65., 66., 67., 68., 69.,\n",
      "        70., 71., 72., 73., 74., 75., 76., 77., 78., 79., 80., 81., 82., 83.,\n",
      "        84., 85., 86., 87., 88., 89., 90., 91., 92., 93., 94., 95., 96., 97.,\n",
      "        98., 99.])\n",
      "torch.Size([100, 2]) tensor([[ 0,  0],\n",
      "        [ 0,  2],\n",
      "        [ 0,  3],\n",
      "        [ 0,  4],\n",
      "        [ 0,  8],\n",
      "        [ 0,  9],\n",
      "        [ 0, 10],\n",
      "        [ 0, 12],\n",
      "        [ 0, 13],\n",
      "        [ 0, 14],\n",
      "        [ 0, 15],\n",
      "        [ 0, 17],\n",
      "        [ 0, 18],\n",
      "        [ 0, 23],\n",
      "        [ 0, 24],\n",
      "        [ 0, 25],\n",
      "        [ 0, 27],\n",
      "        [ 0, 30],\n",
      "        [ 0, 31],\n",
      "        [ 0, 32],\n",
      "        [ 0, 35],\n",
      "        [ 0, 37],\n",
      "        [ 0, 38],\n",
      "        [ 0, 39],\n",
      "        [ 0, 40],\n",
      "        [ 0, 41],\n",
      "        [ 0, 42],\n",
      "        [ 0, 46],\n",
      "        [ 0, 47],\n",
      "        [ 0, 48],\n",
      "        [ 0, 51],\n",
      "        [ 0, 52],\n",
      "        [ 0, 59],\n",
      "        [ 0, 67],\n",
      "        [ 0, 68],\n",
      "        [ 0, 70],\n",
      "        [ 0, 71],\n",
      "        [ 0, 73],\n",
      "        [ 0, 75],\n",
      "        [ 0, 76],\n",
      "        [ 0, 77],\n",
      "        [ 0, 78],\n",
      "        [ 0, 79],\n",
      "        [ 0, 80],\n",
      "        [ 0, 83],\n",
      "        [ 0, 85],\n",
      "        [ 0, 88],\n",
      "        [ 0, 90],\n",
      "        [ 0, 94],\n",
      "        [ 0, 96],\n",
      "        [ 0, 97],\n",
      "        [ 0, 99],\n",
      "        [ 1,  1],\n",
      "        [ 1,  8],\n",
      "        [ 1, 10],\n",
      "        [ 1, 13],\n",
      "        [ 1, 14],\n",
      "        [ 1, 17],\n",
      "        [ 1, 19],\n",
      "        [ 1, 20],\n",
      "        [ 1, 23],\n",
      "        [ 1, 24],\n",
      "        [ 1, 29],\n",
      "        [ 1, 30],\n",
      "        [ 1, 31],\n",
      "        [ 1, 32],\n",
      "        [ 1, 34],\n",
      "        [ 1, 36],\n",
      "        [ 1, 38],\n",
      "        [ 1, 39],\n",
      "        [ 1, 40],\n",
      "        [ 1, 43],\n",
      "        [ 1, 44],\n",
      "        [ 1, 45],\n",
      "        [ 1, 47],\n",
      "        [ 1, 49],\n",
      "        [ 1, 51],\n",
      "        [ 1, 52],\n",
      "        [ 1, 55],\n",
      "        [ 1, 56],\n",
      "        [ 1, 57],\n",
      "        [ 1, 58],\n",
      "        [ 1, 60],\n",
      "        [ 1, 63],\n",
      "        [ 1, 64],\n",
      "        [ 1, 66],\n",
      "        [ 1, 71],\n",
      "        [ 1, 72],\n",
      "        [ 1, 75],\n",
      "        [ 1, 78],\n",
      "        [ 1, 79],\n",
      "        [ 1, 82],\n",
      "        [ 1, 86],\n",
      "        [ 1, 87],\n",
      "        [ 1, 92],\n",
      "        [ 1, 93],\n",
      "        [ 1, 94],\n",
      "        [ 1, 95],\n",
      "        [ 1, 96],\n",
      "        [ 1, 98]])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0bffb48d5dd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_to_serial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tesis/fuzzy-torch/fuzzytorch/models/seq_utils.py\u001b[0m in \u001b[0;36mparallel_to_serial\u001b[0;34m(list_x, s_onehot, fill_value)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0;31m#print(x_s.shape, onehot.shape, x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mx_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_scatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monehot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "y = torch.clone(x).float()\n",
    "y[0] = y[0]+5\n",
    "print(y.shape, y[0,:,0])\n",
    "print(y.shape, y[1,:,0])\n",
    "y_onehot = seq_utils.get_random_onehot(y, 2)\n",
    "#print(y_onehot.shape, y_onehot[0])\n",
    "res = []\n",
    "for i in range(2):\n",
    "    y_p = seq_utils.serial_to_parallel(y, y_onehot[...,i])\n",
    "    #print(y_p.shape)\n",
    "    res.append(y_p)\n",
    "    \n",
    "s = seq_utils.parallel_to_serial(res, y_onehot)\n",
    "print(s.shape, s[0,:,0])\n",
    "print(s.shape, s[1,:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
