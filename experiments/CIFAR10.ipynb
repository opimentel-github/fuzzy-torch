{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': (3, 32, 32)-float32-cpu, 'x2': (32)-float32-cpu}, 'target': {'y': ()-int64-cpu, 'y2': (1)-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': (256, 3, 32, 32)-float32-cpu, 'x2': (256, 32)-float32-cpu}, 'target': {'y': (256)-int64-cpu, 'y2': (256, 1)-int64-cpu}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1532) tensor(2.3043)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzytorch.datasets import tensor_data_collate\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True, collate_fn=tensor_data_collate)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size, collate_fn=tensor_data_collate)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64 - id: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64\n",
      "[x-entropy]\n",
      " - opt-parameters: 117,072[p] - device: cpu\n",
      " - save-mode: only_sup_metric(target_metric_crit: accuracy)\n",
      " - early_stop_epochcheck_epochs: 1 - early_stop_patience_epochchecks: 100\n",
      "\u001b[31m> deleting previous epochs [2] in: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64 (id: 0)\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 1/196000 [00:00,  8.02it/s, id: 0 - epoch: 1/1,000(0/196)[x-entropy] *loss*: 2.30=1.15+.77(loss/2+loss/3)]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fuzzytorch/handlers.py:57: UserWarning: there is not CUDA nor GPUs... Using CPU >:(\n",
      "  warnings.warn('there is not CUDA nor GPUs... Using CPU >:(')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 67/196000 [00:08,  8.20it/s, id: 0 - epoch: 1/1,000(66/196)[x-entropy] *loss*: 1.96=.98+.65(loss/2+loss/3)] \n",
      "\u001b[31m*** ctrl+c ***\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "End of training!\n",
      "[x-entropy] best-epoch: 0 - convergence-time: 0.0000[mins] - time-per-epoch: nan[mins]\n",
      "▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fuzzytorch/monitors.py:143: RuntimeWarning: Mean of empty slice.\n",
      "  return np.array(mins_per_epoch).mean()\n",
      "/home/tesla/anaconda3/envs/lchandler/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import CrossEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = CrossEntropy('x-entropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "from fuzzytorch import C_\n",
    "trainh_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':int(1e2),\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **trainh_config)\n",
    "\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "    #'extra_model_name_dict':{'x':9},\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flamingChoripan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4b2c552d70b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mflamingChoripan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtinyFlame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplots\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfplots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### training plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flamingChoripan'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
