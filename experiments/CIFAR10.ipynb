{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': (3, 32, 32)-float32-cpu, 'x2': (32)-float32-cpu}, 'target': {'y': ()-int64-cpu, 'y2': (1)-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': (256, 3, 32, 32)-float32-cpu, 'x2': (256, 32)-float32-cpu}, 'target': {'y': (256)-int64-cpu, 'y2': (256, 1)-int64-cpu}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1441) tensor(2.3107)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzytorch.datasets import tensor_data_collate\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True, collate_fn=tensor_data_collate)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size, collate_fn=tensor_data_collate)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64 - id: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64\n",
      "[x-entropy]\n",
      " - opt-parameters: 117,072[p] - device: cpu\n",
      " - save-mode: only_sup_metric(target_metric_crit: accuracy)\n",
      " - counter_k: k: 0/0 - counter_epoch: val_epoch: 0/0 > earlystop_epoch: 0/21\n",
      "\u001b[31m> (id: 0) deleting previous epochs: [4] in: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 51/196000 [33:42, 39.24s/it, id: 0 - epoch: 51/1,000(195/196)[x-entropy] __loss__: .38=.19+.13(loss/2+loss/3) #.029[segs]\u001b[34m[train][x-entropy] __loss__: .34=.17+.11(loss/2+loss/3) - accuracy: 88.20 - dummy-accuracy: 10.00 #13.278[segs]\u001b[0m\u001b[31m[val][x-entropy] __loss__: .77=.39+.26(loss/2+loss/3) - accuracy: 76.50 - dummy-accuracy: 10.00 #1.950[segs]\u001b[0m\u001b[33m[stop][x-entropy] counter_epoch: val_epoch: 0/0 > earlystop_epoch: 13/21)\u001b[0m]"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import CrossEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = CrossEntropy('x-entropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "from fuzzytorch import C_\n",
    "trainh_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':int(1e2),\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **trainh_config)\n",
    "\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LossMonitor' object has no attribute 'get_time_util_convergence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-be16fb28cb40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# loss_df opt_df loss_df_epoch metrics_df_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss_monitors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_util_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LossMonitor' object has no attribute 'get_time_util_convergence'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_time_util_convergence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['opt_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['loss_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['metrics_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from flamingchoripan.counters import Counter\n",
    "\n",
    "d = {\n",
    "'val_epoch_counter_duration':1,\n",
    "'earlystop_epoch_duration':5,\n",
    "}\n",
    "c = Counter(d)\n",
    "for _ in range(50):\n",
    "    print(c, c.check('earlystop_epoch_duration'))\n",
    "    c.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
