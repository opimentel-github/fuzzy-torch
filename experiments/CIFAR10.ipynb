{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': tensor([[[ 0.3610,  0.4305,  0.5338,  ..., -1.1783, -1.3134, -0.9674],\n",
      "         [-0.0033, -0.0396,  0.0044,  ..., -1.6962, -2.0036, -1.7666],\n",
      "         [-0.2204, -0.0515, -0.1161,  ..., -1.2356, -1.7011, -1.6361],\n",
      "         ...,\n",
      "         [-1.1904, -1.0701,  0.5286,  ...,  1.1310,  1.2030,  1.2488],\n",
      "         [-0.7042, -0.4528,  1.0063,  ...,  0.9431,  0.7682,  0.8578],\n",
      "         [ 0.0857,  0.4183,  1.4880,  ...,  0.8809,  0.7153,  0.8481]],\n",
      "\n",
      "        [[ 0.0488, -0.0523,  0.2145,  ..., -1.1851, -1.3800, -1.0129],\n",
      "         [-0.5561, -0.6220, -0.5374,  ..., -1.9136, -2.0327, -1.6407],\n",
      "         [-0.8272, -0.5730, -0.6528,  ..., -1.5506, -1.8304, -1.5713],\n",
      "         ...,\n",
      "         [-1.3882, -1.5109,  0.1590,  ...,  0.7144,  0.5238,  0.7640],\n",
      "         [-1.0987, -0.9438,  0.3826,  ...,  0.4387, -0.0112,  0.1769],\n",
      "         [-0.5199, -0.0572,  0.9597,  ...,  0.3163,  0.0595,  0.3930]],\n",
      "\n",
      "        [[-0.1661, -0.1712, -0.1496,  ..., -1.1408, -1.0432, -0.7063],\n",
      "         [-0.9374, -0.9633, -0.8232,  ..., -1.6522, -1.7577, -1.4278],\n",
      "         [-1.0202, -0.9325, -0.9816,  ..., -1.5487, -1.7025, -1.3736],\n",
      "         ...,\n",
      "         [-1.3361, -1.7028, -0.7026,  ..., -1.2176, -1.3316, -0.2846],\n",
      "         [-1.2870, -1.2623, -0.3251,  ..., -1.3208, -1.0181, -0.1722],\n",
      "         [-0.6938, -0.4072,  0.3888,  ..., -0.3716, -0.3505, -0.0089]]]), 'x2': tensor([ 0.3610,  0.4305,  0.5338,  0.4504,  0.5411,  0.6454,  0.6682,  0.3736,\n",
      "         0.1410,  0.1814,  0.1464,  0.2050,  0.1879, -0.0098,  0.1577,  0.2492,\n",
      "         0.1423,  0.1755,  0.3657,  0.1499, -0.0632,  0.1109,  0.3990,  0.4275,\n",
      "         0.3431,  0.2058, -0.0852, -0.5116, -1.0438, -1.1783, -1.3134, -0.9674])}, 'target': {'y': tensor(6), 'y2': tensor([6])}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': tensor([[[[-1.8581e-01, -1.5660e-01,  2.2073e-02,  ...,  1.7056e+00,\n",
      "            1.6274e+00,  1.8562e+00],\n",
      "          [-1.9950e-01, -2.2129e-01, -1.0939e-01,  ...,  1.6689e+00,\n",
      "            1.7951e+00,  1.9623e+00],\n",
      "          [-3.4773e-01, -3.5360e-01, -1.9743e-01,  ...,  1.5959e+00,\n",
      "            1.6486e+00,  1.7150e+00],\n",
      "          ...,\n",
      "          [-2.1087e-01, -2.0699e-01, -2.4119e-01,  ..., -3.3763e-01,\n",
      "           -1.4666e-01, -2.4794e-01],\n",
      "          [-1.2911e-01, -1.7418e-01, -8.8255e-02,  ..., -1.6681e-01,\n",
      "           -1.9526e-01, -1.3866e-01],\n",
      "          [-1.2093e-01, -8.9891e-02, -5.0038e-02,  ..., -2.5595e-01,\n",
      "           -3.8721e-01, -1.9560e-01]],\n",
      "\n",
      "         [[-2.8171e-01, -2.1380e-01, -1.3399e-01,  ...,  1.2792e+00,\n",
      "            1.2691e+00,  1.3127e+00],\n",
      "          [-4.0809e-01, -4.3250e-01, -2.3066e-01,  ...,  1.3693e+00,\n",
      "            1.3914e+00,  1.4488e+00],\n",
      "          [-4.0639e-01, -4.3821e-01, -4.0824e-01,  ...,  1.1488e+00,\n",
      "            1.2284e+00,  1.3069e+00],\n",
      "          ...,\n",
      "          [-8.7464e-01, -8.1174e-01, -8.2100e-01,  ..., -8.4115e-01,\n",
      "           -8.6909e-01, -9.5136e-01],\n",
      "          [-6.5156e-01, -9.4014e-01, -9.2920e-01,  ..., -9.9170e-01,\n",
      "           -8.6479e-01, -8.1635e-01],\n",
      "          [-6.4836e-01, -7.3798e-01, -6.8357e-01,  ..., -9.4256e-01,\n",
      "           -9.3768e-01, -8.0682e-01]],\n",
      "\n",
      "         [[-2.6480e-01, -2.3376e-01, -1.1567e-01,  ...,  9.8117e-01,\n",
      "            8.9200e-01,  1.1283e+00],\n",
      "          [-3.5107e-01, -3.0966e-01, -1.6777e-01,  ...,  1.0606e+00,\n",
      "            1.0301e+00,  1.2240e+00],\n",
      "          [-4.1418e-01, -3.5812e-01, -2.3247e-01,  ...,  8.9498e-01,\n",
      "            9.5147e-01,  1.0450e+00],\n",
      "          ...,\n",
      "          [-1.2713e+00, -1.2679e+00, -1.2593e+00,  ..., -1.1173e+00,\n",
      "           -1.0954e+00, -1.2285e+00],\n",
      "          [-9.6265e-01, -1.1955e+00, -1.1337e+00,  ..., -1.1347e+00,\n",
      "           -1.1647e+00, -1.1628e+00],\n",
      "          [-9.8216e-01, -9.9220e-01, -8.9977e-01,  ..., -1.1101e+00,\n",
      "           -1.1802e+00, -1.1084e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.5169e+00, -1.3824e+00, -1.3182e+00,  ..., -1.5861e+00,\n",
      "           -1.2735e+00, -1.5137e+00],\n",
      "          [-1.5367e+00, -1.4669e+00, -1.4965e+00,  ..., -1.3031e+00,\n",
      "           -1.4447e+00, -1.4873e+00],\n",
      "          [-1.2182e+00, -1.2008e+00, -1.3550e+00,  ..., -1.3189e+00,\n",
      "           -1.3324e+00, -1.4892e+00],\n",
      "          ...,\n",
      "          [-2.0174e+00, -1.3220e+00, -1.3034e+00,  ..., -1.9895e+00,\n",
      "           -1.9477e+00, -1.8978e+00],\n",
      "          [-1.9863e+00, -1.8592e+00, -1.8159e+00,  ..., -1.9176e+00,\n",
      "           -1.9219e+00, -1.9614e+00],\n",
      "          [-1.8847e+00, -1.9808e+00, -1.9679e+00,  ..., -1.9876e+00,\n",
      "           -1.9419e+00, -1.7226e+00]],\n",
      "\n",
      "         [[-1.2601e+00, -1.1737e+00, -1.1977e+00,  ..., -1.4999e+00,\n",
      "           -1.3002e+00, -1.3106e+00],\n",
      "          [-1.3983e+00, -1.3545e+00, -1.3739e+00,  ..., -1.1880e+00,\n",
      "           -1.2349e+00, -1.2973e+00],\n",
      "          [-1.2091e+00, -1.0769e+00, -1.2119e+00,  ..., -1.0989e+00,\n",
      "           -1.2774e+00, -1.3946e+00],\n",
      "          ...,\n",
      "          [-1.8633e+00, -7.5733e-01, -1.0014e+00,  ..., -1.8246e+00,\n",
      "           -1.8002e+00, -1.7644e+00],\n",
      "          [-1.9722e+00, -1.4547e+00, -1.6938e+00,  ..., -1.8916e+00,\n",
      "           -1.8505e+00, -1.7371e+00],\n",
      "          [-1.9396e+00, -1.6823e+00, -1.7453e+00,  ..., -1.8495e+00,\n",
      "           -1.8461e+00, -1.6034e+00]],\n",
      "\n",
      "         [[-1.3863e+00, -1.2512e+00, -1.2545e+00,  ..., -1.4697e+00,\n",
      "           -1.3205e+00, -1.3434e+00],\n",
      "          [-1.4299e+00, -1.4144e+00, -1.4190e+00,  ..., -1.3382e+00,\n",
      "           -1.3488e+00, -1.4751e+00],\n",
      "          [-1.2199e+00, -1.1736e+00, -1.2137e+00,  ..., -1.1981e+00,\n",
      "           -1.3188e+00, -1.3238e+00],\n",
      "          ...,\n",
      "          [-1.4797e+00, -6.0711e-01, -8.5774e-01,  ..., -1.7506e+00,\n",
      "           -1.6985e+00, -1.6290e+00],\n",
      "          [-1.5807e+00, -1.3769e+00, -1.5755e+00,  ..., -1.7343e+00,\n",
      "           -1.7280e+00, -1.7147e+00],\n",
      "          [-1.7048e+00, -1.4922e+00, -1.7228e+00,  ..., -1.7666e+00,\n",
      "           -1.6426e+00, -1.5812e+00]]],\n",
      "\n",
      "\n",
      "        [[[-5.8288e-01, -7.7240e-01, -1.5221e-01,  ..., -5.4548e-01,\n",
      "           -8.5510e-01, -7.7862e-01],\n",
      "          [-8.3953e-01, -8.6923e-01, -3.8709e-01,  ..., -4.7214e-01,\n",
      "           -8.0931e-01, -9.9052e-01],\n",
      "          [-9.8637e-01, -1.1073e+00, -9.5050e-01,  ..., -3.7788e-01,\n",
      "           -6.6794e-01, -9.5855e-01],\n",
      "          ...,\n",
      "          [ 5.0351e-01,  4.5392e-01,  8.3289e-02,  ...,  6.5421e-01,\n",
      "            5.1251e-01,  4.9017e-01],\n",
      "          [ 5.4183e-01,  3.4892e-01,  1.1172e-03,  ...,  3.6062e-01,\n",
      "            3.4508e-01,  2.3329e-01],\n",
      "          [ 5.1381e-01,  1.2174e-02, -8.5117e-01,  ..., -3.3501e-01,\n",
      "           -3.4461e-01, -3.1772e-01]],\n",
      "\n",
      "         [[-8.6589e-01, -7.0261e-01, -2.2021e-01,  ..., -8.9333e-01,\n",
      "           -8.7552e-01, -8.6318e-01],\n",
      "          [-9.9206e-01, -8.9887e-01, -2.2757e-01,  ..., -6.3225e-01,\n",
      "           -8.2443e-01, -1.1412e+00],\n",
      "          [-1.0829e+00, -1.0444e+00, -9.9397e-01,  ..., -5.8511e-01,\n",
      "           -8.1318e-01, -1.0174e+00],\n",
      "          ...,\n",
      "          [ 3.8142e-01, -8.2922e-02, -6.4541e-01,  ...,  4.5721e-01,\n",
      "            4.3958e-01,  4.6035e-01],\n",
      "          [ 3.0664e-01, -2.6879e-02, -5.6567e-01,  ...,  3.4688e-01,\n",
      "            3.4373e-01,  2.3851e-01],\n",
      "          [ 3.7588e-01,  4.3680e-02, -7.9574e-01,  ..., -5.9276e-01,\n",
      "           -4.3011e-01, -5.3093e-01]],\n",
      "\n",
      "         [[-1.0144e-01, -1.9271e-01,  2.9920e-01,  ..., -7.0616e-01,\n",
      "           -7.8105e-01, -6.1406e-01],\n",
      "          [-4.8245e-01, -3.2450e-01,  3.0116e-01,  ..., -6.7416e-01,\n",
      "           -8.8463e-01, -9.1002e-01],\n",
      "          [-7.9109e-01, -5.5070e-01, -4.1127e-01,  ..., -5.2003e-01,\n",
      "           -6.9857e-01, -7.9258e-01],\n",
      "          ...,\n",
      "          [ 4.1998e-01,  3.1191e-02, -5.5189e-01,  ...,  5.2827e-01,\n",
      "            5.1611e-01,  5.2586e-01],\n",
      "          [ 4.7571e-01,  1.5528e-02, -6.5123e-01,  ...,  4.5038e-01,\n",
      "            4.0980e-01,  4.6924e-01],\n",
      "          [ 4.2288e-01,  8.4568e-02, -7.9080e-01,  ..., -3.2511e-01,\n",
      "           -3.5331e-01, -2.6410e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.9880e-01, -8.1797e-01, -6.5372e-01,  ...,  1.9743e+00,\n",
      "            2.0711e+00,  1.9791e+00],\n",
      "          [-3.2558e-01, -7.2860e-01, -6.9525e-01,  ...,  2.0746e+00,\n",
      "            1.9881e+00,  2.0522e+00],\n",
      "          [-2.3816e-01, -6.3235e-01, -5.5532e-01,  ...,  1.9422e+00,\n",
      "            1.8896e+00,  1.9099e+00],\n",
      "          ...,\n",
      "          [ 9.2142e-01,  4.9601e-01,  3.6921e-02,  ...,  2.4221e-01,\n",
      "            4.3970e-01,  3.3979e-01],\n",
      "          [ 1.0180e+00,  9.1156e-01,  5.9182e-01,  ...,  4.9538e-01,\n",
      "            6.1161e-01,  8.0517e-01],\n",
      "          [ 7.8724e-01,  8.6381e-01,  5.3237e-01,  ...,  3.8588e-01,\n",
      "            5.0954e-01,  3.0399e-01]],\n",
      "\n",
      "         [[-4.8119e-01, -8.1520e-01, -6.0681e-01,  ...,  1.9646e+00,\n",
      "            2.0200e+00,  1.8983e+00],\n",
      "          [-4.5857e-01, -7.9713e-01, -6.4419e-01,  ...,  1.8449e+00,\n",
      "            1.9000e+00,  1.8815e+00],\n",
      "          [-2.6320e-01, -7.5046e-01, -5.9390e-01,  ...,  1.9485e+00,\n",
      "            2.0731e+00,  1.9735e+00],\n",
      "          ...,\n",
      "          [ 6.8546e-01,  2.1843e-01, -9.4663e-03,  ...,  2.9482e-02,\n",
      "            1.6457e-01,  1.4773e-01],\n",
      "          [ 6.2104e-01,  4.4815e-01,  3.3768e-01,  ...,  1.9637e-01,\n",
      "            4.6582e-01,  5.2372e-01],\n",
      "          [ 4.8471e-01,  3.3187e-01,  2.3288e-01,  ...,  1.9498e-01,\n",
      "            2.9539e-01,  1.8761e-01]],\n",
      "\n",
      "         [[-4.4573e-01, -5.9965e-01, -5.5719e-01,  ...,  1.5759e+00,\n",
      "            1.5379e+00,  1.6625e+00],\n",
      "          [-3.8017e-01, -7.5307e-01, -5.4275e-01,  ...,  1.5738e+00,\n",
      "            1.5780e+00,  1.5227e+00],\n",
      "          [-3.2858e-01, -6.5437e-01, -4.0942e-01,  ...,  1.6197e+00,\n",
      "            1.5519e+00,  1.5585e+00],\n",
      "          ...,\n",
      "          [-4.0776e-02, -3.1377e-01, -3.7776e-01,  ..., -1.0010e+00,\n",
      "           -9.1567e-01, -8.4615e-01],\n",
      "          [-8.5237e-03,  6.1317e-02, -3.2521e-02,  ..., -1.0433e+00,\n",
      "           -1.0015e+00, -8.8146e-01],\n",
      "          [-1.0360e-01, -3.5003e-02, -1.8949e-01,  ..., -7.0758e-01,\n",
      "           -8.4504e-01, -7.2384e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.5043e-01, -6.1619e-01, -6.9664e-01,  ..., -7.3864e-01,\n",
      "           -6.3261e-01, -6.4184e-01],\n",
      "          [-5.9652e-01, -8.1792e-01, -6.7859e-01,  ..., -4.0871e-01,\n",
      "           -2.8911e-01, -3.7846e-01],\n",
      "          [-3.8114e-01, -8.5540e-01, -6.3248e-01,  ..., -3.5745e-01,\n",
      "           -2.5070e-01, -3.1938e-01],\n",
      "          ...,\n",
      "          [ 1.3779e+00,  1.1356e+00,  1.1161e+00,  ..., -5.0180e-01,\n",
      "            3.5473e-01,  3.0914e-01],\n",
      "          [ 1.1710e+00,  1.0312e+00,  1.1519e+00,  ..., -1.3137e-01,\n",
      "            8.4827e-02,  1.4530e-01],\n",
      "          [ 9.6516e-01,  9.5532e-01,  1.0903e+00,  ...,  2.1378e-02,\n",
      "            2.1870e-01,  1.0733e-01]],\n",
      "\n",
      "         [[ 4.7634e-01,  1.1542e-01,  3.5827e-01,  ...,  8.4972e-03,\n",
      "            2.2212e-01,  3.6415e-02],\n",
      "          [ 3.1161e-01, -1.4391e-01,  2.4248e-01,  ...,  3.3012e-01,\n",
      "            4.6758e-01,  8.1859e-02],\n",
      "          [ 3.9273e-01, -3.0883e-02,  1.9314e-01,  ...,  4.3246e-01,\n",
      "            5.7422e-01,  1.4624e-01],\n",
      "          ...,\n",
      "          [ 9.5473e-01,  7.4425e-01,  7.1001e-01,  ..., -2.2481e-01,\n",
      "            4.5244e-01,  4.3766e-01],\n",
      "          [ 7.9033e-01,  6.0133e-01,  7.3516e-01,  ...,  3.8172e-01,\n",
      "            6.1052e-01,  6.4757e-01],\n",
      "          [ 6.3696e-01,  5.8634e-01,  5.7963e-01,  ...,  4.9326e-01,\n",
      "            6.4815e-01,  7.5464e-01]],\n",
      "\n",
      "         [[-8.2207e-01, -9.3881e-01, -1.0378e+00,  ..., -8.4572e-01,\n",
      "           -7.4652e-01, -7.7382e-01],\n",
      "          [-9.3290e-01, -1.0519e+00, -8.5802e-01,  ..., -6.5496e-01,\n",
      "           -4.7393e-01, -6.8803e-01],\n",
      "          [-8.2582e-01, -9.2315e-01, -6.6324e-01,  ..., -5.3292e-01,\n",
      "           -4.5715e-01, -4.7687e-01],\n",
      "          ...,\n",
      "          [ 6.9899e-01,  4.3432e-01,  3.6382e-01,  ..., -3.5858e-01,\n",
      "            2.4875e-01,  1.9959e-01],\n",
      "          [ 5.5318e-01,  3.8884e-01,  4.0375e-01,  ..., -3.1778e-01,\n",
      "           -5.2152e-02, -9.7483e-03],\n",
      "          [ 4.6610e-01,  3.0247e-01,  4.0960e-01,  ..., -2.2806e-01,\n",
      "           -7.5538e-02,  1.8714e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5486e-01,  4.0605e-01,  5.7272e-01,  ...,  3.8779e-01,\n",
      "            4.3285e-01,  4.0492e-01],\n",
      "          [ 4.7965e-01,  4.8873e-01,  6.0338e-01,  ...,  5.1345e-01,\n",
      "            4.8257e-01,  5.0629e-01],\n",
      "          [ 5.1543e-01,  4.7542e-01,  6.0836e-01,  ...,  4.8362e-01,\n",
      "            5.1502e-01,  5.6794e-01],\n",
      "          ...,\n",
      "          [-6.7326e-01, -7.0691e-01, -6.2892e-01,  ..., -7.9353e-01,\n",
      "           -6.7862e-01, -7.8260e-01],\n",
      "          [-6.3980e-01, -5.9288e-01, -6.9217e-01,  ..., -6.7534e-01,\n",
      "           -6.5348e-01, -7.1069e-01],\n",
      "          [-6.9492e-01, -7.5519e-01, -7.2540e-01,  ..., -8.4970e-01,\n",
      "           -7.5286e-01, -7.1070e-01]],\n",
      "\n",
      "         [[ 7.1068e-01,  6.8715e-01,  7.0417e-01,  ...,  6.5949e-01,\n",
      "            6.7454e-01,  7.3939e-01],\n",
      "          [ 7.1955e-01,  7.4605e-01,  6.8300e-01,  ...,  7.1180e-01,\n",
      "            7.5327e-01,  8.0847e-01],\n",
      "          [ 8.2885e-01,  7.2980e-01,  7.9829e-01,  ...,  7.1368e-01,\n",
      "            7.6363e-01,  7.8748e-01],\n",
      "          ...,\n",
      "          [-2.6498e-01, -3.0518e-01, -3.6250e-01,  ..., -3.9593e-01,\n",
      "           -3.8518e-01, -3.8101e-01],\n",
      "          [-1.6342e-01, -2.5497e-01, -2.3921e-01,  ..., -4.0609e-01,\n",
      "           -3.6873e-01, -3.9155e-01],\n",
      "          [-3.1479e-01, -4.2470e-01, -3.0248e-01,  ..., -3.2718e-01,\n",
      "           -3.5677e-01, -2.6999e-01]],\n",
      "\n",
      "         [[ 9.4277e-01,  9.9439e-01,  8.9870e-01,  ...,  8.9329e-01,\n",
      "            9.7296e-01,  9.4331e-01],\n",
      "          [ 9.8602e-01,  9.9668e-01,  9.7074e-01,  ...,  9.6066e-01,\n",
      "            1.0251e+00,  9.8845e-01],\n",
      "          [ 9.7069e-01,  9.9947e-01,  1.0168e+00,  ...,  9.0867e-01,\n",
      "            9.4567e-01,  9.4089e-01],\n",
      "          ...,\n",
      "          [ 1.2064e-01,  7.9541e-02,  8.7752e-02,  ..., -4.6138e-02,\n",
      "           -4.4066e-02, -4.5187e-02],\n",
      "          [ 1.3676e-01,  4.7352e-02,  1.1909e-01,  ...,  6.7197e-02,\n",
      "           -3.2668e-02,  9.1073e-02],\n",
      "          [ 1.7742e-01, -1.8787e-02,  8.1775e-02,  ..., -6.3224e-02,\n",
      "            1.1711e-02,  3.2050e-02]]]]), 'x2': tensor([[-0.1858, -0.1566,  0.0221,  ...,  1.7056,  1.6274,  1.8562],\n",
      "        [-1.5169, -1.3824, -1.3182,  ..., -1.5861, -1.2735, -1.5137],\n",
      "        [-0.5829, -0.7724, -0.1522,  ..., -0.5455, -0.8551, -0.7786],\n",
      "        ...,\n",
      "        [-0.4988, -0.8180, -0.6537,  ...,  1.9743,  2.0711,  1.9791],\n",
      "        [-0.5504, -0.6162, -0.6966,  ..., -0.7386, -0.6326, -0.6418],\n",
      "        [ 0.4549,  0.4060,  0.5727,  ...,  0.3878,  0.4329,  0.4049]])}, 'target': {'y': tensor([7, 9, 7, 1, 6, 3, 6, 3, 3, 5, 3, 1, 0, 3, 3, 0, 5, 0, 1, 9, 8, 4, 5, 0,\n",
      "        4, 9, 9, 1, 7, 1, 5, 5, 1, 2, 9, 2, 0, 9, 7, 9, 6, 0, 6, 7, 5, 8, 9, 3,\n",
      "        8, 3, 2, 8, 0, 8, 2, 0, 3, 5, 3, 1, 0, 2, 1, 2, 4, 7, 8, 3, 3, 3, 5, 9,\n",
      "        6, 7, 8, 4, 8, 6, 2, 3, 4, 8, 8, 1, 5, 9, 4, 4, 6, 6, 5, 3, 4, 4, 9, 9,\n",
      "        9, 0, 3, 7, 0, 9, 9, 9, 6, 1, 7, 6, 3, 9, 7, 1, 9, 2, 4, 4, 9, 2, 8, 8,\n",
      "        6, 2, 6, 7, 4, 1, 4, 6, 2, 2, 8, 8, 8, 2, 8, 4, 6, 0, 8, 6, 4, 1, 7, 2,\n",
      "        3, 9, 1, 6, 5, 4, 0, 1, 4, 9, 4, 5, 6, 2, 8, 5, 0, 7, 5, 4, 8, 4, 6, 7,\n",
      "        1, 9, 5, 9, 5, 1, 3, 7, 2, 8, 4, 6, 9, 7, 9, 3, 6, 0, 3, 6, 8, 1, 0, 1,\n",
      "        1, 2, 7, 2, 0, 4, 7, 6, 8, 6, 4, 6, 5, 0, 8, 2, 6, 7, 0, 7, 9, 0, 0, 4,\n",
      "        6, 6, 0, 9, 4, 1, 2, 0, 6, 5, 4, 9, 6, 4, 0, 3, 2, 6, 4, 4, 5, 9, 1, 4,\n",
      "        4, 9, 5, 9, 1, 3, 9, 5, 6, 3, 4, 6, 6, 4, 4, 8]), 'y2': tensor([[7],\n",
      "        [9],\n",
      "        [7],\n",
      "        [1],\n",
      "        [6],\n",
      "        [3],\n",
      "        [6],\n",
      "        [3],\n",
      "        [3],\n",
      "        [5],\n",
      "        [3],\n",
      "        [1],\n",
      "        [0],\n",
      "        [3],\n",
      "        [3],\n",
      "        [0],\n",
      "        [5],\n",
      "        [0],\n",
      "        [1],\n",
      "        [9],\n",
      "        [8],\n",
      "        [4],\n",
      "        [5],\n",
      "        [0],\n",
      "        [4],\n",
      "        [9],\n",
      "        [9],\n",
      "        [1],\n",
      "        [7],\n",
      "        [1],\n",
      "        [5],\n",
      "        [5],\n",
      "        [1],\n",
      "        [2],\n",
      "        [9],\n",
      "        [2],\n",
      "        [0],\n",
      "        [9],\n",
      "        [7],\n",
      "        [9],\n",
      "        [6],\n",
      "        [0],\n",
      "        [6],\n",
      "        [7],\n",
      "        [5],\n",
      "        [8],\n",
      "        [9],\n",
      "        [3],\n",
      "        [8],\n",
      "        [3],\n",
      "        [2],\n",
      "        [8],\n",
      "        [0],\n",
      "        [8],\n",
      "        [2],\n",
      "        [0],\n",
      "        [3],\n",
      "        [5],\n",
      "        [3],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [4],\n",
      "        [7],\n",
      "        [8],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [5],\n",
      "        [9],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [4],\n",
      "        [8],\n",
      "        [6],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [8],\n",
      "        [8],\n",
      "        [1],\n",
      "        [5],\n",
      "        [9],\n",
      "        [4],\n",
      "        [4],\n",
      "        [6],\n",
      "        [6],\n",
      "        [5],\n",
      "        [3],\n",
      "        [4],\n",
      "        [4],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [0],\n",
      "        [3],\n",
      "        [7],\n",
      "        [0],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [1],\n",
      "        [7],\n",
      "        [6],\n",
      "        [3],\n",
      "        [9],\n",
      "        [7],\n",
      "        [1],\n",
      "        [9],\n",
      "        [2],\n",
      "        [4],\n",
      "        [4],\n",
      "        [9],\n",
      "        [2],\n",
      "        [8],\n",
      "        [8],\n",
      "        [6],\n",
      "        [2],\n",
      "        [6],\n",
      "        [7],\n",
      "        [4],\n",
      "        [1],\n",
      "        [4],\n",
      "        [6],\n",
      "        [2],\n",
      "        [2],\n",
      "        [8],\n",
      "        [8],\n",
      "        [8],\n",
      "        [2],\n",
      "        [8],\n",
      "        [4],\n",
      "        [6],\n",
      "        [0],\n",
      "        [8],\n",
      "        [6],\n",
      "        [4],\n",
      "        [1],\n",
      "        [7],\n",
      "        [2],\n",
      "        [3],\n",
      "        [9],\n",
      "        [1],\n",
      "        [6],\n",
      "        [5],\n",
      "        [4],\n",
      "        [0],\n",
      "        [1],\n",
      "        [4],\n",
      "        [9],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [2],\n",
      "        [8],\n",
      "        [5],\n",
      "        [0],\n",
      "        [7],\n",
      "        [5],\n",
      "        [4],\n",
      "        [8],\n",
      "        [4],\n",
      "        [6],\n",
      "        [7],\n",
      "        [1],\n",
      "        [9],\n",
      "        [5],\n",
      "        [9],\n",
      "        [5],\n",
      "        [1],\n",
      "        [3],\n",
      "        [7],\n",
      "        [2],\n",
      "        [8],\n",
      "        [4],\n",
      "        [6],\n",
      "        [9],\n",
      "        [7],\n",
      "        [9],\n",
      "        [3],\n",
      "        [6],\n",
      "        [0],\n",
      "        [3],\n",
      "        [6],\n",
      "        [8],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [7],\n",
      "        [2],\n",
      "        [0],\n",
      "        [4],\n",
      "        [7],\n",
      "        [6],\n",
      "        [8],\n",
      "        [6],\n",
      "        [4],\n",
      "        [6],\n",
      "        [5],\n",
      "        [0],\n",
      "        [8],\n",
      "        [2],\n",
      "        [6],\n",
      "        [7],\n",
      "        [0],\n",
      "        [7],\n",
      "        [9],\n",
      "        [0],\n",
      "        [0],\n",
      "        [4],\n",
      "        [6],\n",
      "        [6],\n",
      "        [0],\n",
      "        [9],\n",
      "        [4],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [6],\n",
      "        [5],\n",
      "        [4],\n",
      "        [9],\n",
      "        [6],\n",
      "        [4],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [6],\n",
      "        [4],\n",
      "        [4],\n",
      "        [5],\n",
      "        [9],\n",
      "        [1],\n",
      "        [4],\n",
      "        [4],\n",
      "        [9],\n",
      "        [5],\n",
      "        [9],\n",
      "        [1],\n",
      "        [3],\n",
      "        [9],\n",
      "        [5],\n",
      "        [6],\n",
      "        [3],\n",
      "        [4],\n",
      "        [6],\n",
      "        [6],\n",
      "        [4],\n",
      "        [4],\n",
      "        [8]])}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1929) tensor(2.3281)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64 - id: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64\n",
      "[xentropy]\n",
      " - opt-parameters: 117,072[p] - device: cpu\n",
      " - save-mode: only_sup_metric(target_metric_crit: accuracy)\n",
      " - counter_k: k(0/0) - counter_epoch: val_epoch(0/1)»earlystop_epoch(0/21)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 0/196000 [00:33, ?it/s, id: 0 - epoch: 0/1,000(144/196)[xentropy] __loss__: 1.67(loss/2=.84/loss/3=.56) #.145[segs]]"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' # see issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' # CPU\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import XEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = XEntropy('xentropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "### GET MODEL\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "### MONITORS\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "from fuzzytorch import C_\n",
    "\n",
    "monitor_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':1e2,\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **monitor_config)\n",
    "\n",
    "### TRAIN\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_time_util_convergence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['opt_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['loss_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['metrics_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from flamingchoripan.counters import Counter\n",
    "\n",
    "d = {\n",
    "'val_epoch_counter_duration':1,\n",
    "'earlystop_epoch_duration':5,\n",
    "}\n",
    "c = Counter(d)\n",
    "for _ in range(50):\n",
    "    print(c, c.check('earlystop_epoch_duration'))\n",
    "    c.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
