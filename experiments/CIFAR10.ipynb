{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': (3, 32, 32)-float32-cpu, 'x2': (32)-float32-cpu}, 'target': {'y': ()-int64-cpu, 'y2': (1)-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': (256, 3, 32, 32)-float32-cpu, 'x2': (256, 32)-float32-cpu}, 'target': {'y': (256)-int64-cpu, 'y2': (256, 1)-int64-cpu}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1560) tensor(2.3196)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXLElEQVR4nO3dfZRdVXnH8e+PJCQhCeSVEEMkIQYxIgY6UkrRUgUEVtdCa0vBFmlrG5eVtrZayqIsoV2uFqig9g2NhQLWgiBQxdJKTFmgVoEBIQkkhRAGkpCXyXsIkDCZp3/cm3ZCzz4zc19nsn+ftbJyZz93n/PMnXnmnHv2PXsrIjCzg98h7U7AzFrDxW6WCRe7WSZc7GaZcLGbZcLFbpYJF7tZJlzsw5SkLklntnH/t0j6/CD7nCbpUUm7JC2VdHqz8rP/z8WeKUkjWry/ycB9wF8DE4HrgPskTWplHjlzsQ9Dkr4OvJVKsbwi6bJq+12SNkjaIelhSe/s0+cWSTdKul/SbuAXJU2RdJ+knZIek/R5ST/s0+d4SYslbZX035IuqLYvBH4duKy6//sGkPZpwIaIuCsi9kXEPwPdwC837IWxUiPbnYANXkRcLOm9wO9ExPf7hP4d+G1gL3At8A1gQZ/4R4HzgF8CDgVuAXYDRwGzge8BLwJIGgcsBj4HnAu8C1gsaXlELJJ0GrA2Iq7cv3FJ/1DN7/cSqavg6xMG871b7XxkP4hExM0RsSsi9gBXA++WdESfp3w7In4UEb3AG8BHgKsi4tWIeAa4tc9zfwnoioh/ioieiPgpcDfwqyX7/72SQv8x8BZJF0kaJekSYC5wWK3frw2Oi/0gIWmEpGskPS9pJ9BVDU3t87Q1fR5Po3JmtyYRPwb4WUnb9/+jcup+VC35RcQW4Hzgj4GNwDnA94G1tWzPBs+n8cPXm29X/CiVYjqTSqEfAWzjwFPnvn26gR7gaODZatusPvE1wEMRcdYA999/whEPAe8BkDQSWA1cP9jtWG18ZB++NgLH9vl6ArAH2ELl1PgvyzpHxD7gHuBqSYdJOh74WJ+nfBc4TtLF1dPuUZLeI+kdif33S9JJ1e0cDnwBWBMR3xvMNqx2Lvbh66+AK6un2J8FbqNycW0d8AzwkwFs41IqZwAbgK8Dt1P5g0FE7ALOBi4EXq4+51pgdLXvTcD86v7/FUDSVyR9pWR/lwGbqZw1zAA+PODv1uomT15h+0m6FjgqIi5pdy7WeD6yZ6w6jn6iKk4BPg7c2+68rDl8gS5vE6icur+Fynvw64FvtzUjaxqfxptlwqfxZplo6Wn81KlTY/bs2a3cpdnwtbckdmhxc1dXF5s3b37zx5KBOotd0jnAl4ERwD9GxDVlz589ezadnZ317NJscHoT7cPgnDZeTMd0THF7R0dHsk/N33L1Fsm/p3KTxHzgIknza92emTVXPX/fTgFWRcTqiNgL3EHl45pmNgTVU+wzOfDGibXVtgNIWiipU1Jnd3d3Hbszs3o0/Z1LRCyKiI6I6Jg2bVqzd2dmCfUU+zoOvEvq6GqbmQ1B9VyNfwyYJ2kOlSK/kMptlmZDxzC46p4SJTMHFI6t9aPmYo+IHkmXUpnKaARwc0Q8Xev2zKy56hpnj4j7gfsblIuZNdEwPskxs8FwsZtlwsVulgkXu1kmPHnFQWbrq8Xtq+9Pz1uwcuYLydiFHek5JUeOGnBaVoMdXenYpLcPfns+sptlwsVulgkXu1kmXOxmmXCxm2XCV+OHqBNP/VIytuyRP2pZHheXRg8vif1OYesFly0obAf45rXle8tN1/Z0bFIN2/OR3SwTLnazTLjYzTLhYjfLhIvdLBMudrNMeOitAXpfScdGTPiFkp4PNzyX1tpZEruhsPXO69I97rzuY8nYSR9bnIw9ceuZJXkMXydN6SmJDr50fWQ3y4SL3SwTLnazTLjYzTLhYjfLhIvdLBMeehuEj37krsL22++5oMWZ5Oent52VjOm2dL8/vOp7he2fv/rsZJ/xJXncvfiRZOzkD/xsMjanpsPq7mRkH0cMemt1FbukLmAXsA/oiYiOerZnZs3TiCP7L0bE5gZsx8yayO/ZzTJRb7EH8ICkxyUtLHqCpIWSOiV1dnd317k7M6tVvcV+ekScDJwLfErS+978hIhYFBEdEdExbdq0OndnZrWqq9gjYl31/03AvcApjUjKzBpPEellgUo7SuOAQyJiV/XxYuAvIuI/Un06Ojqis7OztkxbROMuSgdfvaN1iVjbnP2h9ISeD/zrF2vc6pElMSXaXyvpk77jMCIKN1jP1fjpwL2S9m/nX8oK3czaq+Zij4jVwLsbmIuZNZGH3swy4WI3y4SL3SwTLnazTGR511t1BMEOGmVrzqV+1scke9Q+vFZmUxO2OTg+sptlwsVulgkXu1kmXOxmmXCxm2XioL0aL41qdwrWMmXLUKUsbXgWQ52P7GaZcLGbZcLFbpYJF7tZJlzsZplwsZtlYlgPvfmGlqHsqET7hpZmkfbOkljZ3G+rG51Iy/jIbpYJF7tZJlzsZplwsZtlwsVulgkXu1kmal7+qRZHHTkrLvlI8dI6z7y0Jdnvu/f/ZbNSsrocm4zM6vhcYfuazk+WbK9k6S1+UBKbURLbUdw88/R0l3V3l2xvqAwdpqWWf+r3yC7pZkmbJC3v0zZZ0mJJz1X/n9TIZM2s8QZyGn8LcM6b2i4HlkTEPGBJ9WszG8L6LfaIeBjY+qbm84Fbq49vBT7U4LzMrMFqvUA3PSLWVx9voLKiayFJCyV1Sup87bXdNe7OzOpV99X4qFzhS17li4hFEdERER1jx46rd3dmVqNai32jpBkA1f/bv9yFmZUa0NCbpNnAdyPihOrXfw1siYhrJF0OTI6IywawndaN82XqirteLGz/8mVXJvvsfuHrNe1rNL+cjO1JvrN7uWSLZUNoy9KhMe9Ox15P/cqVnWV+oSQ29NUz9HY78GPg7ZLWSvo4cA1wlqTngDOrX5vZENbv/ewRkfqkwwcanIuZNZE/LmuWCRe7WSZc7GaZcLGbZaKld72NlWI2xZNEviPRDvBf9Ba2H82hyT497E3GJjA2Geso+fv3JYb+JwCXJH6eq/5qbbLPJ66YVePe5pfERifay9Zle6UkdkJJrGxdv9TdlLtK+qwsiQ19NQ+9mdnBwcVulgkXu1kmXOxmmXCxm2XCxW6WiZYOvY2R4uhUIiX91iXaDyvpk56+8uD26UXFP89zT0r3+eB7vGbe8DM50b6DiB4PvZnlzMVulgkXu1kmXOxmmXCxm2WipVfjR0oxIRHb3rIsDm6nnlE8f9qPH/xMso9UdpPJ03VmZP255F2/Wdj+rWW3JPuMpHjevVd4lp541VfjzXLmYjfLhIvdLBMudrNMuNjNMuFiN8tES4fevPxT+0yZlV7TY+v69Hx90fODZqSTobOTkX/6kz8rbH9lx/3JPlfc9MPC9t37nmRfvFLz8k83S9okaXmftqslrZP0ZPXfef1tx8zaayCn8bcA5xS0fzEiFlT/pf8EmdmQ0G+xR8TDwNYW5GJmTVTPBbpLJS2tnuZPSj1J0kJJnZI669iXmdWp1mK/EZgLLADWA9ennhgRiyKiIyI6atyXmTVATcUeERsjYl9E9AJfA05pbFpm1mj9rs9eRNKMiFhf/fLDwPKy51v7bVmzpKX7mza6eKjp2BnHJfs80vV3zUpnCFiTjDzw2N8Wtm9avSPZZ9fok4sDrz+X7NNvsUu6HTgDmCppLXAVcIakBUAAXcAn+tuOmbVXv8UeERcVNN/UhFzMrIn8cVmzTLjYzTLhYjfLhIvdLBM1Db3ZUHZoov3Mkj4/Komlh3/KnPHBouu6cNd3/iDZZ84vFA9BAbzw0O/XlMdQcQjjkrHZC36rsH3y8Q8k+yx5ZH1xYOUbJTmYWRZc7GaZcLGbZcLFbpYJF7tZJlzsZpnw0NtwdMj7k6Epc88tbD/xZ2Yl+zz4wInpfW29ZsBp9bVxRGqoaVeyT8/2kmG+93wyHXvsxoEl1Ua9rE7G3nba44XtR66ck+zz1edXFbb37OlN9vGR3SwTLnazTLjYzTLhYjfLhIvdLBO+Gt8AJdeyWdqE/f3npROSsXjnysL2Mcc/kezzaz9YloytHXhaB3j43gsG3WfNU1eWRP+0JDajJLYp0T6mpM/uklit0ksvbN5U/Bv0eHd3sk/PIYmYfCOMWfZc7GaZcLGbZcLFbpYJF7tZJlzsZpkYyIows4DbgOlUVoBZFBFfljQZ+CYwm8qqMBdExLbmpdp+vza3uP2G+25N9pk5/5KG5/H+v/n2oPvc87vp2Np1dSTTMtc2eHvNGF6rzbM/KR7gHLf19XSn3YmFk3vTJT2QI3sP8JmImA+cCnxK0nzgcmBJRMwDllS/NrMhqt9ij4j1EfFE9fEuYAUwEzgf2H9IuxX4ULOSNLP6Deo9u6TZwEnAI8D0Piu5bqBymm9mQ9SAPy4raTxwN/DpiNgp6X9jERGSItFvIbCw3kTNrD4DOrJLGkWl0L8REfdUmzdKmlGNzyDxIeSIWBQRHRHR0YiEzaw2/Ra7Kofwm4AVEXFDn9B3gP2Xmi8BBn+J2MxaRhGFZ9//9wTpdOAHwDJg/wRXV1B5334n8FbgRSpDb+lbeyrbKt+Z2TA27YjzkrHNO7YkY+f91q8Wtm+457+SfR6fMr44sPbfiD2bVRTq9z17RPwQKOwMfKC//mY2NPgTdGaZcLGbZcLFbpYJF7tZJlzsZpnwhJNmDfLHnz0mGXvw9vRxdefKVwvbp88smUhzS2IizV4v/2SWPRe7WSZc7GaZcLGbZcLFbpYJF7tZJlo69HbMtJlcdcGlhbHXZ70r2e/w7uLJAZ9a15Xsc/MdtyRjW1iRjJnVapvSkzU9PS615hyc9/aJhe1nHpeuifuv+/fiQIxI9vGR3SwTLnazTLjYzTLhYjfLhIvdLBMtvRrfvaeXf1hd/KH/qV2rk/1e2/5aYfvYTUck+5x43EXJ2IPPfi4Za6Wn/uihZGzLO05Ixr76aHpuz6cfLV5KaPnSW0oySb/2w56KR3+Iv2v4rr505dPJ2F6eS8aemVc88fL0lcU/SwBmJJaGej09zaOP7GaZcLGbZcLFbpYJF7tZJlzsZplwsZtlYiDLP80CbqOyJHMAiyLiy5KuBn4X6K4+9YqIuL+fbXn5Jxvm3lsS21YS605GZp1avMjxjg1Lkn12vpwYdn7jR0TvjtqWfwJ6gM9ExBOSJgCPS1pcjX0xIr4wgG2YWZsNZK239cD66uNdklYAM5udmJk11qDes0uaDZxEZQVXgEslLZV0s6RJDc7NzBpowMUuaTxwN/DpiNgJ3AjMBRZQOfJfn+i3UFKnpM4G5GtmNRpQsUsaRaXQvxER9wBExMaI2BcRvcDXgFOK+kbEoojoiIjiDwCbWUv0W+ySBNwErIiIG/q0912u4sPA8sanZ2aNMpCr8T8PXAwsk/Rkte0K4CJJC6gMx3UBn+hvQxPHHskZ8369MPbo0q5kv5f5fiKyq79dmg3aSI5Oxk6Ylp7j7blp6TsVJ3XvScamJAak13SV/X6n5rtLH78HcjX+h0DRuF3pmLqZDS3+BJ1ZJlzsZplwsZtlwsVulgkXu1kmWjrh5IhemLhnX2Fs7nGzkv2mvPEzhe07tqUn8du8vXg/AHvZkIyNYl4yNnlM8TJUe18fnewzZlI6j3nbXknGto08Lhk7dGR6+Gf3W+cWt+9JTyr5wqbiCT0BeO3xdKzU2ER7YqJEANITiML2BufRk+zRUxJ7qTt94+bJHcW/HwBbXk732zpla3FgavrnzOZliUD6Z+kju1kmXOxmmXCxm2XCxW6WCRe7WSZc7GaZ6HfCyUYaM3ZizJpzRmFs1YodyX7jE0Nlr5QMocHOklhvSezIklhiiKRkqKZ2E0piZTnOT7Q/UdKnbFgrPZwEU0piqeNIyTAfh5fE5pTEyn6Hi9cWhOdL+pR9X2X5byyJlTjpNwubjxyxJdllU2dqcssnidhVOOGkj+xmmXCxm2XCxW6WCRe7WSZc7GaZcLGbZaKld73teb2XVStSQzmHJfv1JO9cSt81NqJkeGoaJydjG3g2GYNDE+1lfzPLhq7ekowcXrLNnawo2WZqSOmdNeVRfpda6ucCU9hb2L6F9B2CExmfjG0vWSsNJpfEiod0DylZ1Kh3XPp3Z+7Y9DDl85vLXqv00DIvFf8ej5pU9ruTeh0LR90AH9nNsuFiN8uEi90sEy52s0y42M0y0e+NMJLGAA9Tufw3EvhWRFwlaQ5wB5W7Bh4HLo6I4kuwVaM0NaZyfmFsA6tKehZfpT2y5ErxJh5Kxg7hbclY78j0zQf0pAYvxqX7lF2FZXNJrGw+trJtpr63shtr0lemDx2dvuI+oid99Xz8vuLfq25eTPaZTsm8eyVz+e0YmV4maeLe4htGXjpmVLLPvBHp1cfPOiZ9fFyzMj2Sc9/KstGE1BX0kjnokrHVRLxW840we4D3R8S7qSzPfI6kU4FrgS9GxNuAbcDHB7AtM2uTfos9KvYPBI6q/gvg/cC3qu23Ah9qSoZm1hADXZ99RHUF103AYiqf3NgeEftv5F5L2bmgmbXdgIo9IvZFxALgaOAU4PiB7kDSQkmdkjp7Sz+NZWbNNKir8RGxHXgQ+DlgoqT9V6yOBtYl+iyKiI6I6DiEMXUla2a167fYJU2TNLH6eCxwFrCCStH/SvVplwDfblaSZla/gQy9nUjlAtwIKn8c7oyIv5B0LJWht8nAT4HfiIg95duaGOK9hbFgbUnP4uGTSSU3u2xL9KlIz0E3mmnJWPqbKxvW+klJLH0jT+U6aMrpJb2K5097Y+xL6c29VrxkFMCoCek5197YlZqTDxgztbB5wuj0qzhix2nJ2Oh3pIe1pmxJD5XtOKz45qWjXn062WfC26cnY73dqTntIKam36YevjU9P92OOcXf94uPvpDss6Y7tfTZKiJeLRx66/eut4hYCpxU0L6ayvt3MxsG/Ak6s0y42M0y4WI3y4SL3SwTLnazTLR0+SdJ3fC/tz1Npfy2r1ZxHgdyHgcabnkcExGF48ctLfYDdix1RkRHW3buPJxHhnn4NN4sEy52s0y0s9gXtXHffTmPAzmPAx00ebTtPbuZtZZP480y4WI3y0Rbil3SOZL+W9IqSZe3I4dqHl2Slkl6UlJnC/d7s6RNkpb3aZssabGk56r/p+/bbG4eV0taV31NnpR0XgvymCXpQUnPSHpa0h9W21v6mpTk0dLXRNIYSY9Keqqax59X2+dIeqRaN9+UlFp8sFhEtPQflfvinweOpbJS4lPA/FbnUc2lC5jahv2+DzgZWN6n7Trg8urjy4Fr25TH1cBnW/x6zABOrj6eADwLzG/1a1KSR0tfEypzS4+vPh4FPAKcCtwJXFht/wrwycFstx1H9lOAVRGxOirzzN8BicnkD1IR8TDw5pkfzqcySQi0aLbeRB4tFxHrI+KJ6uNdVGZCmkmLX5OSPFoqKho+o3M7in0msKbP1+2cmTaAByQ9Lmlhm3LYb3pErK8+3gCkp0tpvkslLa2e5jf97URfkmZTmSzlEdr4mrwpD2jxa9KMGZ1zv0B3ekScDJwLfErS+9qdEFT+slP5Q9QONwJzqSwIsh64vlU7ljQeuBv4dETs7Btr5WtSkEfLX5OoY0bnlHYU+zpgVp+vkzPTNltErKv+vwm4l/ZOs7VR0gyA6v+b2pFERGys/qL1Al+jRa+JpFFUCuwbEXFPtbnlr0lRHu16Tar7HvSMzintKPbHgHnVK4uHAhcC32l1EpLGSZqw/zFwNrC8vFdTfYfKLL3Qxtl69xdX1YdpwWsiScBNwIqIuKFPqKWvSSqPVr8mTZvRuVVXGN90tfE8Klc6nwf+rE05HEtlJOAp4OlW5gHcTuV08A0q770+TmWBzCXAc8D3gcltyuPrwDJgKZVim9GCPE6ncoq+FHiy+u+8Vr8mJXm09DUBTqQyY/NSKn9YPtfnd/ZRYBVwFzB6MNv1x2XNMpH7BTqzbLjYzTLhYjfLhIvdLBMudrNMuNjNMuFiN8vE/wBnVydMJbGTDQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzytorch.datasets import tensor_data_collate\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True, collate_fn=tensor_data_collate)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size, collate_fn=tensor_data_collate)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64 - id: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64\n",
      "[x-entropy]\n",
      " - opt-parameters: 117,072[p] - device: cpu\n",
      " - save-mode: only_sup_metric(target_metric_crit: accuracy)\n",
      " - early_stop_epochcheck_epochs: 1 - early_stop_patience_epochchecks: 100\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 1/196000 [00:00,  7.86it/s, id: 0 - epoch: 1/1,000(0/196)[x-entropy] *loss*: 2.31=1.16+.77(loss/2+loss/3)]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fuzzytorch/handlers.py:57: UserWarning: there is not CUDA nor GPUs... Using CPU >:(\n",
      "  warnings.warn('there is not CUDA nor GPUs... Using CPU >:(')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 29596/196000 [1:37:15,  5.07it/s, id: 0 - epoch: 151/1,000(195/196)[x-entropy] *loss*: .86=.43+.29(loss/2+loss/3)\u001b[34m[train][x-entropy] *loss*: .62=.31+.21(loss/2+loss/3) - accuracy: 77.44 - dummy-accuracy: 10.00 (time: 0.2176[mins])\u001b[0m\u001b[31m[val][x-entropy] *loss*: .69=.34+.23(loss/2+loss/3) - accuracy: 72.62 - dummy-accuracy: 10.00 (time: 0.0323[mins])\u001b[0m\u001b[33m[stop][x-entropy] epoch-counter: (0/1) - patience: (99/100)\u001b[0m] \n",
      "\u001b[31m*** early stopping ***\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "End of training!\n",
      "[x-entropy] best-epoch: 51 - convergence-time: 20.0473[mins] - time-per-epoch: 0.3933[mins]\n",
      "▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import CrossEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = CrossEntropy('x-entropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "from fuzzytorch import C_\n",
    "trainh_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':int(1e2),\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **trainh_config)\n",
    "\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "    #'extra_model_name_dict':{'x':9},\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flamingChoripan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4b2c552d70b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mflamingChoripan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtinyFlame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplots\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfplots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### training plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flamingChoripan'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
