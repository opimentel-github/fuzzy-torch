{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': tensor([[[-0.9867, -1.3065, -1.1162,  ...,  0.5169,  0.4061,  0.3960],\n",
      "         [-1.7177, -1.9416, -1.6717,  ..., -0.0915, -0.1058, -0.0664],\n",
      "         [-1.6119, -1.7155, -1.2108,  ..., -0.0948, -0.1369, -0.2972],\n",
      "         ...,\n",
      "         [ 1.3203,  1.2308,  1.0595,  ...,  0.6122, -1.1408, -1.0928],\n",
      "         [ 0.7919,  0.7989,  0.9612,  ...,  0.8352, -0.3787, -0.6933],\n",
      "         [ 0.7506,  0.6228,  0.8700,  ...,  1.4175,  0.4214, -0.0128]],\n",
      "\n",
      "        [[-0.9985, -1.2745, -1.1922,  ...,  0.0771,  0.0367, -0.0348],\n",
      "         [-1.6163, -2.0472, -1.8728,  ..., -0.5560, -0.6888, -0.6504],\n",
      "         [-1.5336, -1.7726, -1.5210,  ..., -0.6631, -0.5687, -0.7900],\n",
      "         ...,\n",
      "         [ 0.7920,  0.4354,  0.6798,  ...,  0.2325, -1.5354, -1.3657],\n",
      "         [ 0.2335,  0.0667,  0.4337,  ...,  0.3706, -1.0318, -1.1254],\n",
      "         [ 0.3008,  0.0687,  0.3674,  ...,  1.0640, -0.0991, -0.4656]],\n",
      "\n",
      "        [[-0.7816, -0.9997, -1.0519,  ..., -0.0439, -0.0870, -0.1477],\n",
      "         [-1.3916, -1.6295, -1.7703,  ..., -0.8541, -0.9864, -0.9283],\n",
      "         [-1.3200, -1.7229, -1.5828,  ..., -0.8863, -0.9786, -1.0055],\n",
      "         ...,\n",
      "         [-0.2524, -1.2595, -1.2228,  ..., -0.7044, -1.5622, -1.4451],\n",
      "         [-0.3136, -1.1449, -1.3026,  ..., -0.3161, -1.2321, -1.2510],\n",
      "         [ 0.0726, -0.2775, -0.4148,  ...,  0.4244, -0.4565, -0.5975]]]), 'x2': tensor([-0.9867, -1.3065, -1.1162, -0.9748, -0.3743, -0.1661,  0.2001,  0.2875,\n",
      "         0.3819,  0.3839,  0.1095,  0.0222,  0.2238,  0.2786,  0.2046, -0.0242,\n",
      "         0.1775,  0.1045, -0.0892,  0.2796,  0.2361,  0.1797,  0.2191,  0.1209,\n",
      "         0.4726,  0.6406,  0.6413,  0.5054,  0.4887,  0.5169,  0.4061,  0.3960])}, 'target': {'y': tensor(6), 'y2': tensor([6])}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': tensor([[[[-3.6043e-01, -3.2930e-01, -4.7987e-01,  ..., -5.0797e-02,\n",
      "           -8.4611e-02, -1.5916e-01],\n",
      "          [-4.8262e-01, -5.5468e-01, -6.3671e-01,  ...,  9.2623e-02,\n",
      "           -6.4081e-02, -2.9396e-01],\n",
      "          [-2.4840e-01, -5.0081e-01, -4.8715e-01,  ...,  3.8804e-01,\n",
      "           -3.1989e-01, -9.1395e-01],\n",
      "          ...,\n",
      "          [-8.8460e-01, -1.0697e+00, -1.0235e+00,  ..., -1.1254e+00,\n",
      "           -1.2790e+00, -1.3135e+00],\n",
      "          [-3.7212e-01, -9.1323e-01, -6.7704e-01,  ..., -1.1006e+00,\n",
      "           -1.1789e+00, -1.2437e+00],\n",
      "          [-1.9204e-01, -6.6549e-02, -3.4818e-01,  ..., -1.1456e+00,\n",
      "           -1.1057e+00, -1.3674e+00]],\n",
      "\n",
      "         [[-2.2977e-01, -3.4167e-01, -4.2721e-01,  ..., -1.5859e-01,\n",
      "           -3.3426e-02, -1.3837e-01],\n",
      "          [-3.9894e-01, -5.0200e-01, -5.0664e-01,  ..., -9.8056e-02,\n",
      "           -1.0617e-01, -3.0879e-01],\n",
      "          [-2.3658e-01, -4.5430e-01, -4.8916e-01,  ...,  3.7594e-01,\n",
      "           -4.0201e-01, -8.0067e-01],\n",
      "          ...,\n",
      "          [-9.0469e-01, -1.0317e+00, -1.0196e+00,  ..., -1.1263e+00,\n",
      "           -1.2626e+00, -1.2468e+00],\n",
      "          [-4.8359e-01, -8.7874e-01, -6.8120e-01,  ..., -1.1750e+00,\n",
      "           -1.2362e+00, -1.3170e+00],\n",
      "          [-1.8970e-01, -2.2134e-01, -4.6184e-01,  ..., -1.2462e+00,\n",
      "           -1.1850e+00, -1.3794e+00]],\n",
      "\n",
      "         [[-5.9820e-02, -2.3834e-01, -2.6854e-01,  ...,  2.5162e-02,\n",
      "           -7.8972e-02, -4.9046e-02],\n",
      "          [-2.8806e-01, -3.2332e-01, -3.2270e-01,  ..., -3.8340e-02,\n",
      "           -1.2956e-01, -1.1557e-01],\n",
      "          [-1.6674e-01, -3.5817e-01, -2.3083e-01,  ...,  2.5020e-01,\n",
      "           -2.2346e-01, -6.4007e-01],\n",
      "          ...,\n",
      "          [-8.4318e-01, -9.3742e-01, -8.9412e-01,  ..., -1.0376e+00,\n",
      "           -1.1871e+00, -1.2182e+00],\n",
      "          [-5.1112e-01, -8.5873e-01, -7.0294e-01,  ..., -1.0989e+00,\n",
      "           -1.2032e+00, -1.2702e+00],\n",
      "          [-2.8887e-01, -2.6244e-01, -4.6413e-01,  ..., -1.0390e+00,\n",
      "           -1.1766e+00, -1.3364e+00]]],\n",
      "\n",
      "\n",
      "        [[[-7.2237e-02, -2.0094e-01, -4.4404e-01,  ...,  1.0746e+00,\n",
      "            1.3861e+00,  1.4386e+00],\n",
      "          [-2.5947e-01, -4.5762e-01, -1.2151e+00,  ...,  1.4740e+00,\n",
      "            1.4742e+00,  1.5813e+00],\n",
      "          [-2.2978e-01, -1.0914e+00, -1.6125e+00,  ...,  1.2595e+00,\n",
      "            1.4627e+00,  1.5785e+00],\n",
      "          ...,\n",
      "          [-1.0609e+00, -1.0788e+00, -1.0460e+00,  ..., -1.1953e+00,\n",
      "           -8.3961e-01,  2.8294e-02],\n",
      "          [-9.3371e-01, -9.2062e-01, -7.5710e-01,  ..., -1.1415e+00,\n",
      "           -2.6866e-01,  1.4407e-01],\n",
      "          [-8.9918e-01, -6.0942e-01, -2.4471e-01,  ..., -8.8312e-01,\n",
      "           -1.6682e-02,  1.7459e-02]],\n",
      "\n",
      "         [[ 6.0919e-01,  2.6594e-01, -3.7069e-02,  ...,  8.3698e-01,\n",
      "            1.3342e+00,  1.2104e+00],\n",
      "          [ 5.0658e-01, -1.0191e-01, -8.6760e-01,  ...,  1.2180e+00,\n",
      "            1.1968e+00,  1.3667e+00],\n",
      "          [ 1.7970e-01, -7.1649e-01, -1.4824e+00,  ...,  1.0517e+00,\n",
      "            1.2523e+00,  1.4377e+00],\n",
      "          ...,\n",
      "          [-1.4742e+00, -1.3596e+00, -1.0375e+00,  ..., -1.1211e+00,\n",
      "           -9.2353e-01, -9.8370e-02],\n",
      "          [-1.4260e+00, -1.1423e+00, -6.9266e-01,  ..., -9.7155e-01,\n",
      "           -4.2761e-01, -4.3797e-02],\n",
      "          [-1.3615e+00, -8.7976e-01, -4.6116e-01,  ..., -7.9730e-01,\n",
      "            6.4218e-02, -1.1591e-01]],\n",
      "\n",
      "         [[-4.5082e-01, -4.8231e-01, -5.6192e-01,  ...,  8.9966e-01,\n",
      "            1.1847e+00,  1.2170e+00],\n",
      "          [-6.3770e-01, -7.1930e-01, -9.9077e-01,  ...,  1.1597e+00,\n",
      "            1.0502e+00,  1.2963e+00],\n",
      "          [-5.4637e-01, -1.0758e+00, -1.3525e+00,  ...,  9.9659e-01,\n",
      "            1.1930e+00,  1.3892e+00],\n",
      "          ...,\n",
      "          [-1.5284e+00, -1.3507e+00, -9.6166e-01,  ..., -7.8711e-01,\n",
      "           -4.8259e-01,  1.8578e-01],\n",
      "          [-1.5842e+00, -1.3484e+00, -8.4446e-01,  ..., -7.2646e-01,\n",
      "           -2.6198e-01,  1.0374e-02],\n",
      "          [-1.5384e+00, -1.0181e+00, -4.8496e-01,  ..., -6.1964e-01,\n",
      "           -2.8926e-02, -1.6629e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4152e-01,  5.8990e-01,  5.1967e-01,  ...,  5.8766e-01,\n",
      "            5.2461e-01,  5.7307e-01],\n",
      "          [ 6.3239e-01,  5.6106e-01,  6.6091e-01,  ...,  2.3318e-01,\n",
      "            7.4191e-01,  5.9777e-01],\n",
      "          [ 8.1235e-01,  6.5272e-01,  6.1661e-01,  ...,  3.6563e-01,\n",
      "            7.8277e-01,  6.8978e-01],\n",
      "          ...,\n",
      "          [-5.8074e-02, -6.4662e-02,  6.7055e-03,  ...,  1.0261e-02,\n",
      "            3.9673e-02,  5.4049e-02],\n",
      "          [-4.5552e-02,  2.6476e-02, -2.4781e-02,  ...,  2.8202e-02,\n",
      "            9.3530e-03,  5.5362e-02],\n",
      "          [-5.3033e-02, -1.5515e-01, -1.5988e-01,  ..., -1.7177e-02,\n",
      "            8.8311e-02,  5.8097e-02]],\n",
      "\n",
      "         [[ 1.2141e+00,  1.0992e+00,  1.1142e+00,  ...,  1.0097e+00,\n",
      "            1.1825e+00,  1.2371e+00],\n",
      "          [ 1.1524e+00,  1.1519e+00,  1.2229e+00,  ...,  6.5852e-01,\n",
      "            1.2569e+00,  1.1640e+00],\n",
      "          [ 1.3052e+00,  1.2520e+00,  1.2694e+00,  ...,  6.2158e-01,\n",
      "            1.2908e+00,  1.1504e+00],\n",
      "          ...,\n",
      "          [ 3.6297e-02,  7.0331e-02,  3.1144e-03,  ...,  1.8302e-01,\n",
      "            1.0080e-01,  4.1881e-02],\n",
      "          [ 1.6127e-01, -2.0491e-04,  4.8872e-02,  ...,  1.2167e-01,\n",
      "            2.0702e-02,  7.6840e-02],\n",
      "          [ 1.3551e-02,  6.3571e-03, -1.4325e-01,  ...,  3.3279e-02,\n",
      "           -7.3029e-03,  1.4814e-01]],\n",
      "\n",
      "         [[ 1.7508e+00,  1.7389e+00,  1.7936e+00,  ...,  1.6306e+00,\n",
      "            1.7777e+00,  1.7591e+00],\n",
      "          [ 1.9094e+00,  1.7192e+00,  1.8037e+00,  ...,  1.0050e+00,\n",
      "            1.8370e+00,  1.8182e+00],\n",
      "          [ 1.8157e+00,  1.7863e+00,  1.8264e+00,  ...,  9.5552e-01,\n",
      "            1.7103e+00,  1.8786e+00],\n",
      "          ...,\n",
      "          [ 1.7031e-01,  2.0058e-01,  1.0212e-01,  ...,  2.2393e-01,\n",
      "            2.8481e-01,  2.1689e-01],\n",
      "          [ 1.4124e-01,  1.9999e-01,  1.4551e-01,  ...,  2.8835e-01,\n",
      "            2.7018e-01,  1.7647e-01],\n",
      "          [ 1.7410e-01,  1.4125e-01,  2.1416e-01,  ...,  1.9809e-01,\n",
      "            2.6315e-01,  1.3547e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.4271e+00, -1.3904e+00, -1.1993e+00,  ..., -1.8343e+00,\n",
      "           -1.9317e+00, -1.9045e+00],\n",
      "          [-1.7966e+00, -1.4272e+00, -1.3618e+00,  ..., -1.8639e+00,\n",
      "           -1.8244e+00, -1.8511e+00],\n",
      "          [-1.8198e+00, -1.8101e+00, -1.8186e+00,  ..., -1.8925e+00,\n",
      "           -1.8138e+00, -1.5040e+00],\n",
      "          ...,\n",
      "          [-1.1928e+00, -1.2266e+00, -1.2351e+00,  ..., -1.4423e-01,\n",
      "           -8.7424e-01, -1.1959e+00],\n",
      "          [-4.7143e-01, -3.1420e-01, -2.3751e-01,  ..., -3.3147e-02,\n",
      "           -3.9740e-01, -4.6997e-01],\n",
      "          [ 7.0143e-02,  1.4625e-01,  1.8652e-01,  ..., -1.7930e-01,\n",
      "           -1.0275e-01, -1.3631e-01]],\n",
      "\n",
      "         [[-1.6179e+00, -1.3198e+00, -1.3160e+00,  ..., -1.8965e+00,\n",
      "           -1.8194e+00, -1.9872e+00],\n",
      "          [-1.6468e+00, -1.4679e+00, -1.3557e+00,  ..., -1.8321e+00,\n",
      "           -1.9194e+00, -1.7854e+00],\n",
      "          [-1.8651e+00, -1.9113e+00, -1.8504e+00,  ..., -1.8060e+00,\n",
      "           -1.8468e+00, -1.4962e+00],\n",
      "          ...,\n",
      "          [-1.2353e+00, -1.2486e+00, -1.2274e+00,  ..., -1.9179e-01,\n",
      "           -8.9347e-01, -1.2964e+00],\n",
      "          [-7.5473e-01, -4.5247e-01, -5.4516e-01,  ..., -1.6480e-01,\n",
      "           -3.2846e-01, -5.8212e-01],\n",
      "          [-2.0278e-01, -2.1447e-01, -6.3565e-02,  ..., -2.3327e-01,\n",
      "           -1.2687e-01, -3.1120e-01]],\n",
      "\n",
      "         [[-1.3549e+00, -1.1340e+00, -1.1091e+00,  ..., -1.5093e+00,\n",
      "           -1.5838e+00, -1.6720e+00],\n",
      "          [-1.4237e+00, -1.1632e+00, -1.0445e+00,  ..., -1.5518e+00,\n",
      "           -1.6140e+00, -1.5699e+00],\n",
      "          [-1.6127e+00, -1.6761e+00, -1.6408e+00,  ..., -1.5851e+00,\n",
      "           -1.5560e+00, -1.3389e+00],\n",
      "          ...,\n",
      "          [-1.1270e+00, -1.2336e+00, -1.1911e+00,  ...,  1.4470e-02,\n",
      "           -6.0258e-01, -1.0545e+00],\n",
      "          [-7.4858e-01, -8.5989e-01, -6.7870e-01,  ..., -4.5628e-02,\n",
      "           -1.2153e-01, -5.4597e-01],\n",
      "          [-4.4914e-01, -4.4065e-01, -3.6099e-01,  ..., -2.3576e-01,\n",
      "           -5.9040e-02, -1.7489e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0619e+00,  2.0398e+00,  2.0265e+00,  ...,  2.0318e+00,\n",
      "            2.0789e+00,  2.0999e+00],\n",
      "          [ 2.0844e+00,  2.0330e+00,  1.9978e+00,  ...,  2.1094e+00,\n",
      "            2.1134e+00,  2.0388e+00],\n",
      "          [ 2.0616e+00,  2.0473e+00,  2.0011e+00,  ...,  2.0991e+00,\n",
      "            2.0198e+00,  2.1053e+00],\n",
      "          ...,\n",
      "          [ 2.0945e+00,  2.0527e+00,  2.0565e+00,  ...,  2.0084e+00,\n",
      "            2.0353e+00,  2.0439e+00],\n",
      "          [ 1.9638e+00,  2.1296e+00,  2.1151e+00,  ...,  2.1144e+00,\n",
      "            1.9364e+00,  2.0984e+00],\n",
      "          [ 1.9983e+00,  2.1009e+00,  2.1299e+00,  ...,  2.0934e+00,\n",
      "            2.0034e+00,  2.0768e+00]],\n",
      "\n",
      "         [[ 2.1480e+00,  2.2180e+00,  2.1064e+00,  ...,  2.1121e+00,\n",
      "            2.1872e+00,  2.0321e+00],\n",
      "          [ 2.2241e+00,  2.0379e+00,  2.0948e+00,  ...,  2.1313e+00,\n",
      "            2.1332e+00,  2.0236e+00],\n",
      "          [ 2.1010e+00,  2.1742e+00,  2.1074e+00,  ...,  2.1206e+00,\n",
      "            2.1122e+00,  2.1747e+00],\n",
      "          ...,\n",
      "          [ 2.1724e+00,  2.1623e+00,  2.1149e+00,  ...,  2.1326e+00,\n",
      "            2.1040e+00,  2.1494e+00],\n",
      "          [ 2.1207e+00,  2.2733e+00,  2.1257e+00,  ...,  2.1754e+00,\n",
      "            2.1387e+00,  2.1064e+00],\n",
      "          [ 2.0609e+00,  2.0509e+00,  2.1422e+00,  ...,  2.2093e+00,\n",
      "            2.0945e+00,  2.1412e+00]],\n",
      "\n",
      "         [[ 2.1505e+00,  2.0946e+00,  2.1868e+00,  ...,  2.1108e+00,\n",
      "            2.1788e+00,  2.0622e+00],\n",
      "          [ 2.0533e+00,  2.1304e+00,  2.1607e+00,  ...,  2.1093e+00,\n",
      "            2.0469e+00,  2.1491e+00],\n",
      "          [ 2.1736e+00,  2.1446e+00,  2.1772e+00,  ...,  2.0872e+00,\n",
      "            2.1199e+00,  2.1447e+00],\n",
      "          ...,\n",
      "          [ 2.1082e+00,  2.0662e+00,  2.0994e+00,  ...,  2.1083e+00,\n",
      "            2.0953e+00,  2.0154e+00],\n",
      "          [ 2.2368e+00,  2.0793e+00,  2.1908e+00,  ...,  2.2147e+00,\n",
      "            2.1031e+00,  2.0763e+00],\n",
      "          [ 2.0456e+00,  2.0774e+00,  2.0475e+00,  ...,  2.0504e+00,\n",
      "            2.0626e+00,  2.1284e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.6547e+00, -1.7605e+00, -1.7844e+00,  ..., -3.9738e-01,\n",
      "           -7.5204e-01, -7.5879e-01],\n",
      "          [-1.7700e+00, -1.7112e+00, -1.5043e+00,  ..., -1.7065e-01,\n",
      "           -4.2658e-01, -5.1032e-01],\n",
      "          [-1.7791e+00, -1.7128e+00, -1.5367e+00,  ..., -4.4040e-01,\n",
      "           -4.0866e-01, -4.9752e-01],\n",
      "          ...,\n",
      "          [-5.7443e-01, -1.1191e+00, -9.8993e-01,  ..., -8.3013e-01,\n",
      "           -5.5243e-01, -6.8035e-01],\n",
      "          [-5.6216e-01, -1.1616e+00, -9.9883e-01,  ..., -1.1871e+00,\n",
      "           -5.9273e-01, -7.5923e-01],\n",
      "          [-7.5339e-01, -1.1696e+00, -1.0243e+00,  ..., -1.2282e+00,\n",
      "           -6.1816e-01, -6.3523e-01]],\n",
      "\n",
      "         [[-1.8696e+00, -1.7772e+00, -1.5595e+00,  ..., -3.1826e-01,\n",
      "           -6.4654e-01, -6.6489e-01],\n",
      "          [-1.9229e+00, -1.7477e+00, -1.5092e+00,  ..., -3.8327e-01,\n",
      "           -3.1074e-01, -5.4333e-01],\n",
      "          [-1.7445e+00, -1.6579e+00, -1.5680e+00,  ..., -5.2699e-01,\n",
      "           -4.8280e-01, -2.7476e-01],\n",
      "          ...,\n",
      "          [-2.6610e-01, -8.1880e-01, -7.8367e-01,  ..., -7.0297e-01,\n",
      "           -5.6796e-01, -6.4916e-01],\n",
      "          [-3.1107e-01, -9.4841e-01, -7.0762e-01,  ..., -9.5673e-01,\n",
      "           -6.9890e-01, -6.4249e-01],\n",
      "          [-3.7105e-01, -9.3576e-01, -9.0790e-01,  ..., -1.0575e+00,\n",
      "           -5.4273e-01, -6.0735e-01]],\n",
      "\n",
      "         [[-1.5585e+00, -1.6568e+00, -1.5151e+00,  ..., -4.0657e-02,\n",
      "           -4.5564e-01, -6.1290e-01],\n",
      "          [-1.6632e+00, -1.5358e+00, -1.4439e+00,  ..., -5.7956e-02,\n",
      "           -3.1104e-01, -5.0879e-01],\n",
      "          [-1.5131e+00, -1.4762e+00, -1.4081e+00,  ..., -2.5631e-01,\n",
      "           -2.7208e-01, -2.7148e-01],\n",
      "          ...,\n",
      "          [ 5.2385e-02, -6.0561e-01, -5.1897e-01,  ..., -7.2679e-01,\n",
      "           -6.0644e-01, -5.8593e-01],\n",
      "          [-2.5069e-02, -7.3519e-01, -4.9017e-01,  ..., -9.3036e-01,\n",
      "           -5.1083e-01, -6.3051e-01],\n",
      "          [-1.4745e-01, -7.5977e-01, -7.6755e-01,  ..., -1.0587e+00,\n",
      "           -7.0467e-01, -6.0450e-01]]]]), 'x2': tensor([[-0.3604, -0.3293, -0.4799,  ..., -0.0508, -0.0846, -0.1592],\n",
      "        [-0.0722, -0.2009, -0.4440,  ...,  1.0746,  1.3861,  1.4386],\n",
      "        [ 0.5415,  0.5899,  0.5197,  ...,  0.5877,  0.5246,  0.5731],\n",
      "        ...,\n",
      "        [-1.4271, -1.3904, -1.1993,  ..., -1.8343, -1.9317, -1.9045],\n",
      "        [ 2.0619,  2.0398,  2.0265,  ...,  2.0318,  2.0789,  2.0999],\n",
      "        [-1.6547, -1.7605, -1.7844,  ..., -0.3974, -0.7520, -0.7588]])}, 'target': {'y': tensor([6, 6, 0, 8, 1, 6, 6, 1, 8, 9, 3, 0, 6, 4, 6, 8, 6, 9, 5, 3, 6, 9, 4, 2,\n",
      "        2, 3, 3, 7, 5, 9, 2, 8, 6, 8, 5, 8, 1, 4, 1, 4, 8, 3, 4, 3, 3, 8, 6, 6,\n",
      "        2, 8, 3, 4, 1, 1, 2, 0, 7, 5, 5, 9, 0, 7, 7, 8, 7, 2, 3, 7, 5, 5, 8, 0,\n",
      "        5, 7, 6, 4, 6, 4, 9, 3, 4, 4, 5, 8, 9, 4, 1, 4, 6, 0, 0, 5, 4, 7, 1, 1,\n",
      "        1, 9, 4, 4, 6, 4, 5, 7, 2, 6, 6, 2, 6, 0, 1, 5, 6, 2, 4, 2, 9, 7, 7, 0,\n",
      "        3, 5, 1, 9, 0, 2, 1, 6, 6, 5, 6, 6, 6, 7, 8, 7, 3, 9, 8, 6, 3, 0, 3, 7,\n",
      "        3, 5, 5, 4, 5, 6, 2, 9, 9, 1, 5, 2, 3, 6, 8, 0, 2, 3, 0, 9, 2, 3, 7, 6,\n",
      "        3, 0, 0, 2, 2, 1, 5, 2, 5, 1, 5, 0, 3, 7, 0, 2, 1, 5, 6, 4, 8, 6, 9, 9,\n",
      "        6, 8, 2, 6, 2, 4, 1, 0, 1, 6, 0, 4, 2, 9, 3, 2, 2, 8, 9, 2, 0, 0, 5, 2,\n",
      "        2, 0, 5, 0, 4, 7, 3, 0, 0, 6, 8, 5, 8, 4, 6, 2, 8, 0, 2, 1, 5, 2, 2, 8,\n",
      "        7, 7, 8, 9, 3, 9, 3, 2, 7, 3, 1, 9, 8, 7, 6, 3]), 'y2': tensor([[6],\n",
      "        [6],\n",
      "        [0],\n",
      "        [8],\n",
      "        [1],\n",
      "        [6],\n",
      "        [6],\n",
      "        [1],\n",
      "        [8],\n",
      "        [9],\n",
      "        [3],\n",
      "        [0],\n",
      "        [6],\n",
      "        [4],\n",
      "        [6],\n",
      "        [8],\n",
      "        [6],\n",
      "        [9],\n",
      "        [5],\n",
      "        [3],\n",
      "        [6],\n",
      "        [9],\n",
      "        [4],\n",
      "        [2],\n",
      "        [2],\n",
      "        [3],\n",
      "        [3],\n",
      "        [7],\n",
      "        [5],\n",
      "        [9],\n",
      "        [2],\n",
      "        [8],\n",
      "        [6],\n",
      "        [8],\n",
      "        [5],\n",
      "        [8],\n",
      "        [1],\n",
      "        [4],\n",
      "        [1],\n",
      "        [4],\n",
      "        [8],\n",
      "        [3],\n",
      "        [4],\n",
      "        [3],\n",
      "        [3],\n",
      "        [8],\n",
      "        [6],\n",
      "        [6],\n",
      "        [2],\n",
      "        [8],\n",
      "        [3],\n",
      "        [4],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [7],\n",
      "        [5],\n",
      "        [5],\n",
      "        [9],\n",
      "        [0],\n",
      "        [7],\n",
      "        [7],\n",
      "        [8],\n",
      "        [7],\n",
      "        [2],\n",
      "        [3],\n",
      "        [7],\n",
      "        [5],\n",
      "        [5],\n",
      "        [8],\n",
      "        [0],\n",
      "        [5],\n",
      "        [7],\n",
      "        [6],\n",
      "        [4],\n",
      "        [6],\n",
      "        [4],\n",
      "        [9],\n",
      "        [3],\n",
      "        [4],\n",
      "        [4],\n",
      "        [5],\n",
      "        [8],\n",
      "        [9],\n",
      "        [4],\n",
      "        [1],\n",
      "        [4],\n",
      "        [6],\n",
      "        [0],\n",
      "        [0],\n",
      "        [5],\n",
      "        [4],\n",
      "        [7],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [9],\n",
      "        [4],\n",
      "        [4],\n",
      "        [6],\n",
      "        [4],\n",
      "        [5],\n",
      "        [7],\n",
      "        [2],\n",
      "        [6],\n",
      "        [6],\n",
      "        [2],\n",
      "        [6],\n",
      "        [0],\n",
      "        [1],\n",
      "        [5],\n",
      "        [6],\n",
      "        [2],\n",
      "        [4],\n",
      "        [2],\n",
      "        [9],\n",
      "        [7],\n",
      "        [7],\n",
      "        [0],\n",
      "        [3],\n",
      "        [5],\n",
      "        [1],\n",
      "        [9],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [6],\n",
      "        [6],\n",
      "        [5],\n",
      "        [6],\n",
      "        [6],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [7],\n",
      "        [3],\n",
      "        [9],\n",
      "        [8],\n",
      "        [6],\n",
      "        [3],\n",
      "        [0],\n",
      "        [3],\n",
      "        [7],\n",
      "        [3],\n",
      "        [5],\n",
      "        [5],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [2],\n",
      "        [9],\n",
      "        [9],\n",
      "        [1],\n",
      "        [5],\n",
      "        [2],\n",
      "        [3],\n",
      "        [6],\n",
      "        [8],\n",
      "        [0],\n",
      "        [2],\n",
      "        [3],\n",
      "        [0],\n",
      "        [9],\n",
      "        [2],\n",
      "        [3],\n",
      "        [7],\n",
      "        [6],\n",
      "        [3],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [5],\n",
      "        [2],\n",
      "        [5],\n",
      "        [1],\n",
      "        [5],\n",
      "        [0],\n",
      "        [3],\n",
      "        [7],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [5],\n",
      "        [6],\n",
      "        [4],\n",
      "        [8],\n",
      "        [6],\n",
      "        [9],\n",
      "        [9],\n",
      "        [6],\n",
      "        [8],\n",
      "        [2],\n",
      "        [6],\n",
      "        [2],\n",
      "        [4],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [6],\n",
      "        [0],\n",
      "        [4],\n",
      "        [2],\n",
      "        [9],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [8],\n",
      "        [9],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [5],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [5],\n",
      "        [0],\n",
      "        [4],\n",
      "        [7],\n",
      "        [3],\n",
      "        [0],\n",
      "        [0],\n",
      "        [6],\n",
      "        [8],\n",
      "        [5],\n",
      "        [8],\n",
      "        [4],\n",
      "        [6],\n",
      "        [2],\n",
      "        [8],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [5],\n",
      "        [2],\n",
      "        [2],\n",
      "        [8],\n",
      "        [7],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9],\n",
      "        [3],\n",
      "        [9],\n",
      "        [3],\n",
      "        [2],\n",
      "        [7],\n",
      "        [3],\n",
      "        [1],\n",
      "        [9],\n",
      "        [8],\n",
      "        [7],\n",
      "        [6],\n",
      "        [3]])}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1395) tensor(2.2873)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64 - id: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64\n",
      "[x-entropy]\n",
      " - opt-parameters: 117,072[p] - device: cpu\n",
      " - save-mode: only_sup_metric(target_metric_crit: accuracy)\n",
      " - counter_k: k(0/0) - counter_epoch: val_epoch(0/0)»earlystop_epoch(0/21)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 5/196000 [03:09, 37.86s/it, id: 0 - epoch: 5/1,000(22/196)[x-entropy] __loss__: 1.23=.61+.41(loss/2+loss/3) #.090[segs]\u001b[34m[train][x-entropy] __loss__: .99=.49+.33(loss/2+loss/3) - accuracy: 65.22 - dummy-accuracy: 10.00 #12.272[segs]\u001b[0m\u001b[31m[val][x-entropy] __loss__: 1.03=.51+.34(loss/2+loss/3) - accuracy: 64.04 - dummy-accuracy: 10.00 #1.780[segs]\u001b[0m\u001b[33m[stop][x-entropy] counter_epoch: val_epoch(0/0)»earlystop_epoch(1/21)\u001b[0m]  \n",
      "\u001b[31m*** ctrl+c ***\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "End of training!!!\n",
      "[x-entropy] best_epoch: 4 - time_per_iteration: .09±.00[segs] - time_per_epoch: 7.03±5.25[mins] - total_time: 2.610321[mins]\n",
      "▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' # see issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' # CPU\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import CrossEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = CrossEntropy('x-entropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "### GET MODEL\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "### MONITORS\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "from fuzzytorch import C_\n",
    "\n",
    "monitor_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':1e2,\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **monitor_config)\n",
    "\n",
    "### TRAIN\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_time_util_convergence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['opt_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['loss_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['metrics_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from flamingchoripan.counters import Counter\n",
    "\n",
    "d = {\n",
    "'val_epoch_counter_duration':1,\n",
    "'earlystop_epoch_duration':5,\n",
    "}\n",
    "c = Counter(d)\n",
    "for _ in range(50):\n",
    "    print(c, c.check('earlystop_epoch_duration'))\n",
    "    c.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
