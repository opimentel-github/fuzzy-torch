{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': (3, 32, 32)-float32-cpu, 'x2': (32)-float32-cpu}, 'target': {'y': ()-int64-cpu, 'y2': (1)-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': (256, 3, 32, 32)-float32-cpu, 'x2': (256, 32)-float32-cpu}, 'target': {'y': (256)-int64-cpu, 'y2': (256, 1)-int64-cpu}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1661) tensor(2.3202)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzytorch.datasets import tensor_data_collate\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True, collate_fn=tensor_data_collate)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size, collate_fn=tensor_data_collate)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64 - id: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64\n",
      "[x-entropy]\n",
      " - opt-parameters: 117,072[p] - device: cpu\n",
      " - save-mode: only_sup_metric(target_metric_crit: accuracy)\n",
      " - counter_k: k(0/0) - counter_epoch: val_epoch(0/0)»earlystop_epoch(0/21)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 0/196000 [00:00, ?it/s, id: 0 - epoch: 0/1,000(0/196)[x-entropy] __loss__: 2.30=1.15+.77(loss/2+loss/3) #.092[segs]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fuzzytorch/handlers.py:57: UserWarning: there is not CUDA nor GPUs... Using CPU >:(\n",
      "  warnings.warn('there is not CUDA nor GPUs... Using CPU >:(')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/196000 [00:04, ?it/s, id: 0 - epoch: 0/1,000(35/196)[x-entropy] __loss__: 2.07=1.03+.69(loss/2+loss/3) #.089[segs]]\n",
      "\u001b[31m*** ctrl+c ***\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "End of training!!!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LossMonitor' object has no attribute 'loss_df_epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d7caee01e331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mmodel_train_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_train_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mmodel_train_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_mnist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/fuzzytorch/handlers.py\u001b[0m in \u001b[0;36mfit_loader\u001b[0;34m(self, train_loader, val_loader, model_kwargs, load, k_every, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m                         \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'[{lmonitor.name}] best_epoch: {lmonitor.get_best_epoch()}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                         \u001b[0mtxt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' - time_per_iteration: {lmonitor.get_time_per_iteration()}[segs]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                         \u001b[0mtxt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' - time_per_epoch: {lmonitor.get_time_per_epoch()/60.}[mins]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                         \u001b[0mtxt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' - total_time: {lmonitor.get_total_time()/60.:3f}[mins]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/fuzzytorch/monitors.py\u001b[0m in \u001b[0;36mget_time_per_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_time_per_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_per_epoch_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_evaluation_set_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_total_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/fuzzytorch/monitors.py\u001b[0m in \u001b[0;36mget_evaluation_set_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_evaluation_set_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_df_epoch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__set__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_time_per_epoch_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LossMonitor' object has no attribute 'loss_df_epoch'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' # see issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' # CPU\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import CrossEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = CrossEntropy('x-entropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "\n",
    "### MONITORS\n",
    "from fuzzytorch import C_\n",
    "trainh_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':int(1e2),\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **trainh_config)\n",
    "\n",
    "### TRAIN\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_time_util_convergence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['opt_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['loss_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['metrics_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from flamingchoripan.counters import Counter\n",
    "\n",
    "d = {\n",
    "'val_epoch_counter_duration':1,\n",
    "'earlystop_epoch_duration':5,\n",
    "}\n",
    "c = Counter(d)\n",
    "for _ in range(50):\n",
    "    print(c, c.check('earlystop_epoch_duration'))\n",
    "    c.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
