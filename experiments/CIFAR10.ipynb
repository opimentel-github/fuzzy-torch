{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': (3, 32, 32)-float32-cpu, 'x2': (32)-float32-cpu}, 'target': {'y': ()-int64-cpu, 'y2': (1)-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': (256, 3, 32, 32)-float32-cpu, 'x2': (256, 32)-float32-cpu}, 'target': {'y': (256)-int64-cpu, 'y2': (256, 1)-int64-cpu}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1743) tensor(2.3185)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAY/0lEQVR4nO3deZRV1ZUG8O8TcQRxoCQoKmhjIxpEUxrTDh3HKMZW2rQao0HFJk7dGkdi0tG47AQxYOyYqKgMzkOcjUaJ84iWioigoqYMIEOpoOAQp91/3MtaBd69q+rVG6o432+tWvXq7Dr3bp+1ue/d8845NDOIyMpvlVonICLVoWIXSYSKXSQRKnaRRKjYRRKhYhdJhIpdJBEq9k6KZCPJvWp4/okkzy+h38kk/0byI5IzSW5Zifzk61atdQJSGyS7mNmXVT7nsQCGA9gfwEwAmwNYVM0cUqYreydE8hoAmwK4m+RSkmfm7beQnE/yA5KPkdy6WZ+JJC8leS/JjwDsTnIDkneT/JDkcyTPJ/lEsz4DSE4m+T7J10gekrePAPAjAGfm57+7FTmvAuAcAD81sxmWedPM3i/rkyM+M9NXJ/wC0AhgrxXajgHQHcDqAH4HYGqz2EQAHwDYGdk/8msAuDH/WgvAQACzATyR//7a+c9HI3sFuB2AdwEMbHa881c4/x8B/NHJd1MABuDk/Lh/A/ArAKvU+rlM5Usv41ciZjZ+2WOS5wJYRLKHmX2QN99pZk/m8c8BHAxgGzP7GMAMkpMAfDf/3e8DaDSzCfnPL5K8FcB/ICvSovOfEKTXJ/++D4BvAlgXwAMA5gC4oi3/nVIavYxfSZDsQnIUyTdJfojsyg8APZv92uxmj+uQXbFnO/HNAHyb5OJlX8heun+jxBQ/yb+PNrPFZtYI4HIAQ0o8nrSRruyd14rTFQ8HcCCAvZAVeg9kN7/o9GkC8AWyK+7redsmzeKzATxqZnu38vwteQ3AZyv005TLKtKVvfNagOxu9jLdAfwDwHvI3oP/Oups2Z342wCcS3ItkgMA/LjZr9wDYEuSR5Lsmn/tQHIr5/yh/K3CTchu6nUn2QfAiPw8UgUq9s7rNwB+kb/EPh3A1QDeBjAXwAwAz7TiGCchewUwH8A1AG5A9g8GzGwJsvfXhwF4J/+dC5Dd/AOAqwAMzM9/BwCQvIzkZS2cb2l+vKcBXA9gfPD7UkbM75SKgOQFAL5hZsNqnYuUn67sCcvH0QcxsyOyD7zcXuu8pDJ0gy5t3ZG9dN8I2XvwMQDurGlGUjF6GS+SCL2MF0lEVV/G9+zZ0/r27VvNU4okpbGxEe+++y6LYu0qdpL7ArgYQBcAV5rZqOj3+/bti4aGhvacUkQC9fX1bqzkl/EkuwD4A4D9kE2i+CHJgaUeT0Qqqz3v2XcE8IaZvWVmnyGbPXVgedISkXJrT7FvjOUnTszJ25ZDcgTJBpINTU1N7TidiLRHxe/Gm9k4M6s3s/q6urpKn05EHO0p9rlYfpZUn7xNRDqg9tyNfw5Af5L9kBX5YcimWVbRBDcy64Vj3Fj/7T8KjrlWO/JJyzv3/dyNPfTI2ML2Iy44NzjiWe1LSEIlF7uZfUHyJAD3Ixt6G29mr5QtMxEpq3aNs5vZvQDuLVMuIlJB+risSCJU7CKJULGLJELFLpKITr14xbfpD68dc7bfr//267ixpc8c58ae6/FuYfvuy33cYAVb/a8fw2pBbGEQ2zCIldeTT49xY7sMCde0LHTk6JFu7KJT/dgpY+4LjtoniL3ntP9L0KdrEOu8dGUXSYSKXSQRKnaRRKjYRRKhYhdJRFVXl62vr7fSlqVaWthKdnd77BccrVewns7EGa1MqZWi++3+AkLAU0HsjGArxCFHfW1JAQDAptud7PZ5c/5iN7bPrm2/4x7ZMYg9G8S2DWIvlZiLZ8Dafmz4f/d1Y6f/+rHgqMGITRnV19ejoaGhcA06XdlFEqFiF0mEil0kESp2kUSo2EUSoWIXSUTHGXr7qHjNMgDo2e20wnZvikNLTt3Uj439e4kHleWMdeaSDD3a7zNonB/7NDjX563KqPIGBbGfnu/Hvn/E6ML2npud0eYcNPQmIip2kVSo2EUSoWIXSYSKXSQRKnaRRFR1DbpP5s/CS6OL56MddNZf3H6lDLGtG8TG3LiZG1vtl2+7sVF/LSGRlVi0TeeWexS3b3a0v17cA5vOcWOPBUNXZ0XjciXYLoj58wOBH+3qx776mx97/LpfFLYPPfuo4Gxt3yS1XcVOshHAEgBfAvjCzKJZmyJSQ+W4su9uZsXLropIh6H37CKJaG+xG4AHSD5PckTRL5AcQbKBZMOijz5r5+lEpFTtfRm/i5nNJbkhgMkkXzWz5dbmMbNxAMYBwNZ9elTvg/gispx2XdnNbG7+fSGA2xEvMSYiNVTyrDeSawNYxcyW5I8nAzjPzNwxNJLuyUYGO+4860xreqiVua5ofLCG4lYf+rGTRhW3fxKc64Mg9k4Q2yCI9QtizwWxjmBYMF5zXrAj05pBv4Uf+7FRzm5e1/pdQsODGZNXTvf/iJ+8x5+bt+rs4vYX/ZFIHPd/xaUUzXprz8v4XgBuJ7nsONdHhS4itVVysZvZW4hX+BWRDkRDbyKJULGLJELFLpIIFbtIIqo66y0yaH8/NuGO8p5rwlV+bKP3/djzJZwr2FYOPYNYNKfpX4NYRx96mxRs9RfF1giO+edgRtw11xS373Oe32fMLD92VbAg6d3r+MNrC2xnv+ODTxY2P7Ce36UUurKLJELFLpIIFbtIIlTsIolQsYskoqrbP0UTYQo/uZ87ukdx+3vBLJNXg+O9FsS+FSSy2Mk+egbfCmKTgxGIR/7sx4K5OvAmJwQ3mDuMtYJYMNcl1N9pf/kUv8/4Z4PYU34sGEzAqcP82JiJA5xI8bZnmWMLW7X9k4io2EVSoWIXSYSKXSQRKnaRRKjYRRJR1aG3nht2sQMOXbMwNvGSj9p8vB2ic63jxxqisatAk9MerQkX7PqDC4J9hlYNno7Zr/sxbyJM8VSLjqX4LyMTrfNXbhcP8WN7buXHHpzhxy65z4+9/pkztanrI34nh4beRETFLpIKFbtIIlTsIolQsYskQsUukoiqrkHXd9PtMOH3xXODvrnRum6/084unt4WrrcWDK9FQ3ZvBLHVnPZoeC3y6ot+7JBBfqzLxn5s+twSk6mSaGabN0MNAHYMFuW7yxsTBbCgpYQKXHuvH3s8iO2wmR+78Wg/tuDp4v/yXrv5fUrR4pWd5HiSC0lOb9a2PsnJJGfl38u8NJ6IlFtrXsZPBLDvCm0jATxoZv0BPJj/LCIdWIvFnu+3vuICywcCmJQ/ngTgoDLnJSJlVuoNul5mNi9/PB/Zjq6FSI4g2UCyoakpeHMlIhXV7rvxln243v2AvZmNM7N6M6uvq4u2PhCRSiq12BeQ7A0A+feF5UtJRCqh1KG3uwAMAzAq/35nexM59WeL3diwU4r3azrp8OJF9wDgxmDLqA6zRVJ3P9To7ySED4PhtUO3LG6fH8yUm+6HSuZNOoxmCG7mj75iw2C4cfXg3aH3B/5FkEe0zVf0t3PH237s6gl+7OMJVxa2jx79kNvnB2e8GWRSrDVDbzcAeBrAP5OcQ3I4siLfm+QsAHvlP4tIB9bild3MfuiE9ixzLiJSQfq4rEgiVOwiiVCxiyRCxS6SiKrOeivVBmsOL2y/4fbd3T5bj9zCjXULxprODfZYC7aWc3m7eAFA/2BfuXeC4bXHgmNu4wyxdQn6eLP5AOCzEvt5Q2w7B30+9UdfceFUPxblWIqvSuwXDee9EsS8yW2jz/R3Cly09YGF7e9+4M/b1JVdJBEqdpFEqNhFEqFiF0mEil0kESp2kUR0iqE33+Zu5Bej/DG0F8bv78b+zZ9ohFucDcc+9bvg1SA2JVgUsy5YmXFRcMyXnfZgQhmCCWVYO4htGMTWcNqD0TXMCmLlHl6rtlOd7dwAYMwfitubXvL7HHXmXYXti+b4fXRlF0mEil0kESp2kUSo2EUSoWIXSUQnvxsfGeJGtj/mMjc266fHubFPnbvxawZZOF0AxAv3HRDcfv5dsC3QWGeWTLTt0jeC2DZB7IUg5k0A+jT4i7snmknSQfh/VcCArf1Yl8FBRxaPlaz6ij928bIzsyb6e9OVXSQRKnaRRKjYRRKhYhdJhIpdJBEqdpFErMRDb5GfuJGnP+jvxjZh8b4YwdyDkj0RDENdsZUf+54z9BZNMtkvmKRx86N+LEgD+ztbi0wOJhp9uCA4YGD9ILbiXuOtsVMQO+1wP/btobu6sd/OeMeNLXX+w8+52z/XbD/kas32T+NJLiQ5vVnbuSTnkpyaf0XDjyLSAbTmZfxEAPsWtF9kZoPzr3vLm5aIlFuLxW5mj6G0V0Mi0oG05wbdSSSn5S/z1/N+ieQIkg0kG5qagr11RaSiSi32SwFsAWAwgHkAxni/aGbjzKzezOrr6upKPJ2ItFdJxW5mC8zsSzP7CsAVAHYsb1oiUm4lDb2R7G1m8/IfhwIINlTqbPZwI7OX3F/Yvmr377l9viwxi2iduYGX+7FLehe3d3PaAeDjYIG6I7b1YxsFsUbnRdzEEofXoteE5X5zeO1NfmyLgUHHXv7cwvmnvunGznEWKpzqLSgIYHPnVHOCBRFbLHaSNwD4LoCeJOcAOAfAd0kOBmAAGhENXItIh9BisZtZ0ccjrqpALiJSQfq4rEgiVOwiiVCxiyRCxS6SiERnvZWo2z6FzYtn7ud26b7VfWVP46gg9pf3ituDkTecsZcf2yAYavpiNT82j8XtjUEeka2Cy1LTVyUe1LFZF2fKHgCs83c3dNPY4qFZIB4S6/18cfvjfhdY06WF7fW7/Mbtoyu7SCJU7CKJULGLJELFLpIIFbtIIlTsIonQ0FsZdBvgr8r1h+OcMSgAJ/pbzoWCES/s4kza6xEsYPmUs28YABxQtCBZbtU1/Njrf/FjpVhU4vDapk57j6DPdbfc7sb6zPfH0F6Z4h/z7nH+GTcd+kGQjWMtZ0/CVa50u+jKLpIIFbtIIlTsIolQsYskQsUukgjdja+wEy41N3baZf6d+mDeBB4OYgNWL24f9C2/z4uvBwfsEsT8ZdXw+1uDfiWI1uSLvOu0fxb0ufAm/9nftcHv92mwu8KCxf4d93XWLG6/9/p6/4Al0JVdJBEqdpFEqNhFEqFiF0mEil0kESp2kUS0ZkeYTQBcDaAXsh1gxpnZxSTXB3ATgL7IlhY7xMxKHSFJ0v3X7+zGDjj8STfWPTjmvocWt3/Qze+zg7sHL7K9gByvj/RjwdyakmztDE8BwJxP/NjHbWwHgPlB7JVguHHLoN+/H+3H9hxc3L7fQc8FR2y71lzZvwBwmpkNBLATgBNJDgQwEsCDZtYfwIP5zyLSQbVY7GY2z8xeyB8vATATwMYADgQwKf+1SQAOqlSSItJ+bXrPTrIvgO0ATAHQq9lOrvORvcwXkQ6q1cVOshuAWwGcYmYfNo+ZmSF7P1/UbwTJBpINTU3l3lxXRFqrVcVOsiuyQr/OzG7LmxeQ7J3HewNYWNTXzMaZWb2Z1dfVRbtsi0gltVjsJIlsi+aZZja2WeguAMPyx8MA3Fn+9ESkXFoz621nAEcCeJnk1LztbACjANxMcjiAtwEcUpkUV167HfS5G7vlBL/fF8GUrV7rFrdfda3f5/jN/Rim+6Ej7wr6ldma/lNVVccGsYeC2FNB7PKJzthbmbVY7Gb2BABvLuae5U1HRCpFn6ATSYSKXSQRKnaRRKjYRRKhYhdJhBac/JpopcTrnfYfBH26upFHznrWjU17xD9i/+CzSRf8T3H7lODDiz2DKWCzJvgxP/vyezjYvmpg0G+G0x6to/nNIHbwCD/2p3FBx8A2275YWsc20pVdJBEqdpFEqNhFEqFiF0mEil0kESp2kURo6O1r7nEjEw67rbD9iUeK2wHglQX+mTYJslg7iD0RxLx5xtG57nw7mlI2x41ciKVBv20KW7MZ0223cRA7dCc/dsUzxe3RLmo9gtiJwfDadkG/v953YhCtDl3ZRRKhYhdJhIpdJBEqdpFEqNhFErES341/LYhF97NnuZHrbipufzQ4WjB/A+8FsWi9r1JW9nz0jsODaPRn0LeEswEfPfLrkvp5+gWxc5w77pGTN/RjZxSuk9yyN1/o7Qe3u6S0g5aRruwiiVCxiyRCxS6SCBW7SCJU7CKJULGLJKLFoTeSmwC4GtmWzAZgnJldTPJcAP8JYNnqZmeb2b2VSrStFi85w43dMfxuN3bRLf4xvSdr7yCPh4PYkiB2eRCLvDN2l8L23gdeV+IRS1O/+8/Lerw/l/VowPRgeC26Ai6d+WM/OGBSyflUQ2vG2b8AcJqZvUCyO4DnSU7OYxeZ2W8rl56IlEtr9nqbB2Be/ngJyZmIZxyKSAfUpvfsJPsim7Y7JW86ieQ0kuNJrlfm3ESkjFpd7CS7IVtU/RQz+xDApQC2ADAY2ZV/jNNvBMkGkg1NTcHi5SJSUa0qdpJdkRX6dWZ2GwCY2QIz+9LMvgJwBYAdi/qa2Tgzqzez+rq6YHcDEamoFoud2TpCVwGYaWZjm7U3/9T/UADTy5+eiJRLa+7G7wzgSAAvk5yat50N4IckByMbjmsE8JOKZBi63Y306Pq4G3thvn/Et4Kzrem0R29OPi0x9j+n+rHzxkRz6aKNjUqwyB+y67f+EW6ssbxZYK/V/Fjvz/zY/U778X/y+0w82FqVU2fTmrvxTwAoWiWww4ypi0jL9Ak6kUSo2EUSoWIXSYSKXSQRKnaRRHSSBSd/X9z81Rtuj2k3+ANbD/ujcog+8zvbaQ9GhXBh8SQ0AMDpjz8V9PxOEKuescOqN7y2fhDrHgyvHXaIH7v6Z78sDgz+VatyWpnoyi6SCBW7SCJU7CKJULGLJELFLpIIFbtIIjrJ0Nt/FTcH/1Rte/QObmzcs0e6sSe7+cc8uF/xcFi/EaP8Tqvu5sc6jHfcSOPrfq/tgiNu4rRPcdoBwP8/BqxTuFpCZshNz5Z41LToyi6SCBW7SCJU7CKJULGLJELFLpIIFbtIIjrJ0Fsp/Llo37nU3+jrO1hZl7t+zo3s1M0f1zo+mFE2KDjbaa8Vt0883e8z9MIrgyMOD2LSGrqyiyRCxS6SCBW7SCJU7CKJULGLJKLFu/Ek1wDwGIDV89//k5mdQ7IfgBsBbADgeQBHmlmwUli1BbeRE3T3Jce5sWeWPhr0jCbyfORGPju2eEbR0AtXzq2VOoPWXNn/AWAPM9sW2fbM+5LcCcAFAC4ys38CsAgaGxHp0FosdssszX/smn8ZgD0ALNsebxKAgyqSoYiURWv3Z++S7+C6EMBkAG8CWGxmy7YTnQNg48qkKCLl0KpiN7MvzWwwgD4AdgQwoLUnIDmCZAPJhqamaHNjEamkNt2NN7PFAB5GtoPBuiSX3eDrA2Cu02ecmdWbWX1d3cr6UVSRjq/FYidZR3Ld/PGaAPYGMBNZ0f8g/7VhAO6sVJIi0n6tmQjTG8Akkl2Q/eNws5ndQ3IGgBtJng/gRQBXVTBPaacDTnq+Akdd242ccKWG2DqaFovdzKahYG1BM3sL2ft3EekE9Ak6kUSo2EUSoWIXSYSKXSQRKnaRRNCsekMkJJsAvJ3/2BPAu1U7uU95LE95LK+z5bGZmRV+eq2qxb7cickGM6uvycmVh/JIMA+9jBdJhIpdJBG1LPZxNTx3c8pjecpjeStNHjV7zy4i1aWX8SKJULGLJKImxU5yX5KvkXyD5Mha5JDn0UjyZZJTSTZU8bzjSS4kOb1Z2/okJ5OclX9fr0Z5nEtybv6cTCU5pAp5bELyYZIzSL5C8uS8varPSZBHVZ8TkmuQfJbkS3kev8rb+5GcktfNTST9DQ2LmFlVvwB0QbaG3ebIdl98CcDAaueR59IIoGcNzrsbgO0BTG/WNhrAyPzxSAAX1CiPcwGcXuXnozeA7fPH3QG8DmBgtZ+TII+qPicACKBb/rgrgCkAdgJwM4DD8vbLABzfluPW4sq+I4A3zOwty9aZvxHAgTXIo2bM7DEA76/QfCCyVXqBKq3W6+RRdWY2z8xeyB8vQbYS0sao8nMS5FFVlin7is61KPaNAcxu9nMtV6Y1AA+QfJ7kiBrlsEwvM5uXP54PoFcNczmJ5LT8ZX7F3040R7IvssVSpqCGz8kKeQBVfk4qsaJz6jfodjGz7QHsB+BEktH2J1Vj2eu0Wo2JXgpgC2QbgswDMKZaJybZDcCtAE4xsw+bx6r5nBTkUfXnxNqxorOnFsU+F8AmzX52V6atNDObm39fCOB21HaZrQUkewNA/n1hLZIwswX5H9pXAK5AlZ4Tkl2RFdh1ZnZb3lz156Qoj1o9J/m527yis6cWxf4cgP75ncXVABwG4K5qJ0FybZLdlz0GsA+A6XGviroL2Sq9QA1X611WXLmhqMJzQpLIFiydaWZjm4Wq+px4eVT7OanYis7VusO4wt3GIcjudL4J4Oc1ymFzZCMBLwF4pZp5ALgB2cvBz5G99xqObIPMBwHMAvBXAOvXKI9rALwMYBqyYutdhTx2QfYSfRqAqfnXkGo/J0EeVX1OAAxCtmLzNGT/sPyy2d/sswDeAHALgNXbclx9XFYkEanfoBNJhopdJBEqdpFEqNhFEqFiF0mEil0kESp2kUT8P7Xipo8g12GdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzytorch.datasets import tensor_data_collate\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True, collate_fn=tensor_data_collate)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size, collate_fn=tensor_data_collate)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.MLPClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    'mdl_class':MLPClassifier,\n",
    "    #'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "classifier: MLP(\n",
      "(0) - Linear(input_dims=3072, output_dims=100, activation=relu, bias=True, in_dropout=0.0, out_drop=0.0)(307,300[p])\n",
      "(1) - Linear(input_dims=100, output_dims=10, activation=linear, bias=True, in_dropout=0.5, out_drop=0.0)(1,010[p])\n",
      ")(308,310[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=mlp°dropout=0.5°outD=10 - id: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=mlp°dropout=0.5°outD=10\n",
      "[x-entropy]\n",
      " - opt-parameters: 308,310[p] - device: cpu\n",
      " - save-mode: only_sup_metric(target_metric_crit: dummy-accuracy)\n",
      " - early_stop_epochcheck_epochs: 1 - early_stop_patience_epochchecks: 100\n",
      "\n",
      "\u001b[31m> deleting previous epochs [1] in: ../save/mdl=mlp°dropout=0.5°outD=10 (id: 0)\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 4/196000 [00:00, 26.99it/s, id: 0 - epoch: 1/1000(4/196)[x-entropy] *loss*: 2.11=1.05+.70(loss/2+loss/3)]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fuzzytorch/handler.py:57: UserWarning: there is not CUDA nor GPUs... Using CPU >:(\n",
      "  warnings.warn('there is not CUDA nor GPUs... Using CPU >:(')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4658/196000 [05:46, 26.23it/s, id: 0 - epoch: 24/1000(150/196)[x-entropy] *loss*: 1.63=.82+.54(loss/2+loss/3)\u001b[34m[train][x-entropy] *loss*: 1.34=.67+.45(loss/2+loss/3) - dummy-accuracy: 10.00 - accuracy: 55.22 (eval-time: 0.1108[mins])\u001b[0m\u001b[31m[val][x-entropy] *loss*: 1.32=.66+.44(loss/2+loss/3) - dummy-accuracy: 10.00 - accuracy: 52.31 (eval-time: 0.0103[mins])\u001b[0m\u001b[33m[stop][x-entropy] epoch_counter: (0/1) - patience: (22/100)\u001b[0m]"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import CrossEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = CrossEntropy('x-entropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "from fuzzytorch import C_\n",
    "trainh_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':int(1e2),\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import NewOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = NewOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handler import ModelTrainHandler\n",
    "from fuzzytorch.train_handlers import NewTrainHandler\n",
    "\n",
    "train_handlers = NewTrainHandler(optimizer, loss, metrics, **trainh_config)\n",
    "\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "}\n",
    "#model_name = model1.get_name()\n",
    "model_train_handler = ModelTrainHandler(model, train_handlers, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
