{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{input: {x: (3, 32, 32)-float32-cpu}, target: {y: ()-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "from fuzzytorch.utils import print_tdict\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "print_tdict(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{input: {x: (256, 3, 32, 32)-float32-cpu}, target: {y: (256)-int64-cpu}}\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print_tdict(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16.32.64 - id: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16.32.64\n",
      "[xentropy]\n",
      " - opt-parameters: 117,072[p] - device: cpu\n",
      " - save-mode: only_sup_metric(target_metric_crit: accuracy)\n",
      " - counter_k: k(0/0) - counter_epoch: val_epoch(0/1)»earlystop_epoch(0/21)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 4/196000 [04:05, 53.51s/it, id: 0 - epoch: 4/1,000(126/196)[xentropy] __loss__: 1.21(loss*2=2.43|loss*3=3.64) #.163[segs]\u001b[34m[train][xentropy] __loss__: 1.10(loss*2=2.20|loss*3=3.30) - accuracy: 60.62 - dummy-accuracy: 10.00 #21.241[segs]\u001b[0m\u001b[31m[val][xentropy] __loss__: 1.12(loss*2=2.24|loss*3=3.36) - accuracy: 60.44 - dummy-accuracy: 10.00 #3.028[segs]\u001b[0m\u001b[33m[stop][xentropy] counter_epoch: val_epoch(0/1)»earlystop_epoch(1/21)\u001b[0m]"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' # see issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' # CPU\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import XEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = XEntropy('xentropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "### GET MODEL\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "### MONITORS\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "from fuzzytorch import C_\n",
    "\n",
    "monitor_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':1e2,\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **monitor_config)\n",
    "\n",
    "### TRAIN\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_time_util_convergence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['opt_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['loss_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['metrics_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from flamingchoripan.counters import Counter\n",
    "\n",
    "d = {\n",
    "'val_epoch_counter_duration':1,\n",
    "'earlystop_epoch_duration':5,\n",
    "}\n",
    "c = Counter(d)\n",
    "for _ in range(50):\n",
    "    print(c, c.check('earlystop_epoch_duration'))\n",
    "    c.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
