{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': (3, 32, 32)-float32-cpu, 'x2': (32)-float32-cpu}, 'target': {'y': ()-int64-cpu, 'y2': (1)-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.transfer_info(*train_dataset_mnist.get_norm_values())\n",
    "\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': (256, 3, 32, 32)-float32-cpu, 'x2': (256, 32)-float32-cpu}, 'target': {'y': (256)-int64-cpu, 'y2': (256, 1)-int64-cpu}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1495) tensor(2.3080)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzytorch.datasets import tensor_data_collate\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True, collate_fn=tensor_data_collate)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size, collate_fn=tensor_data_collate)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64 - id: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64\n",
      "[x-entropy]\n",
      " - opt-parameters: 117,072[p] - device: cpu\n",
      " - save-mode: only_sup_metric(target_metric_crit: accuracy)\n",
      " - counter_k: k(0/0) - counter_epoch: val_epoch(0/0)»earlystop_epoch(0/21)\n",
      "\u001b[31m> (id: 0) deleting previous epochs: [4] in: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 0/196000 [00:00, ?it/s, id: 0 - epoch: 0/1,000(0/196)[x-entropy] __loss__: 2.30=1.15+.77(loss/2+loss/3) #.091[segs]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fuzzytorch/handlers.py:57: UserWarning: there is not CUDA nor GPUs... Using CPU >:(\n",
      "  warnings.warn('there is not CUDA nor GPUs... Using CPU >:(')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 67/196000 [43:52, 39.29s/it, id: 0 - epoch: 67/1,000(195/196)[x-entropy] __loss__: .52=.26+.17(loss/2+loss/3) #.030[segs]\u001b[34m[train][x-entropy] __loss__: .28=.14+.09(loss/2+loss/3) - accuracy: 89.81 - dummy-accuracy: 10.00 #12.987[segs]\u001b[0m\u001b[31m[val][x-entropy] __loss__: .84=.42+.28(loss/2+loss/3) - accuracy: 76.84 - dummy-accuracy: 10.00 #1.918[segs]\u001b[0m\u001b[33m[stop][x-entropy] counter_epoch: val_epoch(0/0)»earlystop_epoch(20/21)\u001b[0m]\n",
      "\u001b[31m*** early stopping ***\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "End of training!!!\n",
      "[x-entropy] best_epoch: 47 - time_per_iteration: .09±.00[segs] - time_per_epoch: 7.46±5.55[mins] - total_time: 35.909490[mins]\n",
      "▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import CrossEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = CrossEntropy('x-entropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "from fuzzytorch import C_\n",
    "trainh_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':int(1e2),\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **trainh_config)\n",
    "\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LossMonitor' object has no attribute 'get_time_util_convergence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-be16fb28cb40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# loss_df opt_df loss_df_epoch metrics_df_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss_monitors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_util_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LossMonitor' object has no attribute 'get_time_util_convergence'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_time_util_convergence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['opt_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['loss_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['metrics_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from flamingchoripan.counters import Counter\n",
    "\n",
    "d = {\n",
    "'val_epoch_counter_duration':1,\n",
    "'earlystop_epoch_duration':5,\n",
    "}\n",
    "c = Counter(d)\n",
    "for _ in range(50):\n",
    "    print(c, c.check('earlystop_epoch_duration'))\n",
    "    c.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
