{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{input: {x: (3, 32, 32)-float32-cpu}, target: {y: ()-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "from fuzzytorch.utils import print_tdict\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "print_tdict(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{input: {x: (256, 3, 32, 32)-float32-cpu}, target: {y: (256)-int64-cpu}}\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print_tdict(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16.32.64(117,072[p])\u001b[0m\n",
      "\u001b[34mid: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16.32.64\n",
      "[xentropy]\n",
      " - opt-parameters: 117,072[p] - device: cpu\n",
      " - save-mode: only_inf_loss\n",
      " - counter_k: k(0/0) - counter_epoch: val_epoch(0/0)»earlystop_epoch(0/21)\n",
      "\u001b[31m> (id: 0) deleting previous epochs: [22] in: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16.32.64\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 0/196000 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fuzzytorch/handlers.py:62: UserWarning: there is not CUDA nor GPUs... Using CPU >:(\n",
      "  warnings.warn('there is not CUDA nor GPUs... Using CPU >:(')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/196000 [21:21, 92.56s/it, id: 0 - epoch: 14/1,000(195/196)[xentropy] b: 80 - __loss__: .778 (loss*2=1.556|loss*3=2.335) #.025[segs]\u001b[34m[train][xentropy] __loss__: .695 (loss*2=1.391|loss*3=2.086) - accuracy: 76.042 - b-accuracy: 76.042 - dummy-accuracy: 10.000 #32.194[segs]\u001b[0m\u001b[31m[val][xentropy] __loss__: .805 (loss*2=1.609|loss*3=2.414) - accuracy: 72.130 - b-accuracy: 72.130 - dummy-accuracy: 10.000 #4.412[segs]\u001b[0m\u001b[33m[stop][xentropy] counter_epoch: val_epoch(0/0)»earlystop_epoch(1/21) (best: 0.805)\u001b[0m]  "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' # see issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' # CPU\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import XEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = XEntropy('xentropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, Accuracy\n",
    "metrics = [\n",
    "    Accuracy('accuracy', balanced=False, **loss_kwargs),\n",
    "    Accuracy('b-accuracy', balanced=True, **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "### GET MODEL\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "### MONITORS\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "from fuzzytorch import C_\n",
    "\n",
    "monitor_config = {\n",
    "    'val_epoch_counter_duration':0, # every k epochs check\n",
    "    #'val_epoch_counter_duration':2, # every k epochs check\n",
    "    #'earlystop_epoch_duration':1e2,\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    #'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **monitor_config)\n",
    "\n",
    "### TRAIN\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_time_util_convergence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['opt_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['loss_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['metrics_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from flamingchoripan.counters import Counter\n",
    "\n",
    "d = {\n",
    "'val_epoch_counter_duration':1,\n",
    "'earlystop_epoch_duration':5,\n",
    "}\n",
    "c = Counter(d)\n",
    "for _ in range(50):\n",
    "    print(c, c.check('earlystop_epoch_duration'))\n",
    "    c.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
