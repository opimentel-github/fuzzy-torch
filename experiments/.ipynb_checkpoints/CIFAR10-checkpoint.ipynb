{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': (3, 32, 32)-float32-cpu, 'x2': (32)-float32-cpu}, 'target': {'y': ()-int64-cpu, 'y2': (1)-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': (256, 3, 32, 32)-float32-cpu, 'x2': (256, 32)-float32-cpu}, 'target': {'y': (256)-int64-cpu, 'y2': (256, 1)-int64-cpu}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1641) tensor(2.2972)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzytorch.datasets import tensor_data_collate\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True, collate_fn=tensor_data_collate)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size, collate_fn=tensor_data_collate)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[32, 32](3)\n",
      "[32, 32](3)>[14, 14](16)\n",
      "[14, 14](16)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-fbd51ef28399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m'save_mode'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mC_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSM_ONLY_SUP_METRIC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m }\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mdl_class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmdl_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mdl_kwargs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m### OPTIMIZER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/experiments/baseline_models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dropout, cnn_features, uses_mlp_classifier, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m                         \u001b[0;31m#'padding_mode':'same',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \t\t}\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml_cnn2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcnn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_cnn_output_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml_cnn2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_cnn_output_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml_cnn2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/fuzzytorch/models/cnn/basics.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dims, input_space, output_dims, embd_dims_list, activation, in_dropout, out_dropout, bias, uses_custom_non_linear_init, cnn_kwargs, pool_kwargs, padding_mode, dropout, last_activation, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \t\t\t}\n\u001b[1;32m    348\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{input_space_}({input_dims_})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m                         \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2DLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dims_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_space_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dims_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcnn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m                         \u001b[0moutput_space_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{input_space_}({input_dims_})>{output_space_}({output_dims_})'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/fuzzytorch/models/cnn/basics.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dims, input_space, output_dims, activation, in_dropout, out_dropout, bias, uses_custom_non_linear_init, cnn_kwargs, pool_kwargs, padding_mode, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m                         \u001b[0mcnn_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                         \u001b[0mpool_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                         \u001b[0mpadding_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \t\t\t)\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/fuzzytorch/models/cnn/basics.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dims, input_space, output_dims, activation, in_dropout, out_dropout, bias, uses_custom_non_linear_init, cnn_kwargs, pool_kwargs, padding_mode, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_custom_non_linear_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muses_custom_non_linear_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_correct_cnn_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen_input_space_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_correct_cnn_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen_input_space_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpadding_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/fuzzytorch/models/cnn/utils.py\u001b[0m in \u001b[0;36mget_correct_cnn_kwargs\u001b[0;34m(len_input_space_shape, cnn_kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen_input_space_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlen_input_space_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mnew_cnn_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_cnn_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import CrossEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = CrossEntropy('x-entropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "from fuzzytorch import C_\n",
    "trainh_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':int(1e2),\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import NewOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = NewOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handler import ModelTrainHandler\n",
    "from fuzzytorch.train_handlers import NewTrainHandler\n",
    "\n",
    "train_handlers = NewTrainHandler(optimizer, loss, metrics, **trainh_config)\n",
    "\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "    #'extra_model_name_dict':{'x':9},\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, train_handlers, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
