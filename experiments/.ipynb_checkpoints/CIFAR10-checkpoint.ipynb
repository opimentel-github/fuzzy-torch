{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': (3, 32, 32)-float32-cpu, 'x2': (32)-float32-cpu}, 'target': {'y': ()-int64-cpu, 'y2': (1)-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': (256, 3, 32, 32)-float32-cpu, 'x2': (256, 32)-float32-cpu}, 'target': {'y': (256)-int64-cpu, 'y2': (256, 1)-int64-cpu}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1543) tensor(2.2823)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzytorch.datasets import tensor_data_collate\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True, collate_fn=tensor_data_collate)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size, collate_fn=tensor_data_collate)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fuzzytorch.train_handlers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3d408916c731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflamingchoripan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprints\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfuzzytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelTrainHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfuzzytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_handlers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLossMonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mloss_monitors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLossMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrainh_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fuzzytorch.train_handlers'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import CrossEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = CrossEntropy('x-entropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "from fuzzytorch import C_\n",
    "trainh_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':int(1e2),\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **trainh_config)\n",
    "\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "    #'extra_model_name_dict':{'x':9},\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
