{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../fuzzy-tools') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b2e174909d40fbb873f0c0571f9160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-10-python.tar.gz to ../data/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{input: {x: (3, 32, 32)-float32-cpu}, target: {y: ()-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "from fuzzytorch.utils import print_tdict\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "print_tdict(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{input: {x: (256, 3, 32, 32)-float32-cpu}, target: {y: (256)-int64-cpu}}\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print_tdict(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fuzzytools.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16.32.64(117,072[p])\u001b[0m\n",
      "\u001b[34mid: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16.32.64\n",
      "[xentropy]\n",
      " - opt-parameters: 117,072[p] - device: cpu\n",
      " - save-mode: only_inf_loss\n",
      " - counter_k: k(0/0) - counter_epoch: val_epoch(0/0)»earlystop_epoch(0/21)\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 0/196000 [00:00, ?it/s, id: 0 - epoch: 0/1,000(0/196)[xentropy] b: 256 - __loss__: 2.31 (loss*2=4.61|loss*3=6.92) #.064[segs]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fuzzytorch/handlers.py:62: UserWarning: there is not CUDA nor GPUs... Using CPU >:(\n",
      "  warnings.warn('there is not CUDA nor GPUs... Using CPU >:(')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 23/196000 [04:48, 12.56s/it, id: 0 - epoch: 23/1,000(0/196)[xentropy] b: 256 - __loss__: 2.03 (loss*2=4.07|loss*3=6.10) #.066[segs]\u001b[34m[train][xentropy] __loss__: 1.94 (loss*2=3.88|loss*3=5.82) - accuracy: 28.31 - b-accuracy: 28.31 - dummy-accuracy: 10.00 #12.201[segs]\u001b[0m\u001b[31m[val][xentropy] __loss__: 1.94 (loss*2=3.88|loss*3=5.82) - accuracy: 28.64 - b-accuracy: 28.64 - dummy-accuracy: 10.00 #1.626[segs]\u001b[0m\u001b[33m[stop][xentropy] counter_epoch: val_epoch(0/0)»earlystop_epoch(1/21)\u001b[0m]\n",
      "\u001b[31m*** ctrl+c ***\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "End of training!!!\n",
      "[xentropy] best_epoch: 22 - time_per_iteration: .05±.01[segs] - time_per_epoch: 6.09±4.69[mins] - total_time: 4.709857[mins]\n",
      "▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' # see issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' # CPU\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import XEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = XEntropy('xentropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, Accuracy\n",
    "metrics = [\n",
    "    Accuracy('accuracy', balanced=False, **loss_kwargs),\n",
    "    Accuracy('b-accuracy', balanced=True, **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "### GET MODEL\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "### MONITORS\n",
    "from fuzzytools.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "from fuzzytorch import C_\n",
    "\n",
    "monitor_config = {\n",
    "    'val_epoch_counter_duration':0, # every k epochs check\n",
    "    #'val_epoch_counter_duration':2, # every k epochs check\n",
    "    #'earlystop_epoch_duration':1e2,\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    #'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **monitor_config)\n",
    "\n",
    "### TRAIN\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LossMonitor' object has no attribute 'get_time_util_convergence'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-be16fb28cb40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# loss_df opt_df loss_df_epoch metrics_df_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss_monitors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_util_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'LossMonitor' object has no attribute 'get_time_util_convergence'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_time_util_convergence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['opt_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['loss_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['metrics_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from fuzzytools.counters import Counter\n",
    "\n",
    "d = {\n",
    "'val_epoch_counter_duration':1,\n",
    "'earlystop_epoch_duration':5,\n",
    "}\n",
    "c = Counter(d)\n",
    "for _ in range(50):\n",
    "    print(c, c.check('earlystop_epoch_duration'))\n",
    "    c.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
