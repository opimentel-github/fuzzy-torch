{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': tensor([[[ 0.3112,  0.4327,  0.6139,  ..., -1.1710, -1.2841, -1.0374],\n",
      "         [-0.0600, -0.0324, -0.0495,  ..., -1.7299, -2.0209, -1.6956],\n",
      "         [-0.2751, -0.0280, -0.1842,  ..., -1.2465, -1.6644, -1.6417],\n",
      "         ...,\n",
      "         [-1.1215, -1.1530,  0.6198,  ...,  1.1831,  1.1540,  1.2996],\n",
      "         [-0.6677, -0.4680,  0.9060,  ...,  0.9577,  0.8533,  0.9285],\n",
      "         [-0.0258,  0.3886,  1.4185,  ...,  0.8354,  0.6071,  0.8451]],\n",
      "\n",
      "        [[ 0.0039, -0.0317,  0.1638,  ..., -1.1921, -1.1001, -0.9637],\n",
      "         [-0.5855, -0.6803, -0.5641,  ..., -1.9043, -2.0167, -1.7059],\n",
      "         [-0.8040, -0.6591, -0.6540,  ..., -1.5750, -1.8989, -1.6354],\n",
      "         ...,\n",
      "         [-1.3540, -1.3899,  0.2312,  ...,  0.5844,  0.4936,  0.7546],\n",
      "         [-1.1479, -0.9037,  0.3839,  ...,  0.3096,  0.1001,  0.2264],\n",
      "         [-0.5255, -0.0448,  1.0294,  ...,  0.4353,  0.0649,  0.2373]],\n",
      "\n",
      "        [[-0.1349, -0.1184, -0.0777,  ..., -1.1103, -0.9972, -0.7678],\n",
      "         [-0.8804, -0.8601, -0.9446,  ..., -1.6930, -1.6794, -1.4089],\n",
      "         [-1.1028, -0.9274, -1.0286,  ..., -1.6595, -1.7918, -1.4845],\n",
      "         ...,\n",
      "         [-1.3568, -1.6415, -0.6979,  ..., -1.3252, -1.2008, -0.3472],\n",
      "         [-1.1834, -1.1646, -0.2594,  ..., -1.2970, -1.0513, -0.2639],\n",
      "         [-0.6342, -0.4937,  0.3859,  ..., -0.4333, -0.2693,  0.0590]]]), 'x2': tensor([ 0.3112,  0.4327,  0.6139,  0.5032,  0.4857,  0.6466,  0.6445,  0.5164,\n",
      "         0.2155,  0.1276,  0.1716,  0.1960,  0.1724, -0.0401,  0.1269,  0.1590,\n",
      "         0.1001,  0.1758,  0.3401,  0.3148,  0.0293,  0.0964,  0.3910,  0.4826,\n",
      "         0.2997,  0.1876, -0.1666, -0.5097, -0.9268, -1.1710, -1.2841, -1.0374])}, 'target': {'y': tensor(6), 'y2': tensor([6])}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': tensor([[[[ 1.6343e+00,  1.5874e+00,  1.6171e+00,  ...,  9.1343e-01,\n",
      "            8.5872e-01,  7.1958e-01],\n",
      "          [ 1.5670e+00,  1.6468e+00,  1.6449e+00,  ...,  8.6703e-01,\n",
      "            7.7979e-01,  8.0789e-01],\n",
      "          [ 1.4740e+00,  1.6001e+00,  1.5990e+00,  ...,  6.9899e-01,\n",
      "            7.8610e-01,  7.8499e-01],\n",
      "          ...,\n",
      "          [ 1.1217e+00,  1.2182e+00,  1.1589e+00,  ...,  1.5836e+00,\n",
      "            1.6509e+00,  1.4053e+00],\n",
      "          [ 1.0990e+00,  1.0672e+00,  1.0627e+00,  ...,  8.8321e-01,\n",
      "            8.7938e-01,  1.1428e+00],\n",
      "          [ 1.1774e+00,  1.1780e+00,  1.1763e+00,  ...,  7.8177e-01,\n",
      "            8.8441e-01,  1.4050e+00]],\n",
      "\n",
      "         [[ 1.5306e+00,  1.5744e+00,  1.5142e+00,  ...,  9.0437e-01,\n",
      "            8.6648e-01,  8.3376e-01],\n",
      "          [ 1.5630e+00,  1.6055e+00,  1.5802e+00,  ...,  8.0433e-01,\n",
      "            7.6085e-01,  7.7033e-01],\n",
      "          [ 1.5697e+00,  1.5520e+00,  1.4457e+00,  ...,  5.7469e-01,\n",
      "            7.6870e-01,  6.7455e-01],\n",
      "          ...,\n",
      "          [ 1.1190e+00,  1.0975e+00,  1.1026e+00,  ...,  1.5849e+00,\n",
      "            1.7197e+00,  1.3360e+00],\n",
      "          [ 9.3875e-01,  9.5096e-01,  9.9961e-01,  ...,  7.8763e-01,\n",
      "            7.9981e-01,  1.1896e+00],\n",
      "          [ 1.1666e+00,  1.1378e+00,  1.1535e+00,  ...,  8.2331e-01,\n",
      "            8.6180e-01,  1.4053e+00]],\n",
      "\n",
      "         [[ 1.5256e+00,  1.4423e+00,  1.5296e+00,  ...,  7.5501e-01,\n",
      "            8.7462e-01,  8.6411e-01],\n",
      "          [ 1.4300e+00,  1.4976e+00,  1.4776e+00,  ...,  7.2832e-01,\n",
      "            7.1288e-01,  7.3479e-01],\n",
      "          [ 1.4352e+00,  1.4417e+00,  1.4324e+00,  ...,  5.7613e-01,\n",
      "            6.8105e-01,  6.9475e-01],\n",
      "          ...,\n",
      "          [ 1.0480e+00,  1.0201e+00,  1.0678e+00,  ...,  1.3699e+00,\n",
      "            1.2876e+00,  1.2052e+00],\n",
      "          [ 9.3404e-01,  8.9154e-01,  8.3927e-01,  ...,  7.0790e-01,\n",
      "            6.0780e-01,  1.1755e+00],\n",
      "          [ 1.0724e+00,  9.8948e-01,  1.0369e+00,  ...,  7.7741e-01,\n",
      "            7.7465e-01,  1.4806e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7247e-02, -3.6850e-02, -2.2705e-02,  ...,  1.0190e-01,\n",
      "            7.2545e-02,  8.9105e-02],\n",
      "          [-1.9111e-01, -1.6247e-01, -1.0093e-01,  ...,  3.5526e-03,\n",
      "            4.7140e-02,  3.8086e-02],\n",
      "          [-1.4278e-01, -1.7328e-01, -6.0480e-03,  ..., -2.9102e-02,\n",
      "            6.1852e-02,  1.4600e-01],\n",
      "          ...,\n",
      "          [ 6.3926e-01,  7.2138e-01,  7.4208e-01,  ..., -1.7472e-01,\n",
      "           -2.8165e-01, -3.6725e-01],\n",
      "          [ 8.1697e-01,  6.1664e-01,  6.2847e-01,  ..., -1.8355e-02,\n",
      "            1.8692e-02,  1.2529e-02],\n",
      "          [ 4.9661e-01,  5.6429e-01,  4.9476e-01,  ...,  2.5838e-01,\n",
      "            2.4620e-01,  4.6039e-01]],\n",
      "\n",
      "         [[ 2.0501e-01,  9.5104e-02,  1.0606e-01,  ...,  3.2616e-01,\n",
      "            3.7519e-01,  4.0485e-01],\n",
      "          [ 1.4908e-01,  1.0760e-01,  1.2643e-01,  ...,  1.8455e-01,\n",
      "            2.3931e-01,  3.8261e-01],\n",
      "          [ 8.1710e-02,  1.5538e-01,  2.3555e-01,  ...,  2.9601e-01,\n",
      "            3.2050e-01,  3.6227e-01],\n",
      "          ...,\n",
      "          [ 3.5100e-01,  3.8160e-01,  4.3362e-01,  ...,  3.8925e-02,\n",
      "           -1.4246e-01, -1.4275e-01],\n",
      "          [ 5.2393e-01,  2.4837e-01,  3.6638e-01,  ...,  1.7129e-01,\n",
      "            1.3327e-01,  1.8893e-01],\n",
      "          [ 6.4371e-02,  2.7808e-01,  1.9804e-01,  ...,  1.8445e-01,\n",
      "            2.4589e-01,  5.2592e-01]],\n",
      "\n",
      "         [[ 4.2517e-01,  2.5382e-01,  3.2151e-01,  ...,  4.0369e-01,\n",
      "            5.2745e-01,  4.7711e-01],\n",
      "          [ 3.6938e-01,  2.7530e-01,  4.2393e-01,  ...,  3.1438e-01,\n",
      "            3.7636e-01,  4.5378e-01],\n",
      "          [ 3.6679e-01,  3.8692e-01,  3.8717e-01,  ...,  2.2911e-01,\n",
      "            5.0670e-01,  4.2973e-01],\n",
      "          ...,\n",
      "          [-2.8147e-01, -3.2460e-01, -5.6028e-02,  ...,  1.5133e-01,\n",
      "            1.1388e-01,  1.0076e-01],\n",
      "          [-1.6477e-01, -1.7357e-01, -2.2025e-01,  ...,  2.5613e-01,\n",
      "            2.3760e-01,  1.8646e-01],\n",
      "          [-4.2536e-01, -3.5780e-01, -3.2370e-01,  ...,  1.8616e-01,\n",
      "            1.9371e-01,  3.2399e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1618e-01,  1.4158e+00,  7.9575e-01,  ...,  2.0878e-01,\n",
      "           -2.7991e-01,  3.6547e-02],\n",
      "          [ 5.0806e-01,  1.2558e+00,  4.9654e-01,  ...,  1.8047e-01,\n",
      "            6.2248e-02, -4.0655e-02],\n",
      "          [ 5.5779e-01,  7.6894e-01, -2.9815e-01,  ...,  3.8870e-01,\n",
      "            3.8133e-02,  4.9862e-02],\n",
      "          ...,\n",
      "          [-7.1447e-01, -8.3264e-01, -7.3407e-01,  ..., -3.7737e-01,\n",
      "           -3.4510e-01, -4.0020e-01],\n",
      "          [-3.8318e-01, -3.3950e-01, -2.6017e-01,  ..., -4.5812e-01,\n",
      "           -4.1721e-01, -5.0560e-01],\n",
      "          [-1.6399e-01, -3.7496e-01, -6.5021e-01,  ..., -4.9492e-01,\n",
      "           -3.4574e-01, -3.8083e-01]],\n",
      "\n",
      "         [[ 5.3822e-01,  1.2812e+00,  5.0916e-01,  ..., -2.7620e-01,\n",
      "           -6.9903e-01, -3.5645e-01],\n",
      "          [ 4.5281e-01,  1.1555e+00,  3.7849e-01,  ..., -1.1018e-01,\n",
      "           -1.6118e-01, -1.6871e-01],\n",
      "          [ 2.7487e-01,  7.8553e-01, -4.6535e-01,  ...,  8.6947e-02,\n",
      "            1.3596e-01,  4.7332e-02],\n",
      "          ...,\n",
      "          [-1.0230e+00, -1.1121e+00, -1.0637e+00,  ..., -6.8060e-01,\n",
      "           -6.0816e-01, -5.2995e-01],\n",
      "          [-6.4177e-01, -4.7795e-01, -5.8501e-01,  ..., -5.6776e-01,\n",
      "           -6.0883e-01, -6.3134e-01],\n",
      "          [-5.0774e-01, -6.4684e-01, -8.8374e-01,  ..., -5.8694e-01,\n",
      "           -6.4414e-01, -5.7302e-01]],\n",
      "\n",
      "         [[ 6.5097e-01,  1.5332e+00,  5.6877e-01,  ..., -4.3510e-01,\n",
      "           -4.9345e-01, -1.2823e-01],\n",
      "          [ 5.6070e-01,  1.1673e+00,  4.7149e-01,  ..., -1.0281e-01,\n",
      "            9.9822e-02,  9.2982e-02],\n",
      "          [ 4.3026e-01,  7.8753e-01, -2.9154e-01,  ...,  1.3746e-01,\n",
      "            3.4984e-01,  4.7473e-01],\n",
      "          ...,\n",
      "          [-8.7504e-01, -9.9741e-01, -1.1165e+00,  ..., -2.6314e-01,\n",
      "           -2.2454e-01, -2.8465e-01],\n",
      "          [-6.6288e-01, -5.2816e-01, -6.1707e-01,  ..., -2.8082e-01,\n",
      "           -3.0292e-01, -2.8023e-01],\n",
      "          [-4.3330e-01, -5.6414e-01, -6.9888e-01,  ..., -2.6978e-01,\n",
      "           -3.7609e-01, -2.5071e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.5911e-01,  8.9944e-01,  1.8566e-01,  ...,  1.3946e-01,\n",
      "            9.8725e-01,  3.4938e-01],\n",
      "          [ 9.5837e-01,  8.8989e-01,  3.3005e-01,  ..., -1.1174e-01,\n",
      "            1.1398e+00,  1.0417e+00],\n",
      "          [ 1.1940e+00,  9.2106e-01,  6.9370e-01,  ...,  1.1975e-01,\n",
      "            1.2870e+00,  9.4758e-01],\n",
      "          ...,\n",
      "          [-8.5731e-01, -1.3183e+00, -1.4702e+00,  ..., -1.6896e+00,\n",
      "           -1.6928e+00, -1.5812e+00],\n",
      "          [-1.0035e+00, -1.3894e+00, -1.5465e+00,  ..., -1.6323e+00,\n",
      "           -1.5711e+00, -1.7082e+00],\n",
      "          [-1.0877e+00, -1.5150e+00, -1.4610e+00,  ..., -1.5782e+00,\n",
      "           -1.5393e+00, -1.5990e+00]],\n",
      "\n",
      "         [[ 9.7242e-01,  1.1652e+00,  5.2755e-01,  ...,  3.0720e-01,\n",
      "            1.2249e+00,  6.5166e-01],\n",
      "          [ 1.2397e+00,  1.2381e+00,  6.2240e-01,  ...,  1.3217e-01,\n",
      "            1.4140e+00,  1.1960e+00],\n",
      "          [ 1.3192e+00,  1.3285e+00,  1.0319e+00,  ...,  3.1012e-01,\n",
      "            1.6098e+00,  1.3702e+00],\n",
      "          ...,\n",
      "          [-7.4146e-01, -1.3980e+00, -1.3653e+00,  ..., -1.5478e+00,\n",
      "           -1.5955e+00, -1.5283e+00],\n",
      "          [-9.7680e-01, -1.4740e+00, -1.5200e+00,  ..., -1.4772e+00,\n",
      "           -1.5788e+00, -1.5894e+00],\n",
      "          [-1.0073e+00, -1.4517e+00, -1.3813e+00,  ..., -1.4353e+00,\n",
      "           -1.4202e+00, -1.4073e+00]],\n",
      "\n",
      "         [[ 4.6634e-01,  7.9316e-01,  5.3164e-02,  ..., -7.3776e-02,\n",
      "            7.7669e-01,  3.1985e-01],\n",
      "          [ 7.2440e-01,  8.0153e-01,  3.4488e-01,  ..., -1.8570e-01,\n",
      "            9.6706e-01,  1.0134e+00],\n",
      "          [ 8.6356e-01,  8.4668e-01,  6.8228e-01,  ..., -1.2149e-02,\n",
      "            1.2969e+00,  1.2224e+00],\n",
      "          ...,\n",
      "          [-6.2160e-01, -1.2183e+00, -1.2904e+00,  ..., -1.1056e+00,\n",
      "           -1.1138e+00, -1.1206e+00],\n",
      "          [-7.9758e-01, -1.2735e+00, -1.2697e+00,  ..., -1.0976e+00,\n",
      "           -1.1894e+00, -1.1903e+00],\n",
      "          [-8.4337e-01, -1.3123e+00, -1.2181e+00,  ..., -1.0177e+00,\n",
      "           -9.9904e-01, -1.0237e+00]]],\n",
      "\n",
      "\n",
      "        [[[-9.8682e-01, -1.0827e+00, -9.8124e-01,  ..., -1.8868e-01,\n",
      "           -1.7612e-01, -1.8685e-01],\n",
      "          [-2.0579e-01, -4.2267e-01, -5.5528e-01,  ..., -2.2289e-01,\n",
      "           -2.1238e-01, -1.9403e-01],\n",
      "          [ 5.1795e-01,  4.9225e-01,  3.8347e-01,  ..., -3.4240e-01,\n",
      "           -1.3847e-01, -1.6566e-01],\n",
      "          ...,\n",
      "          [ 6.0785e-01,  7.1488e-01,  6.7809e-01,  ...,  5.8497e-01,\n",
      "            5.9655e-01,  4.9056e-01],\n",
      "          [ 6.7187e-01,  7.1832e-01,  8.2425e-01,  ...,  6.2845e-01,\n",
      "            5.3179e-01,  4.7310e-01],\n",
      "          [ 5.6950e-01,  5.7049e-01,  5.6731e-01,  ...,  5.3386e-01,\n",
      "            5.4803e-01,  4.5271e-01]],\n",
      "\n",
      "         [[-9.4157e-01, -1.0735e+00, -1.0618e+00,  ..., -2.0442e-01,\n",
      "           -3.2154e-01, -2.4687e-01],\n",
      "          [-9.2150e-02, -4.9506e-01, -6.2672e-01,  ..., -1.2667e-01,\n",
      "           -2.3683e-01, -3.0936e-01],\n",
      "          [ 6.4069e-01,  7.1605e-01,  4.2189e-01,  ..., -4.6117e-01,\n",
      "           -2.2311e-01, -3.4189e-01],\n",
      "          ...,\n",
      "          [ 7.1745e-01,  7.7558e-01,  7.3111e-01,  ...,  6.7078e-01,\n",
      "            7.1717e-01,  5.2301e-01],\n",
      "          [ 7.4463e-01,  7.5197e-01,  6.5981e-01,  ...,  6.8620e-01,\n",
      "            6.8257e-01,  4.4353e-01],\n",
      "          [ 6.6592e-01,  8.2136e-01,  7.3694e-01,  ...,  6.7135e-01,\n",
      "            5.9265e-01,  5.8705e-01]],\n",
      "\n",
      "         [[-8.8293e-01, -9.2709e-01, -8.3263e-01,  ..., -7.8629e-02,\n",
      "           -2.2779e-01, -1.8179e-01],\n",
      "          [-1.1634e-01, -3.5242e-01, -5.4952e-01,  ...,  2.3725e-02,\n",
      "           -3.0306e-01, -2.3085e-01],\n",
      "          [ 6.7917e-01,  6.8437e-01,  5.8974e-01,  ..., -3.0604e-01,\n",
      "           -2.4826e-01, -2.7246e-01],\n",
      "          ...,\n",
      "          [ 9.5714e-01,  1.0070e+00,  9.6900e-01,  ...,  9.1082e-01,\n",
      "            8.4954e-01,  8.0678e-01],\n",
      "          [ 9.2029e-01,  9.7358e-01,  9.8368e-01,  ...,  8.8047e-01,\n",
      "            8.5753e-01,  7.4411e-01],\n",
      "          [ 8.6008e-01,  9.6125e-01,  9.0992e-01,  ...,  8.5657e-01,\n",
      "            8.6528e-01,  8.4767e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.2608e-01, -2.5597e-01, -4.9140e-03,  ...,  1.2494e+00,\n",
      "            2.8240e-01, -2.4100e-01],\n",
      "          [-3.0562e-01, -1.7845e-01, -2.1439e-01,  ...,  7.3656e-01,\n",
      "            2.3272e-01, -5.6143e-01],\n",
      "          [-2.9577e-01, -2.0172e-01, -2.8241e-01,  ...,  2.6122e-01,\n",
      "           -9.1022e-02, -4.5960e-01],\n",
      "          ...,\n",
      "          [ 9.2594e-02,  6.8071e-02, -4.9254e-02,  ...,  4.4552e-01,\n",
      "            6.9532e-01,  6.7832e-01],\n",
      "          [ 8.8986e-02,  3.0939e-02, -1.8113e-01,  ...,  6.2105e-01,\n",
      "            6.8078e-01,  7.2484e-01],\n",
      "          [ 1.1918e-01,  1.4657e-03, -3.3632e-02,  ...,  2.7847e-01,\n",
      "            3.3651e-01,  3.3691e-01]],\n",
      "\n",
      "         [[-6.4128e-01, -5.1376e-01, -3.7266e-01,  ...,  1.1493e+00,\n",
      "            8.5894e-02, -3.2950e-01],\n",
      "          [-5.9743e-01, -4.3309e-01, -6.1368e-01,  ...,  6.2508e-01,\n",
      "           -9.8268e-02, -6.1231e-01],\n",
      "          [-4.7280e-01, -4.7952e-01, -7.6253e-01,  ...,  7.4469e-02,\n",
      "           -2.8375e-01, -5.8549e-01],\n",
      "          ...,\n",
      "          [ 1.5718e-01,  1.1968e-01,  2.0755e-02,  ...,  6.0800e-01,\n",
      "            6.7155e-01,  6.3658e-01],\n",
      "          [ 1.0992e-01,  4.7535e-02, -2.3163e-01,  ...,  6.4398e-01,\n",
      "            7.3505e-01,  7.1416e-01],\n",
      "          [ 9.5434e-02,  6.3848e-02,  2.1801e-02,  ...,  3.2943e-01,\n",
      "            4.3945e-01,  3.5344e-01]],\n",
      "\n",
      "         [[-7.3820e-01, -8.8010e-01, -8.0750e-01,  ...,  9.9893e-01,\n",
      "           -2.7539e-01, -8.6990e-01],\n",
      "          [-7.0703e-01, -7.2119e-01, -1.0533e+00,  ...,  5.2096e-01,\n",
      "           -3.7740e-01, -1.0020e+00],\n",
      "          [-7.0574e-01, -8.4234e-01, -1.0494e+00,  ..., -1.8373e-01,\n",
      "           -5.5179e-01, -1.0457e+00],\n",
      "          ...,\n",
      "          [ 1.9905e-01,  8.7174e-02,  1.6543e-01,  ...,  6.1944e-01,\n",
      "            6.9000e-01,  6.9355e-01],\n",
      "          [ 1.8519e-01,  1.4202e-01, -1.3100e-01,  ...,  5.5986e-01,\n",
      "            7.3798e-01,  7.3276e-01],\n",
      "          [ 2.9256e-01,  2.1004e-01,  2.5768e-01,  ...,  3.9659e-01,\n",
      "            5.0992e-01,  4.4560e-01]]]]), 'x2': tensor([[ 1.6343,  1.5874,  1.6171,  ...,  0.9134,  0.8587,  0.7196],\n",
      "        [ 0.0872, -0.0368, -0.0227,  ...,  0.1019,  0.0725,  0.0891],\n",
      "        [ 0.7162,  1.4158,  0.7958,  ...,  0.2088, -0.2799,  0.0365],\n",
      "        ...,\n",
      "        [ 0.7591,  0.8994,  0.1857,  ...,  0.1395,  0.9873,  0.3494],\n",
      "        [-0.9868, -1.0827, -0.9812,  ..., -0.1887, -0.1761, -0.1868],\n",
      "        [-0.4261, -0.2560, -0.0049,  ...,  1.2494,  0.2824, -0.2410]])}, 'target': {'y': tensor([5, 0, 1, 6, 6, 9, 1, 0, 9, 6, 0, 8, 0, 4, 7, 7, 8, 5, 3, 0, 7, 6, 6, 9,\n",
      "        6, 9, 8, 4, 8, 3, 5, 2, 7, 1, 9, 2, 2, 7, 4, 8, 2, 9, 3, 1, 2, 1, 1, 9,\n",
      "        1, 6, 1, 4, 2, 8, 3, 9, 4, 0, 1, 8, 1, 5, 8, 4, 7, 1, 8, 3, 0, 4, 0, 1,\n",
      "        2, 0, 8, 1, 7, 1, 5, 3, 3, 5, 2, 6, 7, 4, 4, 7, 5, 5, 9, 7, 5, 3, 3, 7,\n",
      "        8, 2, 5, 5, 3, 8, 5, 5, 7, 4, 5, 1, 2, 2, 8, 9, 4, 7, 7, 4, 5, 3, 4, 1,\n",
      "        8, 3, 4, 0, 8, 2, 7, 3, 7, 6, 2, 1, 2, 7, 2, 5, 5, 3, 8, 9, 1, 8, 2, 1,\n",
      "        9, 9, 9, 5, 8, 1, 9, 9, 5, 4, 8, 5, 0, 8, 4, 4, 2, 7, 6, 4, 5, 0, 8, 3,\n",
      "        5, 1, 7, 1, 6, 4, 8, 2, 0, 8, 8, 6, 4, 9, 4, 4, 7, 8, 0, 3, 7, 8, 0, 6,\n",
      "        4, 1, 4, 1, 6, 7, 8, 5, 5, 3, 6, 5, 5, 0, 0, 0, 4, 6, 3, 7, 8, 0, 1, 4,\n",
      "        8, 1, 0, 1, 4, 0, 6, 2, 0, 9, 5, 8, 5, 6, 5, 0, 5, 0, 2, 8, 3, 1, 5, 7,\n",
      "        4, 2, 8, 4, 5, 5, 2, 1, 0, 6, 8, 1, 1, 2, 7, 9]), 'y2': tensor([[5],\n",
      "        [0],\n",
      "        [1],\n",
      "        [6],\n",
      "        [6],\n",
      "        [9],\n",
      "        [1],\n",
      "        [0],\n",
      "        [9],\n",
      "        [6],\n",
      "        [0],\n",
      "        [8],\n",
      "        [0],\n",
      "        [4],\n",
      "        [7],\n",
      "        [7],\n",
      "        [8],\n",
      "        [5],\n",
      "        [3],\n",
      "        [0],\n",
      "        [7],\n",
      "        [6],\n",
      "        [6],\n",
      "        [9],\n",
      "        [6],\n",
      "        [9],\n",
      "        [8],\n",
      "        [4],\n",
      "        [8],\n",
      "        [3],\n",
      "        [5],\n",
      "        [2],\n",
      "        [7],\n",
      "        [1],\n",
      "        [9],\n",
      "        [2],\n",
      "        [2],\n",
      "        [7],\n",
      "        [4],\n",
      "        [8],\n",
      "        [2],\n",
      "        [9],\n",
      "        [3],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [9],\n",
      "        [1],\n",
      "        [6],\n",
      "        [1],\n",
      "        [4],\n",
      "        [2],\n",
      "        [8],\n",
      "        [3],\n",
      "        [9],\n",
      "        [4],\n",
      "        [0],\n",
      "        [1],\n",
      "        [8],\n",
      "        [1],\n",
      "        [5],\n",
      "        [8],\n",
      "        [4],\n",
      "        [7],\n",
      "        [1],\n",
      "        [8],\n",
      "        [3],\n",
      "        [0],\n",
      "        [4],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [8],\n",
      "        [1],\n",
      "        [7],\n",
      "        [1],\n",
      "        [5],\n",
      "        [3],\n",
      "        [3],\n",
      "        [5],\n",
      "        [2],\n",
      "        [6],\n",
      "        [7],\n",
      "        [4],\n",
      "        [4],\n",
      "        [7],\n",
      "        [5],\n",
      "        [5],\n",
      "        [9],\n",
      "        [7],\n",
      "        [5],\n",
      "        [3],\n",
      "        [3],\n",
      "        [7],\n",
      "        [8],\n",
      "        [2],\n",
      "        [5],\n",
      "        [5],\n",
      "        [3],\n",
      "        [8],\n",
      "        [5],\n",
      "        [5],\n",
      "        [7],\n",
      "        [4],\n",
      "        [5],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [8],\n",
      "        [9],\n",
      "        [4],\n",
      "        [7],\n",
      "        [7],\n",
      "        [4],\n",
      "        [5],\n",
      "        [3],\n",
      "        [4],\n",
      "        [1],\n",
      "        [8],\n",
      "        [3],\n",
      "        [4],\n",
      "        [0],\n",
      "        [8],\n",
      "        [2],\n",
      "        [7],\n",
      "        [3],\n",
      "        [7],\n",
      "        [6],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [7],\n",
      "        [2],\n",
      "        [5],\n",
      "        [5],\n",
      "        [3],\n",
      "        [8],\n",
      "        [9],\n",
      "        [1],\n",
      "        [8],\n",
      "        [2],\n",
      "        [1],\n",
      "        [9],\n",
      "        [9],\n",
      "        [9],\n",
      "        [5],\n",
      "        [8],\n",
      "        [1],\n",
      "        [9],\n",
      "        [9],\n",
      "        [5],\n",
      "        [4],\n",
      "        [8],\n",
      "        [5],\n",
      "        [0],\n",
      "        [8],\n",
      "        [4],\n",
      "        [4],\n",
      "        [2],\n",
      "        [7],\n",
      "        [6],\n",
      "        [4],\n",
      "        [5],\n",
      "        [0],\n",
      "        [8],\n",
      "        [3],\n",
      "        [5],\n",
      "        [1],\n",
      "        [7],\n",
      "        [1],\n",
      "        [6],\n",
      "        [4],\n",
      "        [8],\n",
      "        [2],\n",
      "        [0],\n",
      "        [8],\n",
      "        [8],\n",
      "        [6],\n",
      "        [4],\n",
      "        [9],\n",
      "        [4],\n",
      "        [4],\n",
      "        [7],\n",
      "        [8],\n",
      "        [0],\n",
      "        [3],\n",
      "        [7],\n",
      "        [8],\n",
      "        [0],\n",
      "        [6],\n",
      "        [4],\n",
      "        [1],\n",
      "        [4],\n",
      "        [1],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [5],\n",
      "        [5],\n",
      "        [3],\n",
      "        [6],\n",
      "        [5],\n",
      "        [5],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [4],\n",
      "        [6],\n",
      "        [3],\n",
      "        [7],\n",
      "        [8],\n",
      "        [0],\n",
      "        [1],\n",
      "        [4],\n",
      "        [8],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [4],\n",
      "        [0],\n",
      "        [6],\n",
      "        [2],\n",
      "        [0],\n",
      "        [9],\n",
      "        [5],\n",
      "        [8],\n",
      "        [5],\n",
      "        [6],\n",
      "        [5],\n",
      "        [0],\n",
      "        [5],\n",
      "        [0],\n",
      "        [2],\n",
      "        [8],\n",
      "        [3],\n",
      "        [1],\n",
      "        [5],\n",
      "        [7],\n",
      "        [4],\n",
      "        [2],\n",
      "        [8],\n",
      "        [4],\n",
      "        [5],\n",
      "        [5],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [6],\n",
      "        [8],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [7],\n",
      "        [9]])}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1586) tensor(2.3156)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYCUlEQVR4nO3de5RV1X0H8O8XHJ6DIk+Rh4MoIkkUyQgYrVGCVo0p2lRjYoypJmSlIY1ZGsoyXVVT02gaNelK1I7Raqj1EZH4iE0l1oZofY3yBpWHIw95v+Qlj+HXP85hdSDnt+dy595zZ9jfz1qz5s7+3X3O5jC/uefufffeNDOIyOGvXaUbICL5ULKLRELJLhIJJbtIJJTsIpFQsotEQskuEgklextFsoHkuAqe/0GStx7C8weR3HbQl5G8vpztlP93RKUbIJVBsr2ZNeZ1PjNbBqC6yfkHA1gMYGpebYidXtnbIJJTAAwC8Ez6CjkpLf81ydUkt5CcQfJjTeo8SPIeks+R3A7gXJI9ST5D8kOSb5C8leRLTeoMIzmd5EaS75C8PC2fAOBKAJPS8z9TxD/jKwBmmFlD8VdCDomZ6asNfgFoADDuoLJrAHQD0BHATwHMahJ7EMAWAGci+SPfCcCj6VcXAMMBLAfwUvr8runPf43kDvA0AOsBDG9yvFsPOv/dAO4uoO0EsATAVyt9HWP60m38YcTMHtj/mOTNADaRPMrMtqTFT5nZy2l8D4DPA/i4me0AsIDkQwDOSZ97MYAGM/u39OeZJKcCuAzALc75/6bApp4FoC+AJwr9t0nLKdkPEyTbA/ghkmTsDWBfGuqF5BUdSF6p9+uN5P+/aVnTx8cBGE1yc5OyIwBMKUFzrwYw1cy2leBYUiAle9t18HTFLwEYD2Acklv8owBsQnLLnFVnHYC9AAYAeDctG9gkvhzAH8zsvALPXxCSnZH8Qbq0mPpSPHXQtV1rABzf5OduAHYB2IDkPfg/hSpb0hP/JICbSXYhOQxJp9l+zwIYSvIqklXp1+kkT3bOX6hLkfwRerGIutICSva260cA/p7kZpI3APgVgPcBrASwAMCrBRxjIpI7gNVIbs8fQfIHA2a2FcD5AK4A8EH6nNuRdP4BwP0Ahqfn/w0AkLyX5L3NnPNqAFMs7amT/FDXXPYjeTuAY8zs6kq3RUpPr+wRS8fRT2FiFIBrAUyrdLukPNRBF7duSG7dj0XyHvwOAE9VtEVSNrqNF4mEbuNFIpHrbXyvXr2spqYmz1OKRKWhoQHr169nVqxFyU7yAgA/A9AewC/N7LbQ82tqalBfX9+SU4pIQG1trRsr+jY+/XjmLwBciGQSxRdJDi/2eCJSXi15zz4KwGIzW2pmu5HMnhpfmmaJSKm1JNn748CJEyvSsgOQnECynmT9unXrWnA6EWmJsvfGm1mdmdWaWW3v3r3LfToRcbQk2VfiwFlSA9IyEWmFWpLsbwA4keRgkh2QTJh4ujTNEpFSK3rozcz2kpwI4L+QDL09YGbzS9YyESmpFo2zm9lzAJ4rUVtEpIz0cVmRSCjZRSKhZBeJhJJdJBJKdpFIKNlFIqFkF4mEkl0kEkp2kUgo2UUi0YqWkt4QiM10yseVoyGt3nJ8yY0NxKecyMTyNOYwtD2wmU5XNLqxhah2YyfjGDdWj59nlo/77q1unWfv+mVm+Tasd+volV0kEkp2kUgo2UUioWQXiYSSXSQSSnaRSOS6sePRNbSx38+ObXwjUO/I7PI7f9LZrVODOW7s1uWnurHG1Tvc2J+d3jOz/Cyc4NZ5y40AY3BGIHq+G7mh/iI3tvaD7PITuvtnmr/Fjx2z2Y8t80ea0HFXdvmqwJKkWxf6sephfqzT235sjDNK+UpgtcTf3+fH8NlA7J1ArG8gtqyI4wWYWeb2T3plF4mEkl0kEkp2kUgo2UUioWQXiYSSXSQSuQ69sQcN52XHRh7l1+vQKbv8hJF+nVu+6seGhHaRP9YPjXBG7GY979e5fJIfq7vqSjf2fmB2VTfsdWNTFz2RWT7jZb8dq/b5Mc7zY50Dw2HrZ2eXL7jbrxNUG4hVBWKvFHm+YpwViPUJxH7rlDvDl83xht5aNMWVZAOArQAaAew1s9B/iYhUUCnms59rZv4kWhFpFfSeXSQSLU12A/A8yTdJTsh6AskJJOtJ1hf7HkREWq6lt/FnmdlKkn0ATCf5tpnNaPoEM6sDUAekHXQiUhEtemU3s5Xp97UApgEYVYpGiUjpFT30RrIrgHZmtjV9PB3AD8zsd16dqh607s7Q2zHOzDYAOGNPdvnywH3JW2/6sbWz/FjQBU65+y8GMCQQuyIQ2+6HRo8JVHs2u3yev4YiApP20L69Hxsc+LctrncC/xtoR0ho6Cp7MmIiMJOu5AKzAHsG2r9haWmbUY6ht74AppHcf5z/CCW6iFRW0cluZksB+BPDRaRV0dCbSCSU7CKRULKLRELJLhKJfGe9sbQfqgmt4bemlCcql9CQUWAo0ps5CACY4pTvbL45h8zbVg7wF1FcUYZ29ArEIpy1oQUnRSKnZBeJhJJdJBJKdpFIKNlFItGme+ND+gViq0p8rsyuz1RoHsziYk84MBDzPsDsTJApmz93yucH6pSjpz5C6o0XiZySXSQSSnaRSCjZRSKhZBeJhJJdJBJtYujtbKd8hlPempwciI3s4sceHhCo+G6xrclRaM04z9qStyJKGnoTiZySXSQSSnaRSCjZRSKhZBeJhJJdJBKl2J+97OZVugEtENp9aMgOP2Y/9seunnzFH6O6/Pbs8sZAO8qilQyjXXxUdvmzW/JtR2vQ7Cs7yQdIriU5r0lZD5LTSS5Kvx9d3maKSEsVchv/IP50S8PJAF4wsxMBvJD+LCKtWLPJnu63vvGg4vEAHkofPwTgkhK3S0RKrNj37H3NbP+CL6sRWMKd5AQAE4o8j4iUSIs76MzMQp95N7M6AHVAvstSiciBih16W0OyHwCk31tJ36uIeAqa9UayBsCzZvbx9Od/BrDBzG4jORlADzObVMBx9MpeoD2B2BEPDvWDH+udXb6hwa0y9b2VbuyyH/mnMm+Lp4ArArHqQX7sjMAsumvODxzU+4079TK3ygdbf+fGJn9vqxubsjnQjhwVPeuN5CMAXgFwEskVJK8FcBuA80guAjAu/VlEWrFm37Ob2Red0GdK3BYRKSN9XFYkEkp2kUgo2UUioWQXiUSuC05W96aN+Hx2rGtgpP6P07LLd7a8Sa3WtwOxfwktRvkXTvkFgaUvP7eggBZlWPYVP/bLKdnloYUoJ54RCHr9xABm/7sb+sOI1zPLPz0qcKrvXOzH7g9smveDwDGXBmLV2cWzT/KrrHSGPb/zt8Cid7XgpEjUlOwikVCyi0RCyS4SCSW7SCSU7CKRyHXByeoewOgvZMf6dvTrnd6QXf7DmS1uUqv1YSC2coUf23l3dvkJfQNLX37uicDZLvRDgy73Yzdsyi5/2B+62tj5FTfWY4wfwwg/dI4XyB6RS1wZGF4LmPDffuyac/3YaGcY8FR3SRige212eefA/oF6ZReJhJJdJBJKdpFIKNlFIqFkF4lErr3xrAKqnB7G277p19t0GPe6e3YHYoFl4bDBKf/CTX6duTf567F993N+vepJ3/CDoz+VXT7T7+ke+5F/uB3/48duecmP5akuFHvRjx3rxH7xCb/ORmfyzIeBxQv1yi4SCSW7SCSU7CKRULKLRELJLhIJJbtIJHJdg673CbS/vDM7VheYU4FdZWmOtNB9zk5TAPC172UvNvfqJH+xwdAKdDE6JZAT3T6bXT7rJmDbe8Vv//QAybUk5zUpu5nkSpKz0q+LmjuOiFRWIbfxDwK4IKP8LjMbkX49V9pmiUipNZvsZjYDwMYc2iIiZdSSDrqJJOekt/lHe08iOYFkPcn6j0IrMohIWRWb7PcAGIJkjZBVAO7wnmhmdWZWa2a1nY4s8mwi0mJFJbuZrTGzRjPbB+A+AKH9NUSkFShq1hvJfma2Kv3xUgDzQs/fr0MnYMCJTjDH4bWJj/qxn08KVHS23InV19cFYoEhNinMnMCuXCOdobfQQHqzyU7yESTr9vUiuQLATQDOITkiPXYDgMBcRxFpDZpNdjPL2lHv/jK0RUTKSB+XFYmEkl0kEkp2kUgo2UUikeuCkyDQrlM+p7pjhh+b38+PnX+vH3te032kldi5N7t8X2DsTa/sIpFQsotEQskuEgklu0gklOwikVCyi0Qi16G3nY3AvM3ZsTOv9+u97MyWvzCw6dmAk/3YzDl+7Cj9+ZPWIrD33cDu2eUrAxmtX22RSCjZRSKhZBeJhJJdJBJKdpFI5Nob32470PnV7NjYS/x61/xddvlyp0cSAObP9mNnD/Fjm7f6sV972x0F1mITKVaXfX7s9POzy+fc6tfRK7tIJJTsIpFQsotEQskuEgklu0gklOwikShkR5iBAH4FoC+SHWDqzOxnJHsAeAxADZJdYS43s02hY3XpAnzytOzYkhV+vcfXZJdbf7/OBUP9WP/AkMYxgdgXnMk6j03260j53fi0H3vRGRZ95drytKWUdgSGdNdsyS7f2+jXKeSVfS+A681sOIAxAL5FcjiAyQBeMLMTAbyQ/iwirVSzyW5mq8zsrfTxVgALAfQHMB7AQ+nTHgIQ+FiMiFTaIb1nJ1kD4DQArwHo22Qn19VIbvNFpJUqONlJVgOYCuA6M/uwaczMDM5usSQnkKwnWb/NWbhCRMqvoGQnWYUk0R82syfT4jUk+6XxfgAyN+Q2szozqzWz2urAZ9lFpLyaTXaSRLJF80Izu7NJ6GkAV6ePrwbwVOmbJyKlUsistzMBXAVgLslZadmNAG4D8DjJawG8D+Dy5g7EDkC747Jj/ejXa+8Mo7ULDNdt3+XHFgRinVb6sU/UZpc/5leRgwXWBhw03o99+Wt+bFgPP9azS3Z5Wxh6Q2gG5jPZ5aG3ys0mu5m9BMBLxc80V19EWgd9gk4kEkp2kUgo2UUioWQXiYSSXSQSuS44uWsf0LA9O1bV3q93vDMTbXHgXK++58d6BmYTNXb0Y4M6OOXO4n8AsOx5P5an8d/zY0O+7cdqArMAFwdmWK1Ykl1+1DC/TnvndwMAOq73Y+8Ghps+fooTCMyYRGD4tbXo+WF2+c4WznoTkcOAkl0kEkp2kUgo2UUioWQXiYSSXSQSuQ697d0NrHVmqu0JzFxa7gy77Orn1zm9sx9rH6i3a7cf2+0My119pV/nH1vJ0NvpgTmJXXf6sVVVfqzbUj/WxxkO65y56kHiqMC1336iH9u9yI+tXpVd3ulYv85HbWDobe9GJ6ChNxFRsotEQskuEgklu0gklOwikci1N35TIzDV6UU8NzCrpZuzbllHZzIAAOwI9DD3qfFjG5f7sSOc9cx6jfbrtBYbAz3Mg5219QCga2BDr7d7+rHjnN7uPr39OoMCsdff8WNzAyMvm5ze+I/a+MvcsvlOIPB738b/ySJSKCW7SCSU7CKRULKLRELJLhIJJbtIJJodeiM5EMCvkGzJbADqzOxnJG8G8HUA+1d0u9HMngsdq6MBJ+xxYmP9ektmZJd3ytw3NhXYZqhbYPunfdV+rKvzp3HB3kA7inVSIBYYhvKsX+DHPhrnx+b+zo/tCmzZNcu5JkMDa7+tHOTH1r3kx7Z19WMrejmBtr7J6G+d8kBOFDLOvhfA9Wb2FsluAN4kOT2N3WVmPzmkRopIRRSy19sqAKvSx1tJLkR4bU4RaYUO6T07yRoApwF4LS2aSHIOyQdIHl3itolICRWc7CSrAUwFcJ2ZfQjgHgBDAIxA8sp/h1NvAsl6kvV7Ax9vFZHyKijZSVYhSfSHzexJADCzNWbWaGb7ANwHYFRWXTOrM7NaM6s94shSNVtEDlWzyU6SAO4HsNDM7mxS3nRxp0sBzCt980SkVArpjT8TwFUA5pKclZbdCOCLJEcg6exvAPCNZk+2G+juzL6a28ev18+ZXXVMYNbVkYHZWksC66DtdGa2AcDLDc7xNvh1ilbE8FrI07P9WNc3/djbgW20OgTWDTxtZHb54sDsxnff8GNdjvdjawJDb8P6Zpe/9JFfp00IDTs7CumNfwlA1ohqcExdRFoXfYJOJBJKdpFIKNlFIqFkF4mEkl0kErkuOPlRFfD2Mdmxzm/59d7bll3e/5N+nWWd/NjvA+MIfQKLRw7rkF1+0qf9Og/7oVxtDlzfD9b5saFn+7GlW/zY+85Cj+vb+3UGn+nHdnjbHQEYFzhm36HZ5VMCi1QervTKLhIJJbtIJJTsIpFQsotEQskuEgklu0gkch1627MLWOXMomr3tl/vJGeIrcMwv06n7X7s/M8H6gWGcY50Ztk1BvbXQmA2HwKz74Ze58fe/WngmJ7QXm+B2YPVgfWHZj4fOJ0z2+y4AX6d0wJDqbMWBc71rh9b+IITCCykGXRpIDatyGMWw/s9bfSr6JVdJBJKdpFIKNlFIqFkF4mEkl0kEkp2kUjkOvRWtQvo4wyhbAkMuww7Nbt871a/zszALK+xgX3gqqr8WEdnWGNDaMHJgYFYYOhtcWBGWfVNfmzbLU5gh19n2hw/NiSwJ9qSbn6sytlPb8GTfp32gd/GDYGh1IZA+3cFhqKKcUpgD75AM4oy9CI/5m3BsD6wJ55e2UUioWQXiYSSXSQSSnaRSCjZRSLRbG88yU4AZgDomD7/CTO7ieRgAI8C6AngTQBXmdnu0LHaVQGdj82OXXKcX2+xs/7Y5vl+nRGD/djbga2VRgfWXDvC6f1fEugpZmAnewtsu7Tvj35s7L/6saf9kOv9rP1+UltX+LHegZ7pFV69wKJ8z/6nH8O5gVhgIgyWB2JFmHNbaY8HALg4u3h7YCuyPb2yyy2whVYhr+y7AIw1s1ORbM98AckxAG4HcJeZnQBgE4BrCziWiFRIs8luif3ru1alXwZgLIAn0vKHAFxSlhaKSEkUuj97+3QH17UApgNYAmCzme1Nn7ICQOCGVUQqraBkN7NGMxsBYACAUQACy0YciOQEkvUk6xsDn+ISkfI6pN54M9sM4EUAZwDoTnJ/B98AOGuhmFmdmdWaWW37QIeDiJRXs8lOsjfJ7unjzgDOA7AQSdL/Vfq0qwE8Va5GikjL0czCTyBPQdIB1x7JH4fHzewHJI9HMvTWA8BMAF82M2f6Q6JLX9pJX8qOXfYtv94sZ4htdWDIq0+1H9vtzSIAsC0wqaW3sx7bImddPQCYebMfEwnpfJof2+VMHNv3G8DWWeZgarPj7GY2B8CfnNbMliJ5/y4ibYA+QScSCSW7SCSU7CKRULKLRELJLhKJZofeSnoych2A99MfewFYn9vJfWrHgdSOA7W1dhxnZr2zArkm+wEnJuvNrLYiJ1c71I4I26HbeJFIKNlFIlHJZK+r4LmbUjsOpHYc6LBpR8Xes4tIvnQbLxIJJbtIJCqS7CQvIPkOycUkJ1eiDWk7GkjOJTmLZH2O532A5FqS85qU9SA5neSi9Lszobbs7biZ5Mr0mswiGdhxrGTtGEjyRZILSM4n+Z20PNdrEmhHrteEZCeSr5OcnbbjlrR8MMnX0rx5jGSHQzqwmeX6hWRe/BIAxwPoAGA2gOF5tyNtSwOAXhU479kARgKY16TsxwAmp48nA7i9Qu24GcANOV+PfgBGpo+7IVkcenje1yTQjlyvCQACqE4fVwF4DcAYAI8DuCItvxfANw/luJV4ZR8FYLGZLbVknflHAYyvQDsqxsxmADh4NfzxSBYJAXJarddpR+7MbJWZvZU+3opkJaT+yPmaBNqRK0uUfEXnSiR7fxy4dH8lV6Y1AM+TfJPkhAq1Yb++ZrYqfbwaQN8KtmUiyTnpbX7Z3040RbIGyWIpr6GC1+SgdgA5X5NyrOgcewfdWWY2EsCFAL5FMrAfTH4suU+r1JjoPQCGINkQZBWAO/I6MclqAFMBXGdmByweluc1yWhH7tfEWrCis6cSyb4SwMAmP7sr05abma1Mv68FMA2VXWZrDcl+AJB+X1uJRpjZmvQXbR+A+5DTNSFZhSTBHjazJ9Pi3K9JVjsqdU3Scx/yis6eSiT7GwBOTHsWOwC4AsVtUdYiJLuS7Lb/MYDzAcwL1yqrp5Gs0gtUcLXe/cmVuhQ5XBOSBHA/gIVmdmeTUK7XxGtH3tekbCs659XDeFBv40VIejqXAPh+hdpwPJKRgNkA5ufZDgCPILkd3IPkvde1SDbIfAHAIgC/B9CjQu2YAmAugDlIkq1fDu04C8kt+hwAs9Kvi/K+JoF25HpNAJyCZMXmOUj+sPxDk9/Z1wEsBvBrAB0P5bj6uKxIJGLvoBOJhpJdJBJKdpFIKNlFIqFkF4mEkl0kEkp2kUj8H8YBlJHyczgDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CrossEntropy' from 'fuzzytorch.losses' (../fuzzytorch/losses.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1530ede24f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m### LOSS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfuzzytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEntropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m loss_kwargs = {\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'CrossEntropy' from 'fuzzytorch.losses' (../fuzzytorch/losses.py)"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' # see issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '' # CPU\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import XEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = XEntropy('xentropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "### GET MODEL\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "### MONITORS\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "from fuzzytorch import C_\n",
    "\n",
    "monitor_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':1e2,\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **monitor_config)\n",
    "\n",
    "### TRAIN\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_time_util_convergence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['opt_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['loss_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['metrics_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from flamingchoripan.counters import Counter\n",
    "\n",
    "d = {\n",
    "'val_epoch_counter_duration':1,\n",
    "'earlystop_epoch_duration':5,\n",
    "}\n",
    "c = Counter(d)\n",
    "for _ in range(50):\n",
    "    print(c, c.check('earlystop_epoch_duration'))\n",
    "    c.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
