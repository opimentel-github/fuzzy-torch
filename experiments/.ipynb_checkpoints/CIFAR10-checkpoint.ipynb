{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../flaming-choripan') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "\n",
    "## Train-Val Split\n",
    "train_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':True,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "val_kwargs = {\n",
    "    'root':'../data/',\n",
    "    'train':False,\n",
    "    'download':True,\n",
    "    'transform':transforms.Compose([transforms.ToTensor()]),\n",
    "}\n",
    "train_cifar10 = datasets.CIFAR10(**train_kwargs)\n",
    "val_cifar10 = datasets.CIFAR10(**val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([50000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([50000]) - y.max: 9\n",
      "x: torch.Size([10000, 3, 32, 32]) - x.max: 1.0 - y: torch.Size([10000]) - y.max: 9\n",
      "{'input': {'x': (3, 32, 32)-float32-cpu, 'x2': (32)-float32-cpu}, 'target': {'y': ()-int64-cpu, 'y2': (1)-int64-cpu}}\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from datasets import MyDataset\n",
    "import numpy as np\n",
    "\n",
    "## Batch Sizes\n",
    "train_batch_size = 256\n",
    "val_batch_size = train_batch_size\n",
    "\n",
    "train_dataset_mnist = MyDataset(train_cifar10.data, train_cifar10.targets, uses_da=True)\n",
    "val_dataset_mnist = MyDataset(val_cifar10.data, val_cifar10.targets)\n",
    "val_dataset_mnist.set_norm_values(*train_dataset_mnist.get_norm_values())\n",
    "\n",
    "print(train_dataset_mnist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'input': {'x': (256, 3, 32, 32)-float32-cpu, 'x2': (256, 32)-float32-cpu}, 'target': {'y': (256)-int64-cpu, 'y2': (256, 1)-int64-cpu}}\n",
      "data torch.Size([256, 3, 32, 32]) cpu torch.float32 tensor(-2.1726) tensor(2.3228)\n",
      "target torch.Size([256]) cpu torch.int64 tensor(0) tensor(9)\n",
      "196\n",
      "40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzytorch.datasets import tensor_data_collate\n",
    "\n",
    "## DataLoaders\n",
    "train_loader_mnist = torch.utils.data.DataLoader(train_dataset_mnist, batch_size=train_batch_size, shuffle=True, collate_fn=tensor_data_collate)\n",
    "val_loader_mnist = torch.utils.data.DataLoader(val_dataset_mnist, batch_size=val_batch_size, collate_fn=tensor_data_collate)\n",
    "\n",
    "# print example\n",
    "for k,tensor_dict in enumerate(train_loader_mnist):\n",
    "#for k,(data, target) in enumerate(val_loader_mnist):\n",
    "    print(tensor_dict)\n",
    "    ind = 37\n",
    "    data = tensor_dict['input']['x']\n",
    "    target = tensor_dict['target']['y']\n",
    "    print('data', data.shape, data.device ,data.dtype, data.min(), data.max())\n",
    "    print('target', target.shape, target.device, target.dtype, target.min(), target.max())\n",
    "    img = data[ind].permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.title(f'target: {target[ind]}')\n",
    "    break\n",
    "    \n",
    "print(len(train_loader_mnist))\n",
    "print(len(val_loader_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(0) - {'mdl_class': <class 'baseline_models.CNN2DClassifier'>, 'mdl_kwargs': {'dropout': 0.5, 'cnn_features': [16, 32, 64], 'uses_mlp_classifier': True}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flamingchoripan.datascience.grid_search import GDIter, GridSeacher\n",
    "from baseline_models import MLPClassifier, CNN2DClassifier\n",
    "\n",
    "mdl_params = {\n",
    "    #'mdl_class':MLPClassifier,\n",
    "    'mdl_class':CNN2DClassifier,\n",
    "    'mdl_kwargs':{\n",
    "        'dropout':0.5,\n",
    "        #'dropout':0.0,\n",
    "        'cnn_features':[16, 32, 64],\n",
    "        #'cnn_features':[16, 32],\n",
    "        'uses_mlp_classifier':True,\n",
    "        #'uses_mlp_classifier':False,\n",
    "    },\n",
    "}\n",
    "gs = GridSeacher(mdl_params)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "ml_cnn2d: Conv2D(\n",
      "  (0) - Conv2DLinear(input_dims=3, input_space=[32, 32], output_dims=16, output_space=[16, 16], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(1,216[p])\n",
      "  (1) - Conv2DLinear(input_dims=16, input_space=[16, 16], output_dims=32, output_space=[8, 8], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(12,832[p])\n",
      "  (2) - Conv2DLinear(input_dims=32, input_space=[8, 8], output_dims=64, output_space=[4, 4], spatial_field=[6, 6], cnn_kwargs={'kernel_size': [5, 5], 'stride': [1, 1], 'dilation': [1, 1]}, pool_kwargs={'kernel_size': [2, 2], 'stride': [2, 2], 'dilation': [1, 1]}, padding_mode=same, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True)(51,264[p])\n",
      ")(65,312[p])\n",
      "mlp_classifier: MLP(\n",
      "  (0) - Linear(input_dims=1024, output_dims=50, activation=relu, in_dropout=0.0, out_dropout=0.0, bias=True, split_out=1)(51,250[p])\n",
      "  (1) - Linear(input_dims=50, output_dims=10, activation=linear, in_dropout=0.5, out_dropout=0.0, bias=True, split_out=1)(510[p])\n",
      ")(51,760[p])\n",
      "▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄\n",
      "\u001b[34mmodel_name: mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64 - id: 0\u001b[0m\n",
      "\u001b[32mdevice: cpu - device_name: cpu\u001b[0m\n",
      "save_rootdir: ../save/mdl=cnn2d°dropout=0.5°output_dims=10°cnn_features=16-32-64\n",
      "[x-entropy]\n",
      " - opt-parameters: 117,072[p] - device: cpu\n",
      " - save-mode: only_sup_metric(target_metric_crit: None)\n",
      " - counter_k: k: 0/0 - counter_epoch: val_epoch: 0/0 > earlystop_epoch: 0/5\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "  0%|          | 35/196000 [01:21,  2.33s/it, id: 0 - epoch: 5/1,000(6/196)[x-entropy] __loss__: 1.98=.99+.66(loss/2+loss/3) @.089[segs]\u001b[34m[train][x-entropy] __loss__: 1.94=.97+.65(loss/2+loss/3) - accuracy: 29.87 - dummy-accuracy: 10.00 @13.340[segs]\u001b[0m\u001b[31m[val][x-entropy] __loss__: 1.92=.96+.64(loss/2+loss/3) - accuracy: 30.00 - dummy-accuracy: 10.00 @1.973[segs]\u001b[0m\u001b[33m[stop][x-entropy] counter_epoch: val_epoch: 0/0 > earlystop_epoch: 4/5)\u001b[0m]   \n",
      "\u001b[31m*** early stopping ***\u001b[0m\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "End of training!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LossMonitor' object has no attribute 'get_best_epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-147578ca82a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mmodel_train_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_train_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mmodel_train_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_mnist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/fuzzytorch/handlers.py\u001b[0m in \u001b[0;36mfit_loader\u001b[0;34m(self, train_loader, val_loader, model_kwargs, load, k_every, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'End of training!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mlmonitor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmonitors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'[{lmonitor.name}] best-epoch: {lmonitor.get_best_epoch()} - convergence-time: {lmonitor.get_mins_to_convergence():.4f}[mins]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                         \u001b[0mtext\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf' - time-per-epoch: {lmonitor.get_mins_per_epoch():.4f}[mins]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LossMonitor' object has no attribute 'get_best_epoch'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### LOSS\n",
    "from fuzzytorch.losses import CrossEntropy\n",
    "\n",
    "loss_kwargs = {\n",
    "    'model_output_is_with_softmax':False,\n",
    "    'target_is_onehot':False,\n",
    "}\n",
    "loss = CrossEntropy('x-entropy', **loss_kwargs)\n",
    "\n",
    "### METRICS\n",
    "from fuzzytorch.metrics import DummyAccuracy, OnehotAccuracy\n",
    "metrics = [\n",
    "    OnehotAccuracy('accuracy', **loss_kwargs),\n",
    "    DummyAccuracy('dummy-accuracy', **loss_kwargs),\n",
    "]\n",
    "\n",
    "from fuzzytorch import C_\n",
    "trainh_config = {\n",
    "    'early_stop_epochcheck_epochs':1, # every n epochs check\n",
    "    #'early_stop_epochcheck_epochs':2, # every n epochs check\n",
    "    'early_stop_patience_epochchecks':int(1e2),\n",
    "    #'save_mode':C_.SM_NO_SAVE,\n",
    "    #'save_mode':C_.SM_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_ALL,\n",
    "    #'save_mode':C_.SM_ONLY_INF_METRIC,\n",
    "    #'save_mode':C_.SM_ONLY_INF_LOSS,\n",
    "    'save_mode':C_.SM_ONLY_SUP_METRIC,\n",
    "}\n",
    "model = mdl_params['mdl_class'](**mdl_params['mdl_kwargs'])\n",
    "\n",
    "### OPTIMIZER\n",
    "import torch.optim as optims\n",
    "from fuzzytorch.optimizers import LossOptimizer\n",
    "\n",
    "optimizer_kwargs = {\n",
    "    'opt_kwargs':{\n",
    "        'lr':1e-3,\n",
    "    },\n",
    "    'decay_kwargs':{\n",
    "        'lr':0.9,\n",
    "    }\n",
    "}\n",
    "optimizer = LossOptimizer(model, optims.Adam, **optimizer_kwargs)\n",
    "\n",
    "from flamingchoripan.prints import print_bar\n",
    "from fuzzytorch.handlers import ModelTrainHandler\n",
    "from fuzzytorch.monitors import LossMonitor\n",
    "\n",
    "loss_monitors = LossMonitor(loss, optimizer, metrics, **trainh_config)\n",
    "\n",
    "mtrain_config = {\n",
    "    'id':0,\n",
    "    'epochs_max':1e3,\n",
    "    'save_rootdir':'../save',\n",
    "}\n",
    "model_train_handler = ModelTrainHandler(model, loss_monitors, **mtrain_config)\n",
    "model_train_handler.build_gpu(gpu_index=None)\n",
    "print(model_train_handler)\n",
    "model_train_handler.fit_loader(train_loader_mnist, val_loader_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'XError' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-be16fb28cb40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# loss_df opt_df loss_df_epoch metrics_df_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mloss_monitors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_util_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/fuzzytorch/monitors.py\u001b[0m in \u001b[0;36mget_time_util_convergence\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_time_util_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_util_convergence_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_evaluation_set_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \t'''\n",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/fuzzytorch/monitors.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_time_util_convergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_util_convergence_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_evaluation_set_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \t'''\n",
      "\u001b[0;32m~/oscar/tesis/fuzzy-torch/fuzzytorch/monitors.py\u001b[0m in \u001b[0;36mget_time_util_convergence_set\u001b[0;34m(self, set_name)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_time_util_convergence_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_per_epoch_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget_time_per_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'XError' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_time_util_convergence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__k__</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>64</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       __k__     lr\n",
       "epoch              \n",
       "0          8  0.001\n",
       "1         16  0.001\n",
       "2         24  0.001\n",
       "3         32  0.001\n",
       "4         40  0.001\n",
       "5         48  0.001\n",
       "6         56  0.001\n",
       "7         64  0.001\n",
       "8         72  0.001\n",
       "9         80  0.001"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['opt_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__dt__</th>\n",
       "      <th>__set__</th>\n",
       "      <th>__len__</th>\n",
       "      <th>__loss__</th>\n",
       "      <th>loss/2</th>\n",
       "      <th>loss/3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.301657</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>2.093698</td>\n",
       "      <td>1.046849</td>\n",
       "      <td>0.697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.942505</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "      <td>2.089720</td>\n",
       "      <td>1.044860</td>\n",
       "      <td>0.696573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.287506</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1.971287</td>\n",
       "      <td>0.985643</td>\n",
       "      <td>0.657095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.947751</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "      <td>1.962694</td>\n",
       "      <td>0.981347</td>\n",
       "      <td>0.654231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.305208</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1.902148</td>\n",
       "      <td>0.951074</td>\n",
       "      <td>0.634049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.958064</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "      <td>1.895375</td>\n",
       "      <td>0.947687</td>\n",
       "      <td>0.631791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.209358</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1.803590</td>\n",
       "      <td>0.901795</td>\n",
       "      <td>0.601197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.940974</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "      <td>1.796123</td>\n",
       "      <td>0.898061</td>\n",
       "      <td>0.598707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.328839</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1.686646</td>\n",
       "      <td>0.843323</td>\n",
       "      <td>0.562216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              __dt__ __set__  __len__  __loss__    loss/2    loss/3\n",
       "val_epoch                                                          \n",
       "1          13.301657   train        1  2.093698  1.046849  0.697900\n",
       "1           1.942505     val        1  2.089720  1.044860  0.696573\n",
       "3          13.287506   train        1  1.971287  0.985643  0.657095\n",
       "3           1.947751     val        1  1.962694  0.981347  0.654231\n",
       "5          13.305208   train        1  1.902148  0.951074  0.634049\n",
       "5           1.958064     val        1  1.895375  0.947687  0.631791\n",
       "7          13.209358   train        1  1.803590  0.901795  0.601197\n",
       "7           1.940974     val        1  1.796123  0.898061  0.598707\n",
       "9          13.328839   train        1  1.686646  0.843323  0.562216"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['loss_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__dt__</th>\n",
       "      <th>__set__</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>dummy-accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.311674</td>\n",
       "      <td>train</td>\n",
       "      <td>24.200415</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.947278</td>\n",
       "      <td>val</td>\n",
       "      <td>24.521484</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.298579</td>\n",
       "      <td>train</td>\n",
       "      <td>29.657606</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.952386</td>\n",
       "      <td>val</td>\n",
       "      <td>30.400391</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.316425</td>\n",
       "      <td>train</td>\n",
       "      <td>33.138950</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.962826</td>\n",
       "      <td>val</td>\n",
       "      <td>33.398438</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.220486</td>\n",
       "      <td>train</td>\n",
       "      <td>36.941963</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.945632</td>\n",
       "      <td>val</td>\n",
       "      <td>37.333984</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.340092</td>\n",
       "      <td>train</td>\n",
       "      <td>39.051338</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              __dt__ __set__   accuracy  dummy-accuracy\n",
       "val_epoch                                              \n",
       "1          13.311674   train  24.200415            10.0\n",
       "1           1.947278     val  24.521484            10.0\n",
       "3          13.298579   train  29.657606            10.0\n",
       "3           1.952386     val  30.400391            10.0\n",
       "5          13.316425   train  33.138950            10.0\n",
       "5           1.962826     val  33.398438            10.0\n",
       "7          13.220486   train  36.941963            10.0\n",
       "7           1.945632     val  37.333984            10.0\n",
       "9          13.340092   train  39.051338            10.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss_df opt_df loss_df_epoch metrics_df_epoch\n",
    "loss_monitors.get_save_dict()['metrics_df_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from flamingchoripan.counters import Counter\n",
    "\n",
    "d = {\n",
    "'val_epoch_counter_duration':1,\n",
    "'earlystop_epoch_duration':5,\n",
    "}\n",
    "c = Counter(d)\n",
    "for _ in range(50):\n",
    "    print(c, c.check('earlystop_epoch_duration'))\n",
    "    c.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import flamingChoripan.tinyFlame.plots as tfplots\n",
    "\n",
    "### training plots\n",
    "fig, ax = tfplots.plot_trainloss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_loss(train_handler)\n",
    "fig, ax = tfplots.plot_evaluation_metrics(train_handler)\n",
    "#fig, ax = tfplots.plot_optimizer(train_handler, save_dir=mtrain_config['images_save_dir'])\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction and CM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
